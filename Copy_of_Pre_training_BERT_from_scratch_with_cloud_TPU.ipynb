{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Pre-training BERT from scratch with cloud TPU",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/algharak/CTRL/blob/master/Copy_of_Pre_training_BERT_from_scratch_with_cloud_TPU.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E2XB_l-Hgzq_",
        "colab_type": "text"
      },
      "source": [
        "# Pre-training BERT from scratch with cloud TPU"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vZPgpRl5g2e2",
        "colab_type": "text"
      },
      "source": [
        "In this experiment, we will be pre-training a state-of-the-art Natural Language Understanding model [BERT](https://arxiv.org/abs/1810.04805.) on arbitrary text data using Google Cloud infrastructure.\n",
        "\n",
        "This guide covers all stages of the procedure, including:\n",
        "\n",
        "1. Setting up the training environment\n",
        "2. Downloading raw text data\n",
        "3. Preprocessing text data\n",
        "4. Learning a new vocabulary\n",
        "5. Creating sharded pre-training data\n",
        "6. Setting up GCS storage for data and model\n",
        "7. Training the model on a cloud TPU\n",
        "\n",
        "For persistent storage of training data and model, you will require a Google Cloud Storage bucket. \n",
        "Please follow the [Google Cloud TPU quickstart](https://cloud.google.com/tpu/docs/quickstart) to create a GCP account and GCS bucket. New Google Cloud users have [$300 free credit](https://cloud.google.com/free/) to get started with any GCP product. \n",
        "\n",
        "Steps 1-5 of this tutorial can be run without a GCS bucket for demonstration purposes. In that case, however, you will not be able to train the model.\n",
        "\n",
        "**Note** \n",
        "The only parameter you *really have to set* is BUCKET_NAME in steps 5 and 6. Everything else has default values which should work for most use-cases.\n",
        "\n",
        "**Note** \n",
        "Pre-training a BERT-Base model on a TPUv2 will take about 54 hours. Google Colab is not designed for executing such long-running jobs and will interrupt the training process every 8 hours or so. For uninterrupted training, consider using a preemptible TPUv2 instance. \n",
        "\n",
        "That said, at the time of writing (09.05.2019), with a Colab TPU, pre-training a BERT model from scratch can be achieved at a negligible cost of storing the said model and data in GCS  (~1 USD).\n",
        "\n",
        "Now, let's get to business."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ODimOhBR05yR",
        "colab_type": "text"
      },
      "source": [
        "MIT License\n",
        "\n",
        "Copyright (c) [2019] [Antyukhov Denis Olegovich]\n",
        "\n",
        "Permission is hereby granted, free of charge, to any person obtaining a copy\n",
        "of this software and associated documentation files (the \"Software\"), to deal\n",
        "in the Software without restriction, including without limitation the rights\n",
        "to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n",
        "copies of the Software, and to permit persons to whom the Software is\n",
        "furnished to do so, subject to the following conditions:\n",
        "\n",
        "The above copyright notice and this permission notice shall be included in all\n",
        "copies or substantial portions of the Software.\n",
        "\n",
        "THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
        "IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
        "FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n",
        "AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
        "LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n",
        "OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n",
        "SOFTWARE."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fjad5jsr9YaM",
        "colab_type": "text"
      },
      "source": [
        "## Step 1: setting up training environment\n",
        "First and foremost, we get the packages required to train the model. \n",
        "The Jupyter environment allows executing bash commands directly from the notebook by using an exclamation mark ‘!’. I will be exploiting this approach to make use of several other bash commands throughout the experiment.\n",
        "\n",
        "Now, let’s import the packages and authorize ourselves in Google Cloud."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9S4CiOh3RzFW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install sentencepiece\n",
        "!git clone https://github.com/google-research/bert\n",
        "\n",
        "import os\n",
        "import sys\n",
        "import json\n",
        "import nltk\n",
        "import random\n",
        "import logging\n",
        "import tensorflow as tf\n",
        "import sentencepiece as spm\n",
        "\n",
        "from glob import glob\n",
        "from google.colab import auth, drive\n",
        "from tensorflow.keras.utils import Progbar\n",
        "\n",
        "sys.path.append(\"bert\")\n",
        "\n",
        "from bert import modeling, optimization, tokenization\n",
        "from bert.run_pretraining import input_fn_builder, model_fn_builder\n",
        "\n",
        "auth.authenticate_user()\n",
        "  \n",
        "# configure logging\n",
        "log = logging.getLogger('tensorflow')\n",
        "log.setLevel(logging.INFO)\n",
        "\n",
        "# create formatter and add it to the handlers\n",
        "formatter = logging.Formatter('%(asctime)s :  %(message)s')\n",
        "sh = logging.StreamHandler()\n",
        "sh.setLevel(logging.INFO)\n",
        "sh.setFormatter(formatter)\n",
        "log.handlers = [sh]\n",
        "\n",
        "if 'COLAB_TPU_ADDR' in os.environ:\n",
        "  log.info(\"Using TPU runtime\")\n",
        "  USE_TPU = True\n",
        "  TPU_ADDRESS = 'grpc://' + os.environ['COLAB_TPU_ADDR']\n",
        "\n",
        "  with tf.Session(TPU_ADDRESS) as session:\n",
        "    log.info('TPU address is ' + TPU_ADDRESS)\n",
        "    # Upload credentials to TPU.\n",
        "    with open('/content/adc.json', 'r') as f:\n",
        "      auth_info = json.load(f)\n",
        "    tf.contrib.cloud.configure_gcs(session, credentials=auth_info)\n",
        "    \n",
        "else:\n",
        "  log.warning('Not connected to TPU runtime')\n",
        "  USE_TPU = False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hPkrAnvMF4tJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "5f650686-d555-42ff-dac3-1ed97922a684"
      },
      "source": [
        "!ls\n",
        "%cd content\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "bin\t datalab  home\t lib64\topt   run   swift\t\t  tmp\t var\n",
            "boot\t dev\t  lib\t media\tproc  sbin  sys\t\t\t  tools\n",
            "content  etc\t  lib32  mnt\troot  srv   tensorflow-2.0.0-rc2  usr\n",
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PGVXMoC-aMy1",
        "colab_type": "text"
      },
      "source": [
        "## Step 2: getting the data\n",
        "\n",
        "We begin with obtaining a corpus of raw text data. For this experiment, we will be using the [OpenSubtitles](http://www.opensubtitles.org/) dataset, which is available for 65 languages [here](http://opus.nlpl.eu/OpenSubtitles-v2016.php). \n",
        "\n",
        "Unlike more common text datasets (like Wikipedia) it does not require any complex pre-processing. It also comes pre-formatted with one sentence per line.\n",
        "\n",
        "Feel free to use the dataset for your language instead by changing the language code (en) below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FotFkkshbdvK",
        "colab_type": "code",
        "outputId": "4a396546-d1e6-49b6-eae1-f4be0dfcae28",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 479
        }
      },
      "source": [
        "AVAILABLE =  {'af','ar','bg','bn','br','bs','ca','cs',\n",
        "              'da','de','el','en','eo','es','et','eu',\n",
        "              'fa','fi','fr','gl','he','hi','hr','hu',\n",
        "              'hy','id','is','it','ja','ka','kk','ko',\n",
        "              'lt','lv','mk','ml','ms','nl','no','pl',\n",
        "              'pt','pt_br','ro','ru','si','sk','sl','sq',\n",
        "              'sr','sv','ta','te','th','tl','tr','uk',\n",
        "              'ur','vi','ze_en','ze_zh','zh','zh_cn',\n",
        "              'zh_en','zh_tw','zh_zh'}\n",
        "\n",
        "LANG_CODE = \"en\" #@param {type:\"string\"}\n",
        "\n",
        "assert LANG_CODE in AVAILABLE, \"Invalid language code selected\"\n",
        "\n",
        "!wget http://opus.nlpl.eu/download.php?f=OpenSubtitles/v2016/mono/OpenSubtitles.raw.'$LANG_CODE'.gz -O dataset.txt.gz\n",
        "!gzip -d dataset.txt.gz\n",
        "!tail dataset.txt"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-10-15 06:27:40--  http://opus.nlpl.eu/download.php?f=OpenSubtitles/v2016/mono/OpenSubtitles.raw.en.gz\n",
            "Resolving opus.nlpl.eu (opus.nlpl.eu)... 193.166.25.9\n",
            "Connecting to opus.nlpl.eu (opus.nlpl.eu)|193.166.25.9|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://object.pouta.csc.fi/OPUS-OpenSubtitles/v2016/mono/en.txt.gz [following]\n",
            "--2019-10-15 06:27:41--  https://object.pouta.csc.fi/OPUS-OpenSubtitles/v2016/mono/en.txt.gz\n",
            "Resolving object.pouta.csc.fi (object.pouta.csc.fi)... 86.50.254.18\n",
            "Connecting to object.pouta.csc.fi (object.pouta.csc.fi)|86.50.254.18|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2906709304 (2.7G) [application/gzip]\n",
            "Saving to: ‘dataset.txt.gz’\n",
            "\n",
            "dataset.txt.gz      100%[===================>]   2.71G  21.2MB/s    in 2m 11s  \n",
            "\n",
            "2019-10-15 06:29:53 (21.1 MB/s) - ‘dataset.txt.gz’ saved [2906709304/2906709304]\n",
            "\n",
            "The astronomers run at full speed turning around each time they are pressed too closely and reducing the fragile beings to dust.\n",
            "At last, the astronomers have found the shell and quickly shut themselves in the interior.\n",
            "Thanks to the advance, they have succeeded in getting over their adversaries.\n",
            "Only one, the president, has been left behind.\n",
            "He rushes to the rope which hangs from the point of the shell and letting himself slide down the rope he gives it an impetus which causes the shell to fall off the edge of the moon.\n",
            "The shell falls with sickening rapidity.\n",
            "The sea appears.\n",
            "The shell balances and thanks to the hermetically sealed air in its interior rises slowly to the surface.\n",
            "The shell is picked up by a steamer which tows it to port.\n",
            "The Mayor welcomes the astronomers with a speech, and the general ovation awaits their happy return.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nb5TPsPOppn0",
        "colab_type": "text"
      },
      "source": [
        "For demonstration purposes, we will only use a small fraction of the whole corpus for this experiment. \n",
        "\n",
        "When training the real model, make sure to uncheck the DEMO_MODE checkbox to use a 100x larger dataset.\n",
        "\n",
        "Rest assured, 100M lines are perfectly sufficient to train a reasonably good BERT-base model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mkxbVDslIeFk",
        "colab_type": "text"
      },
      "source": [
        "I am saving at this checkpoint since things seems to have been working\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UDR5Z1MDgB1g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "DEMO_MODE = False #@param {type:\"boolean\"}\n",
        "\n",
        "if DEMO_MODE:\n",
        "  CORPUS_SIZE = 1000000\n",
        "else:\n",
        "  CORPUS_SIZE = 100000000 #@param {type: \"integer\"}\n",
        "  \n",
        "!(head -n $CORPUS_SIZE dataset.txt) > subdataset.txt\n",
        "!mv subdataset.txt dataset.txt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n43zSM6kJ0Hp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "9ff47525-0d16-4a78-e9f8-d6c61558a7e0"
      },
      "source": [
        "%ls -al\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 2875772\n",
            "drwxr-xr-x 1 root root       4096 Oct 15 06:40 \u001b[0m\u001b[01;34m.\u001b[0m/\n",
            "drwxr-xr-x 1 root root       4096 Oct 15 05:53 \u001b[01;34m..\u001b[0m/\n",
            "-rw-r--r-- 1 root root       2654 Oct 15 06:23 adc.json\n",
            "drwxr-xr-x 4 root root       4096 Oct 15 06:22 \u001b[01;34mbert\u001b[0m/\n",
            "drwxr-xr-x 1 root root       4096 Oct 15 06:23 \u001b[01;34m.config\u001b[0m/\n",
            "-rw-r--r-- 1 root root 2944752690 Oct 15 06:40 dataset.txt\n",
            "drwxr-xr-x 1 root root       4096 Aug 27 16:17 \u001b[01;34msample_data\u001b[0m/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X58Z7OSaKRS-",
        "colab_type": "text"
      },
      "source": [
        "I stopped here and will be updating the github"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oRQd4-v0nQqH",
        "colab_type": "text"
      },
      "source": [
        "## Step 3: preprocessing text\n",
        "\n",
        "The raw text data we have downloaded contains punсtuation, uppercase letters and non-UTF symbols which we will remove before proceeding. During inference, we will apply the same normalization procedure to new data.\n",
        "\n",
        "If your use-case requires different preprocessing (e.g. if uppercase letters or punctuation are expected during inference), feel free to modify the function below to accomodate for your needs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iCi2oSdInRkC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "regex_tokenizer = nltk.RegexpTokenizer(\"\\w+\")\n",
        "\n",
        "def normalize_text(text):\n",
        "  # lowercase text\n",
        "  text = str(text).lower()\n",
        "  # remove non-UTF\n",
        "  text = text.encode(\"utf-8\", \"ignore\").decode()\n",
        "  # remove punktuation symbols\n",
        "  text = \" \".join(regex_tokenizer.tokenize(text))\n",
        "  return text\n",
        "\n",
        "def count_lines(filename):\n",
        "  count = 0\n",
        "  with open(filename) as fi:\n",
        "    for line in fi:\n",
        "      count += 1\n",
        "  return count"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rYtwtDnesaQQ",
        "colab_type": "text"
      },
      "source": [
        "Check how that works."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0gngtEZWqVhY",
        "colab_type": "code",
        "outputId": "785333c0-6d5f-4d24-e4fc-7eb0fe5094d0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "normalize_text('Thanks to the advance, they have succeeded in getting over their adversaries.')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'thanks to the advance they have succeeded in getting over their adversaries'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zY-Kvnx6sUFS",
        "colab_type": "text"
      },
      "source": [
        "Apply normalization to the whole dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "myjxQe5awo1v",
        "colab_type": "code",
        "outputId": "80757166-7e12-44d5-b79a-69da6e6f6acd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "RAW_DATA_FPATH = \"dataset.txt\" #@param {type: \"string\"}\n",
        "PRC_DATA_FPATH = \"proc_dataset.txt\" #@param {type: \"string\"}\n",
        "\n",
        "# apply normalization to the dataset\n",
        "# this will take a minute or two\n",
        "\n",
        "total_lines = count_lines(RAW_DATA_FPATH)\n",
        "bar = Progbar(total_lines)\n",
        "\n",
        "with open(RAW_DATA_FPATH,encoding=\"utf-8\") as fi:\n",
        "  with open(PRC_DATA_FPATH, \"w\",encoding=\"utf-8\") as fo:\n",
        "    for l in fi:\n",
        "      fo.write(normalize_text(l)+\"\\n\")\n",
        "      bar.add(1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1000000/1000000 [==============================] - 5s 5us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O3A64RZjwo9k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zVO9EnUwrluQ",
        "colab_type": "text"
      },
      "source": [
        "## Step 4: building the vocabulary\n",
        "\n",
        "For the next step, we will learn a new vocabulary that we will use to represent our dataset. \n",
        "\n",
        "The BERT paper uses a WordPiece tokenizer, which is not available in opensource. Instead, we will be using SentencePiece tokenizer in unigram mode. While it is not directly compatible with BERT, with a small hack we can make it work.\n",
        "\n",
        "SentencePiece requires quite a lot of RAM, so running it on the full dataset in Colab will crash the kernel. To avoid this, we will randomly subsample a fraction of the dataset for building the vocabulary. Another option would be to use a machine with more RAM for this step - that decision is up to you.\n",
        "\n",
        "Also, SentencePiece adds BOS and EOS control symbols to the vocabulary by default. We disable them explicitly by setting their indices to -1.\n",
        "\n",
        "The typical values for VOC_SIZE are somewhere in between 32000 and 128000. We reserve NUM_PLACEHOLDERS tokens in case one wants to update the vocabulary and fine-tune the model after the pre-training phase is finished."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "18nn6eW_s-fV",
        "colab_type": "code",
        "outputId": "4fe0d4bb-d3a5-49ec-f1f6-4169b353ef8e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "MODEL_PREFIX = \"tokenizer\" #@param {type: \"string\"}\n",
        "VOC_SIZE = 32000 #@param {type:\"integer\"}\n",
        "SUBSAMPLE_SIZE = 12800000 #@param {type:\"integer\"}\n",
        "NUM_PLACEHOLDERS = 256 #@param {type:\"integer\"}\n",
        "\n",
        "SPM_COMMAND = ('--input={} --model_prefix={} '\n",
        "               '--vocab_size={} --input_sentence_size={} '\n",
        "               '--shuffle_input_sentence=true ' \n",
        "               '--bos_id=-1 --eos_id=-1').format(\n",
        "               PRC_DATA_FPATH, MODEL_PREFIX, \n",
        "               VOC_SIZE - NUM_PLACEHOLDERS, SUBSAMPLE_SIZE)\n",
        "\n",
        "spm.SentencePieceTrainer.Train(SPM_COMMAND)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mAowCoH2u1iZ",
        "colab_type": "text"
      },
      "source": [
        "Now let's see how we can make SentencePiece tokenizer work for the BERT model. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4OLaw7kPW3he",
        "colab_type": "text"
      },
      "source": [
        "Below is a sentence tokenized using the WordPiece vocabulary from a pretrained English [BERT-base](https://storage.googleapis.com/bert_models/2018_10_18/uncased_L-12_H-768_A-12.zip) model from the official [repo](https://github.com/google-research/bert). "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kwHAp_Gh5OPK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "testcase = \"Colorless geothermal substations are generating furiously\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NyEGAVl_5YRD",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "```\n",
        ">>> wordpiece.tokenize(\"Colorless geothermal substations are generating furiously\")\n",
        "\n",
        "['color',\n",
        " '##less',\n",
        " 'geo',\n",
        " '##thermal',\n",
        " 'sub',\n",
        " '##station',\n",
        " '##s',\n",
        " 'are',\n",
        " 'generating',\n",
        " 'furiously']\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BNiLdWXTh9cj",
        "colab_type": "text"
      },
      "source": [
        "As we can see, the WordPiece tokenizer prepends the subwords which occur in the middle of words with '##'. The subwords occurring at the beginning of words are unchanged. If the subword occurs both in the beginning and in the middle of words, both versions (with and without '##') are added to the vocabulary.\n",
        "\n",
        "Now let's have a look at the vocabulary that the SentencePiece tokenizer has learned."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H8_ebLxqTnWu",
        "colab_type": "code",
        "outputId": "bcb062f3-5261-42d1-9617-205b6bc6d6ff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "!ls"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "adc.json  dataset.txt\t    sample_data      tokenizer.vocab\n",
            "bert\t  proc_dataset.txt  tokenizer.model\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nYlBqiv5UD-j",
        "colab_type": "text"
      },
      "source": [
        "SentencePiece has created two files: tokenizer.model and tokenizer.vocab. Let's have a look at the learned vocabulary:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WDJ9QmNMUEQf",
        "colab_type": "code",
        "outputId": "46d5f5d7-fdb6-4a08-b1d6-82bfb04471b2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!head -n 100 tokenizer.vocab"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<unk>\t0\n",
            "▁you\t-3.2342\n",
            "▁i\t-3.2821\n",
            "▁the\t-3.56375\n",
            "▁s\t-3.84955\n",
            "▁to\t-3.87601\n",
            "▁a\t-3.9102\n",
            "▁it\t-3.97593\n",
            "▁t\t-4.25729\n",
            "▁and\t-4.32686\n",
            "▁that\t-4.33991\n",
            "▁of\t-4.57503\n",
            "▁what\t-4.59504\n",
            "▁is\t-4.67144\n",
            "▁me\t-4.7115\n",
            "▁in\t-4.71265\n",
            "▁we\t-4.7231\n",
            "▁he\t-4.88446\n",
            "▁this\t-4.89466\n",
            "▁no\t-4.98519\n",
            "▁on\t-4.99226\n",
            "▁my\t-4.99616\n",
            "▁m\t-5.02169\n",
            "▁your\t-5.02715\n",
            "▁for\t-5.05648\n",
            "▁have\t-5.06695\n",
            "▁don\t-5.09057\n",
            "▁do\t-5.12828\n",
            "▁\t-5.12998\n",
            "▁re\t-5.1371\n",
            "▁can\t-5.20534\n",
            "▁was\t-5.20891\n",
            "▁know\t-5.22494\n",
            "▁be\t-5.23557\n",
            "▁are\t-5.25247\n",
            "▁not\t-5.26685\n",
            "▁all\t-5.29439\n",
            "▁with\t-5.31925\n",
            "▁but\t-5.37188\n",
            "▁so\t-5.42124\n",
            "▁get\t-5.43031\n",
            "▁here\t-5.43446\n",
            "▁just\t-5.43719\n",
            "▁ll\t-5.49322\n",
            "▁like\t-5.5182\n",
            "▁they\t-5.5196\n",
            "▁there\t-5.52012\n",
            "▁up\t-5.55201\n",
            "▁go\t-5.55369\n",
            "▁she\t-5.5887\n",
            "▁right\t-5.61613\n",
            "▁out\t-5.64626\n",
            "▁oh\t-5.68517\n",
            "s\t-5.71583\n",
            "▁come\t-5.73109\n",
            "▁if\t-5.73944\n",
            "▁him\t-5.74635\n",
            "▁one\t-5.75141\n",
            "▁about\t-5.75416\n",
            "▁got\t-5.77074\n",
            "▁at\t-5.78535\n",
            "▁now\t-5.8265\n",
            "▁yeah\t-5.84144\n",
            "▁how\t-5.84948\n",
            "▁her\t-5.87603\n",
            "▁well\t-5.94933\n",
            "▁let\t-5.95131\n",
            "▁good\t-5.98986\n",
            "▁want\t-6.01295\n",
            "▁ve\t-6.02348\n",
            "▁think\t-6.04507\n",
            "▁who\t-6.06409\n",
            "▁did\t-6.09598\n",
            "▁see\t-6.10352\n",
            "▁why\t-6.11416\n",
            "▁will\t-6.12599\n",
            "▁gonna\t-6.17628\n",
            "▁from\t-6.17938\n",
            "▁look\t-6.19767\n",
            "▁as\t-6.20588\n",
            "▁yes\t-6.21377\n",
            "▁back\t-6.22989\n",
            "▁d\t-6.23892\n",
            "▁his\t-6.24827\n",
            "n\t-6.25315\n",
            "▁man\t-6.25455\n",
            "▁when\t-6.26481\n",
            "▁okay\t-6.27249\n",
            "▁time\t-6.27638\n",
            "▁could\t-6.28472\n",
            "▁take\t-6.30417\n",
            "▁hey\t-6.31565\n",
            "▁say\t-6.35372\n",
            "▁had\t-6.37539\n",
            "▁an\t-6.37643\n",
            "▁us\t-6.38685\n",
            "▁or\t-6.38714\n",
            "▁were\t-6.38932\n",
            "▁some\t-6.39201\n",
            "▁where\t-6.39465\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yBsURk_h5jw4",
        "colab_type": "code",
        "outputId": "80b23dbe-86e3-4609-9ccd-7037d2740949",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "def read_sentencepiece_vocab(filepath):\n",
        "  voc = []\n",
        "  with open(filepath, encoding='utf-8') as fi:\n",
        "    for line in fi:\n",
        "      voc.append(line.split(\"\\t\")[0])\n",
        "  # skip the first <unk> token\n",
        "  voc = voc[1:]\n",
        "  return voc\n",
        "\n",
        "snt_vocab = read_sentencepiece_vocab(\"{}.vocab\".format(MODEL_PREFIX))\n",
        "print(\"Learnt vocab size: {}\".format(len(snt_vocab)))\n",
        "print(\"Sample tokens: {}\".format(random.sample(snt_vocab, 10)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Learnt vocab size: 31743\n",
            "Sample tokens: ['▁beth', '▁voice', '▁hologram', '▁condom', '▁hail', '▁regret', '▁satir', '▁entering', '▁admit', '▁marion']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lJPtxrtz5470",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3YjqHVRpmlKq",
        "colab_type": "text"
      },
      "source": [
        "As we may observe, SentencePiece does quite the opposite to WordPiece. From the [documentation](https://github.com/google/sentencepiece/blob/master/README.md):\n",
        "\n",
        "\n",
        "SentencePiece first escapes the whitespace with a meta-symbol \"▁\" (U+2581) as follows:\n",
        "\n",
        "`Hello▁World`.\n",
        "\n",
        "Then, this text is segmented into small pieces, for example:\n",
        "\n",
        "`[Hello] [▁Wor] [ld] [.]`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OD-28l_0p0PQ",
        "colab_type": "text"
      },
      "source": [
        "Subwords which occur after whitespace (which are also those that most words begin with) are prepended with '▁', while others are unchanged. This excludes subwords which only occur at the beginning of sentences and nowhere else. These cases should be quite rare, however. \n",
        "\n",
        "So, in order to obtain a vocabulary analogous to WordPiece, we need to perform a simple conversion, removing \"▁\" from the tokens that contain it and adding \"##\"  to the ones that don't."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5QJGFjzOMbfN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def parse_sentencepiece_token(token):\n",
        "    if token.startswith(\"▁\"):\n",
        "        return token[1:]\n",
        "    else:\n",
        "        return \"##\" + token"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "64dcVgD98S28",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bert_vocab = list(map(parse_sentencepiece_token, snt_vocab))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mL9ZR3RN9IMA",
        "colab_type": "text"
      },
      "source": [
        "We also add some special control symbols which are required by the BERT architecture. By convention, we put those at the beginning of the vocabulary."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VdTlXDPL8cHE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ctrl_symbols = [\"[PAD]\",\"[UNK]\",\"[CLS]\",\"[SEP]\",\"[MASK]\"]\n",
        "bert_vocab = ctrl_symbols + bert_vocab"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ry1jvEr9EIdd",
        "colab_type": "text"
      },
      "source": [
        "We also append some placeholder tokens to the vocabulary. Those are useful if one wishes to update the pre-trained model with new, task-specific tokens. \n",
        "\n",
        "In that case, the placeholder tokens are replaced with new real ones, the pre-training data is re-generated, and the model is fine-tuned on new data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XLYSTil4E0Dm",
        "colab_type": "code",
        "outputId": "2c5d823e-6603-40f6-b43c-0810d0594500",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "bert_vocab += [\"[UNUSED_{}]\".format(i) for i in range(VOC_SIZE - len(bert_vocab))]\n",
        "print(len(bert_vocab))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "32000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qJKk_7JI-MtW",
        "colab_type": "text"
      },
      "source": [
        "Finally, we write the obtained vocabulary to file."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8G1jg0cj9Duf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "VOC_FNAME = \"vocab.txt\" #@param {type:\"string\"}\n",
        "\n",
        "with open(VOC_FNAME, \"w\") as fo:\n",
        "  for token in bert_vocab:\n",
        "    fo.write(token+\"\\n\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u5fs7H049nB8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1MqXZnc3FCuY",
        "colab_type": "text"
      },
      "source": [
        "Now let's see how the new vocabulary works in practice:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xsSOnEnC-jG1",
        "colab_type": "code",
        "outputId": "d2c8aeaa-cb8a-4e17-d853-55ea1edcc0e3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "bert_tokenizer = tokenization.FullTokenizer(VOC_FNAME)\n",
        "bert_tokenizer.tokenize(testcase)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['color',\n",
              " '##less',\n",
              " 'geo',\n",
              " '##ther',\n",
              " '##mal',\n",
              " 'subs',\n",
              " '##tation',\n",
              " '##s',\n",
              " 'are',\n",
              " 'generat',\n",
              " '##ing',\n",
              " 'furious',\n",
              " '##ly']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RN8xDNfF0Q2q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DauD8ndhEA-z",
        "colab_type": "text"
      },
      "source": [
        "Looking good!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EwFtStCo__QX",
        "colab_type": "text"
      },
      "source": [
        "## Step 5: generating pre-training data\n",
        "\n",
        "With the vocabulary at hand, we are ready to generate pre-training data for the BERT model. Since our dataset might be quite large, we will split it into shards:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xyN1nI04-uKV",
        "colab_type": "code",
        "outputId": "b5f83572-7cd4-4a63-e03d-7a3669ea2101",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!mkdir ./shards\n",
        "!split -a 4 -l 256000 -d $PRC_DATA_FPATH ./shards/shard_\n",
        "!ls ./shards/"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "shard_0000  shard_0001\tshard_0002  shard_0003\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w-FSq3zNFvLs",
        "colab_type": "text"
      },
      "source": [
        "Before we start generating, we need to set some model-specific parameters.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UnZcD0yIBGPd",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "MAX_SEQ_LENGTH = 128 #@param {type:\"integer\"}\n",
        "MASKED_LM_PROB = 0.15 #@param\n",
        "MAX_PREDICTIONS = 20 #@param {type:\"integer\"}\n",
        "DO_LOWER_CASE = True #@param {type:\"boolean\"}\n",
        "PROCESSES = 2 #@param {type:\"integer\"}\n",
        "PRETRAINING_DIR = \"pretraining_data\" #@param {type:\"string\"}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k-MibOBkFam2",
        "colab_type": "text"
      },
      "source": [
        "Now, for each shard we need to call *create_pretraining_data.py* script. To that end, we will employ the  *xargs* command. \n",
        "\n",
        "Running this might take quite some time depending on the size of your dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YbZjIeVP0T36",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "XARGS_CMD = (\"ls ./shards/ | \"\n",
        "             \"xargs -n 1 -P {} -I{} \"\n",
        "             \"python3 bert/create_pretraining_data.py \"\n",
        "             \"--input_file=./shards/{} \"\n",
        "             \"--output_file={}/{}.tfrecord \"\n",
        "             \"--vocab_file={} \"\n",
        "             \"--do_lower_case={} \"\n",
        "             \"--max_predictions_per_seq={} \"\n",
        "             \"--max_seq_length={} \"\n",
        "             \"--masked_lm_prob={} \"\n",
        "             \"--random_seed=34 \"\n",
        "             \"--dupe_factor=5\")\n",
        "\n",
        "XARGS_CMD = XARGS_CMD.format(PROCESSES, '{}', '{}', PRETRAINING_DIR, '{}', \n",
        "                             VOC_FNAME, DO_LOWER_CASE, \n",
        "                             MAX_PREDICTIONS, MAX_SEQ_LENGTH, MASKED_LM_PROB)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fyo9_LcQ0pla",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u5XzaY8xCdiV",
        "colab_type": "code",
        "outputId": "e1caa4ec-dfba-44c3-dcf2-471c39cc5386",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "tf.gfile.MkDir(PRETRAINING_DIR)\n",
        "!$XARGS_CMD"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From bert/create_pretraining_data.py:469: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.\n",
            "\n",
            "WARNING:tensorflow:From bert/create_pretraining_data.py:469: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.\n",
            "\n",
            "WARNING:tensorflow:From bert/create_pretraining_data.py:437: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.\n",
            "\n",
            "W0918 12:31:07.421359 140304780035968 deprecation_wrapper.py:119] From bert/create_pretraining_data.py:437: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.\n",
            "\n",
            "WARNING:tensorflow:From bert/create_pretraining_data.py:437: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.\n",
            "\n",
            "W0918 12:31:07.421587 140061523146624 deprecation_wrapper.py:119] From bert/create_pretraining_data.py:437: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.\n",
            "\n",
            "WARNING:tensorflow:From bert/create_pretraining_data.py:437: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.\n",
            "\n",
            "W0918 12:31:07.422145 140304780035968 deprecation_wrapper.py:119] From bert/create_pretraining_data.py:437: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.\n",
            "\n",
            "WARNING:tensorflow:From bert/create_pretraining_data.py:437: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/bert/tokenization.py:125: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "W0918 12:31:07.422334 140061523146624 deprecation_wrapper.py:119] From bert/create_pretraining_data.py:437: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.\n",
            "\n",
            "\n",
            "W0918 12:31:07.422415 140304780035968 deprecation_wrapper.py:119] From /content/bert/tokenization.py:125: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/bert/tokenization.py:125: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n",
            "W0918 12:31:07.422595 140061523146624 deprecation_wrapper.py:119] From /content/bert/tokenization.py:125: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n",
            "WARNING:tensorflow:From bert/create_pretraining_data.py:444: The name tf.gfile.Glob is deprecated. Please use tf.io.gfile.glob instead.\n",
            "\n",
            "W0918 12:31:07.587536 140304780035968 deprecation_wrapper.py:119] From bert/create_pretraining_data.py:444: The name tf.gfile.Glob is deprecated. Please use tf.io.gfile.glob instead.\n",
            "\n",
            "WARNING:tensorflow:From bert/create_pretraining_data.py:444: The name tf.gfile.Glob is deprecated. Please use tf.io.gfile.glob instead.\n",
            "\n",
            "W0918 12:31:07.590197 140061523146624 deprecation_wrapper.py:119] From bert/create_pretraining_data.py:444: The name tf.gfile.Glob is deprecated. Please use tf.io.gfile.glob instead.\n",
            "\n",
            "WARNING:tensorflow:From bert/create_pretraining_data.py:446: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n",
            "\n",
            "W0918 12:31:07.594781 140304780035968 deprecation_wrapper.py:119] From bert/create_pretraining_data.py:446: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n",
            "\n",
            "INFO:tensorflow:*** Reading from input files ***\n",
            "I0918 12:31:07.595087 140304780035968 create_pretraining_data.py:446] *** Reading from input files ***\n",
            "INFO:tensorflow:  ./shards/shard_0000\n",
            "I0918 12:31:07.595183 140304780035968 create_pretraining_data.py:448]   ./shards/shard_0000\n",
            "WARNING:tensorflow:From bert/create_pretraining_data.py:446: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n",
            "\n",
            "W0918 12:31:07.597430 140061523146624 deprecation_wrapper.py:119] From bert/create_pretraining_data.py:446: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n",
            "\n",
            "INFO:tensorflow:*** Reading from input files ***\n",
            "I0918 12:31:07.597797 140061523146624 create_pretraining_data.py:446] *** Reading from input files ***\n",
            "INFO:tensorflow:  ./shards/shard_0001\n",
            "I0918 12:31:07.597925 140061523146624 create_pretraining_data.py:448]   ./shards/shard_0001\n",
            "INFO:tensorflow:*** Writing to output files ***\n",
            "I0918 12:32:58.249080 140304780035968 create_pretraining_data.py:457] *** Writing to output files ***\n",
            "INFO:tensorflow:  pretraining_data/shard_0000.tfrecord\n",
            "I0918 12:32:58.249498 140304780035968 create_pretraining_data.py:459]   pretraining_data/shard_0000.tfrecord\n",
            "WARNING:tensorflow:From bert/create_pretraining_data.py:101: The name tf.python_io.TFRecordWriter is deprecated. Please use tf.io.TFRecordWriter instead.\n",
            "\n",
            "W0918 12:32:58.249802 140304780035968 deprecation_wrapper.py:119] From bert/create_pretraining_data.py:101: The name tf.python_io.TFRecordWriter is deprecated. Please use tf.io.TFRecordWriter instead.\n",
            "\n",
            "INFO:tensorflow:*** Example ***\n",
            "I0918 12:32:58.251384 140304780035968 create_pretraining_data.py:149] *** Example ***\n",
            "INFO:tensorflow:tokens: [CLS] no it [MASK] her birthday [SEP] you [MASK] sung happy birthday to 20 women [MASK] [SEP]\n",
            "I0918 12:32:58.251689 140304780035968 create_pretraining_data.py:151] tokens: [CLS] no it [MASK] her birthday [SEP] you [MASK] sung happy birthday to 20 women [MASK] [SEP]\n",
            "INFO:tensorflow:input_ids: 2 23 11 4 68 735 3 5 4 10213 294 735 9 577 449 4 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0918 12:32:58.251905 140304780035968 create_pretraining_data.py:161] input_ids: 2 23 11 4 68 735 3 5 4 10213 294 735 9 577 449 4 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0918 12:32:58.252096 140304780035968 create_pretraining_data.py:161] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0918 12:32:58.252269 140304780035968 create_pretraining_data.py:161] segment_ids: 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:masked_lm_positions: 3 8 15 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0918 12:32:58.252384 140304780035968 create_pretraining_data.py:161] masked_lm_positions: 3 8 15 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:masked_lm_ids: 8 73 287 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0918 12:32:58.252495 140304780035968 create_pretraining_data.py:161] masked_lm_ids: 8 73 287 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:masked_lm_weights: 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
            "I0918 12:32:58.252636 140304780035968 create_pretraining_data.py:161] masked_lm_weights: 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
            "INFO:tensorflow:next_sentence_labels: 0\n",
            "I0918 12:32:58.252759 140304780035968 create_pretraining_data.py:161] next_sentence_labels: 0\n",
            "INFO:tensorflow:*** Example ***\n",
            "I0918 12:32:58.253516 140304780035968 create_pretraining_data.py:149] *** Example ***\n",
            "INFO:tensorflow:tokens: [CLS] [MASK] know what they say about a kid in short pants short pants [MASK] dick fuck off my thumbs are twice as big as yours bullshit who s got the biggest dick now runt you do ##ultures i am ii [MASK] nobody s bigger graphics [MASK] ooh renato s [MASK] school shh you come here [MASK] need some cigarettes [MASK] cigarettes do you want maced ##onia extra [SEP] malcolm kareem can [MASK] hear me [SEP]\n",
            "I0918 12:32:58.253739 140304780035968 create_pretraining_data.py:151] tokens: [CLS] [MASK] know what they say about a kid in short pants short pants [MASK] dick fuck off my thumbs are twice as big as yours bullshit who s got the biggest dick now runt you do ##ultures i am ii [MASK] nobody s bigger graphics [MASK] ooh renato s [MASK] school shh you come here [MASK] need some cigarettes [MASK] cigarettes do you want maced ##onia extra [SEP] malcolm kareem can [MASK] hear me [SEP]\n",
            "INFO:tensorflow:input_ids: 2 4 36 16 49 96 62 10 383 19 684 813 684 813 4 936 275 125 25 2326 38 1066 83 148 83 506 1189 75 8 63 7 1851 936 65 2443 5 31 15370 6 139 1717 4 425 8 1090 8514 4 616 1560 8 4 361 977 5 58 45 4 128 102 2508 4 2508 31 5 72 6590 6866 1406 3 1275 4512 34 4 240 18 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0918 12:32:58.253944 140304780035968 create_pretraining_data.py:161] input_ids: 2 4 36 16 49 96 62 10 383 19 684 813 684 813 4 936 275 125 25 2326 38 1066 83 148 83 506 1189 75 8 63 7 1851 936 65 2443 5 31 15370 6 139 1717 4 425 8 1090 8514 4 616 1560 8 4 361 977 5 58 45 4 128 102 2508 4 2508 31 5 72 6590 6866 1406 3 1275 4512 34 4 240 18 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0918 12:32:58.254111 140304780035968 create_pretraining_data.py:161] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0918 12:32:58.254278 140304780035968 create_pretraining_data.py:161] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:masked_lm_positions: 1 14 37 41 45 46 50 56 60 67 72 0 0 0 0 0 0 0 0 0\n",
            "I0918 12:32:58.254389 140304780035968 create_pretraining_data.py:161] masked_lm_positions: 1 14 37 41 45 46 50 56 60 67 72 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:masked_lm_ids: 5 684 23 1947 197 18 6247 6 16 1406 5 0 0 0 0 0 0 0 0 0\n",
            "I0918 12:32:58.254496 140304780035968 create_pretraining_data.py:161] masked_lm_ids: 5 684 23 1947 197 18 6247 6 16 1406 5 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
            "I0918 12:32:58.254609 140304780035968 create_pretraining_data.py:161] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
            "INFO:tensorflow:next_sentence_labels: 1\n",
            "I0918 12:32:58.254747 140304780035968 create_pretraining_data.py:161] next_sentence_labels: 1\n",
            "INFO:tensorflow:*** Example ***\n",
            "I0918 12:32:58.255454 140304780035968 create_pretraining_data.py:149] *** Example ***\n",
            "INFO:tensorflow:tokens: [CLS] what a wonderful creature you are my love oh my love you ve taken my heart your beauty overwhelm ##s [MASK] l m spellbound [MASK] love for the first time [MASK] love come touch my heart [SEP] yamamura sadako will take the part that s all hey mr shigemori why her ignore them ok [MASK] hello hello who is this beige [MASK] you never speak andrei anna is [MASK] you anna do [MASK] [MASK] what will happen [SEP]\n",
            "I0918 12:32:58.255654 140304780035968 create_pretraining_data.py:151] tokens: [CLS] what a wonderful creature you are my love oh my love you ve taken my heart your beauty overwhelm ##s [MASK] l m spellbound [MASK] love for the first time [MASK] love come touch my heart [SEP] yamamura sadako will take the part that s all hey mr shigemori why her ignore them ok [MASK] hello hello who is this beige [MASK] you never speak andrei anna is [MASK] you anna do [MASK] [MASK] what will happen [SEP]\n",
            "INFO:tensorflow:input_ids: 2 16 10 598 2889 5 38 25 113 56 25 113 5 73 741 25 331 27 863 9260 57 4 233 26 21523 4 113 28 7 175 92 4 113 58 552 25 331 3 4578 792 79 94 7 399 14 8 40 95 209 3035 78 68 4208 105 192 4 212 212 75 17 22 15603 4 5 117 523 7707 848 17 4 5 848 31 4 4 16 79 436 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0918 12:32:58.255822 140304780035968 create_pretraining_data.py:161] input_ids: 2 16 10 598 2889 5 38 25 113 56 25 113 5 73 741 25 331 27 863 9260 57 4 233 26 21523 4 113 28 7 175 92 4 113 58 552 25 331 3 4578 792 79 94 7 399 14 8 40 95 209 3035 78 68 4208 105 192 4 212 212 75 17 22 15603 4 5 117 523 7707 848 17 4 5 848 31 4 4 16 79 436 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0918 12:32:58.255959 140304780035968 create_pretraining_data.py:161] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0918 12:32:58.256095 140304780035968 create_pretraining_data.py:161] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:masked_lm_positions: 5 11 21 25 31 32 55 61 62 69 73 74 0 0 0 0 0 0 0 0\n",
            "I0918 12:32:58.256196 140304780035968 create_pretraining_data.py:161] masked_lm_positions: 5 11 21 25 31 32 55 61 62 69 73 74 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:masked_lm_ids: 5 113 18 25 25 113 1466 78 31 14 5 36 0 0 0 0 0 0 0 0\n",
            "I0918 12:32:58.256302 140304780035968 create_pretraining_data.py:161] masked_lm_ids: 5 113 18 25 25 113 1466 78 31 14 5 36 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
            "I0918 12:32:58.256409 140304780035968 create_pretraining_data.py:161] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
            "INFO:tensorflow:next_sentence_labels: 1\n",
            "I0918 12:32:58.256515 140304780035968 create_pretraining_data.py:161] next_sentence_labels: 1\n",
            "INFO:tensorflow:*** Example ***\n",
            "I0918 12:32:58.257188 140304780035968 create_pretraining_data.py:149] *** Example ***\n",
            "INFO:tensorflow:tokens: [CLS] can t save up more money [MASK] s over now gene doesn t even turn 1 3 until [MASK] christmas it was 2 [UNK] and 1 0 cents in the tin i can t count it now but i trust you and [MASK] s 30 i [MASK] [MASK] which makes it 2 [UNK] and 1 0 cents it s not enough but it ll have to do selma bye bill selma selma stop i [MASK] [MASK] my gun [MASK] [MASK] selma i [MASK] t believe you [MASK] re [MASK] [MASK] to scare me i can [MASK] see a gun selma just [MASK] this feel [MASK] just feel it [SEP] feel it do you believe i have the gun i believe you [MASK] it s my money [SEP]\n",
            "I0918 12:32:58.257400 140304780035968 create_pretraining_data.py:151] tokens: [CLS] can t save up more money [MASK] s over now gene doesn t even turn 1 3 until [MASK] christmas it was 2 [UNK] and 1 0 cents in the tin i can t count it now but i trust you and [MASK] s 30 i [MASK] [MASK] which makes it 2 [UNK] and 1 0 cents it s not enough but it ll have to do selma bye bill selma selma stop i [MASK] [MASK] my gun [MASK] [MASK] selma i [MASK] t believe you [MASK] re [MASK] [MASK] to scare me i can [MASK] see a gun selma just [MASK] this feel [MASK] just feel it [SEP] feel it do you believe i have the gun i believe you [MASK] it s my money [SEP]\n",
            "INFO:tensorflow:input_ids: 2 34 12 497 51 129 188 4 8 120 65 802 208 12 142 289 204 437 412 4 1341 11 35 346 1 13 204 573 3023 19 7 14377 6 34 12 861 11 65 42 6 493 5 13 4 8 681 6 4 4 273 472 11 346 1 13 204 573 3023 11 8 39 235 42 11 47 29 9 31 397 347 629 397 397 168 6 4 4 25 461 4 4 397 6 4 12 223 5 4 33 4 4 9 1479 18 6 34 4 77 10 461 397 46 4 22 199 4 46 199 11 3 199 11 31 5 223 6 29 7 461 6 223 5 4 11 8 25 188 3\n",
            "I0918 12:32:58.257595 140304780035968 create_pretraining_data.py:161] input_ids: 2 34 12 497 51 129 188 4 8 120 65 802 208 12 142 289 204 437 412 4 1341 11 35 346 1 13 204 573 3023 19 7 14377 6 34 12 861 11 65 42 6 493 5 13 4 8 681 6 4 4 273 472 11 346 1 13 204 573 3023 11 8 39 235 42 11 47 29 9 31 397 347 629 397 397 168 6 4 4 25 461 4 4 397 6 4 12 223 5 4 33 4 4 9 1479 18 6 34 4 77 10 461 397 46 4 22 199 4 46 199 11 3 199 11 31 5 223 6 29 7 461 6 223 5 4 11 8 25 188 3\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0918 12:32:58.257786 140304780035968 create_pretraining_data.py:161] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0918 12:32:58.257944 140304780035968 create_pretraining_data.py:161] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:masked_lm_positions: 7 19 33 43 45 47 48 75 76 79 80 83 87 89 90 96 102 105 122 0\n",
            "I0918 12:32:58.258054 140304780035968 create_pretraining_data.py:161] masked_lm_positions: 7 19 33 43 45 47 48 75 76 79 80 83 87 89 90 96 102 105 122 0\n",
            "INFO:tensorflow:masked_lm_ids: 14 202 34 11 681 63 287 26 6864 64 5 30 5 46 329 12 199 22 42 0\n",
            "I0918 12:32:58.258160 140304780035968 create_pretraining_data.py:161] masked_lm_ids: 14 202 34 11 681 63 287 26 6864 64 5 30 5 46 329 12 199 22 42 0\n",
            "INFO:tensorflow:masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0\n",
            "I0918 12:32:58.258285 140304780035968 create_pretraining_data.py:161] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0\n",
            "INFO:tensorflow:next_sentence_labels: 0\n",
            "I0918 12:32:58.258388 140304780035968 create_pretraining_data.py:161] next_sentence_labels: 0\n",
            "INFO:tensorflow:*** Example ***\n",
            "I0918 12:32:58.259089 140304780035968 create_pretraining_data.py:149] *** Example ***\n",
            "INFO:tensorflow:tokens: [CLS] the back the seal the pyramid it [MASK] unfinished with the eye of god looking over it and the words [MASK] god favors our undertaking the seal is meant to be unfinished because this country is we [MASK] meant to keep [MASK] [MASK] [MASK] keep debating we re meant to read books [MASK] great scholars and talk about them which is why [MASK] [MASK] my name to a [MASK] cover i wanna be [MASK] assistant attorney general for [SEP] no it s more than one man who died in the last 12 years everyone who was there has died not one [MASK] [MASK] reporters at that demonstration is alive today [MASK] [MASK] have any idea [MASK] dr lkuma might be no 0 ##r his daughter sadako [SEP]\n",
            "I0918 12:32:58.259315 140304780035968 create_pretraining_data.py:151] tokens: [CLS] the back the seal the pyramid it [MASK] unfinished with the eye of god looking over it and the words [MASK] god favors our undertaking the seal is meant to be unfinished because this country is we [MASK] meant to keep [MASK] [MASK] [MASK] keep debating we re meant to read books [MASK] great scholars and talk about them which is why [MASK] [MASK] my name to a [MASK] cover i wanna be [MASK] assistant attorney general for [SEP] no it s more than one man who died in the last 12 years everyone who was there has died not one [MASK] [MASK] reporters at that demonstration is alive today [MASK] [MASK] have any idea [MASK] dr lkuma might be no 0 ##r his daughter sadako [SEP]\n",
            "INFO:tensorflow:input_ids: 2 7 85 7 2549 7 18160 11 4 14806 41 7 671 15 137 280 120 11 13 7 713 4 137 12717 114 14869 7 2549 17 896 9 37 14806 134 22 692 17 20 4 896 9 179 4 4 4 179 19917 20 33 896 9 447 925 4 167 7668 13 172 62 105 273 17 78 4 4 25 187 9 10 4 947 6 243 37 4 2813 3084 1549 28 3 23 11 8 129 197 61 89 75 575 19 7 200 905 213 405 75 35 50 126 575 39 61 4 4 7734 64 14 6549 17 591 287 4 4 29 152 328 4 473 5677 272 37 23 573 440 87 515 792 3\n",
            "I0918 12:32:58.259509 140304780035968 create_pretraining_data.py:161] input_ids: 2 7 85 7 2549 7 18160 11 4 14806 41 7 671 15 137 280 120 11 13 7 713 4 137 12717 114 14869 7 2549 17 896 9 37 14806 134 22 692 17 20 4 896 9 179 4 4 4 179 19917 20 33 896 9 447 925 4 167 7668 13 172 62 105 273 17 78 4 4 25 187 9 10 4 947 6 243 37 4 2813 3084 1549 28 3 23 11 8 129 197 61 89 75 575 19 7 200 905 213 405 75 35 50 126 575 39 61 4 4 7734 64 14 6549 17 591 287 4 4 29 152 328 4 473 5677 272 37 23 573 440 87 515 792 3\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0918 12:32:58.300862 140304780035968 create_pretraining_data.py:161] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0918 12:32:58.301174 140304780035968 create_pretraining_data.py:161] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:masked_lm_positions: 8 21 38 42 43 44 51 53 57 63 64 69 74 102 103 111 112 116 119 0\n",
            "I0918 12:32:58.301397 140304780035968 create_pretraining_data.py:161] masked_lm_positions: 8 21 38 42 43 44 51 53 57 63 64 69 74 102 103 111 112 116 119 0\n",
            "INFO:tensorflow:masked_lm_ids: 8 21 33 145 182 9 447 119 172 6 6729 2946 27 15 7 31 5 103 272 0\n",
            "I0918 12:32:58.301562 140304780035968 create_pretraining_data.py:161] masked_lm_ids: 8 21 33 145 182 9 447 119 172 6 6729 2946 27 15 7 31 5 103 272 0\n",
            "INFO:tensorflow:masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0\n",
            "I0918 12:32:58.301760 140304780035968 create_pretraining_data.py:161] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0\n",
            "INFO:tensorflow:next_sentence_labels: 1\n",
            "I0918 12:32:58.301898 140304780035968 create_pretraining_data.py:161] next_sentence_labels: 1\n",
            "INFO:tensorflow:*** Example ***\n",
            "I0918 12:32:58.302829 140304780035968 create_pretraining_data.py:149] *** Example ***\n",
            "INFO:tensorflow:tokens: [CLS] 0 ##ne swimming class they went to the beach sadako was simply terrified lf you go in the sea you ll all [MASK] she said [SEP] i never said [MASK] [MASK] didn t say [MASK] [MASK] [MASK] [MASK] it it was just a joke were ##n t it faith she [MASK] [MASK] all right dad come and [MASK] down she ll be all right [SEP]\n",
            "I0918 12:32:58.303036 140304780035968 create_pretraining_data.py:151] tokens: [CLS] 0 ##ne swimming class they went to the beach sadako was simply terrified lf you go in the sea you ll all [MASK] she said [SEP] i never said [MASK] [MASK] didn t say [MASK] [MASK] [MASK] [MASK] it it was just a joke were ##n t it faith she [MASK] [MASK] all right dad come and [MASK] down she ll be all right [SEP]\n",
            "INFO:tensorflow:input_ids: 2 573 2334 3750 881 49 250 9 7 1195 792 35 1499 4246 1800 5 52 19 7 778 5 47 40 4 53 135 3 6 117 135 4 4 112 12 96 4 4 4 4 11 11 35 46 10 1029 101 88 12 11 1200 53 4 4 40 54 216 58 13 4 115 53 47 37 40 54 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0918 12:32:58.303232 140304780035968 create_pretraining_data.py:161] input_ids: 2 573 2334 3750 881 49 250 9 7 1195 792 35 1499 4246 1800 5 52 19 7 778 5 47 40 4 53 135 3 6 117 135 4 4 112 12 96 4 4 4 4 11 11 35 46 10 1029 101 88 12 11 1200 53 4 4 40 54 216 58 13 4 115 53 47 37 40 54 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0918 12:32:58.303413 140304780035968 create_pretraining_data.py:161] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0918 12:32:58.303588 140304780035968 create_pretraining_data.py:161] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:masked_lm_positions: 23 30 31 35 36 37 38 51 52 58 0 0 0 0 0 0 0 0 0 0\n",
            "I0918 12:32:58.303732 140304780035968 create_pretraining_data.py:161] masked_lm_positions: 23 30 31 35 36 37 38 51 52 58 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:masked_lm_ids: 307 6 6 6 112 12 48 47 37 395 0 0 0 0 0 0 0 0 0 0\n",
            "I0918 12:32:58.303843 140304780035968 create_pretraining_data.py:161] masked_lm_ids: 307 6 6 6 112 12 48 47 37 395 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
            "I0918 12:32:58.303963 140304780035968 create_pretraining_data.py:161] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
            "INFO:tensorflow:next_sentence_labels: 1\n",
            "I0918 12:32:58.304069 140304780035968 create_pretraining_data.py:161] next_sentence_labels: 1\n",
            "INFO:tensorflow:*** Example ***\n",
            "I0918 12:32:58.304812 140304780035968 create_pretraining_data.py:149] *** Example ***\n",
            "INFO:tensorflow:tokens: [CLS] i need [MASK] help [MASK] [MASK] find mr [MASK] in the morning i ll confess no i [MASK] t let them torment [MASK] no it s the only way your hand is hot [SEP] for a while billionaire ##k time for tv [MASK] you cold i ll [MASK] [MASK] a [MASK] of water you wait here is that the [MASK] of [MASK] go get [MASK] sadako go to the dressing room quick where s shigemori he s vanished what do we do we can t cancel we [MASK] go on mr toyama when [MASK] is [MASK] let s go away somewhere don t worry you ll be great you re beautiful we re going to open the doors it s all [MASK] the [MASK] touched him [SEP]\n",
            "I0918 12:32:58.305031 140304780035968 create_pretraining_data.py:151] tokens: [CLS] i need [MASK] help [MASK] [MASK] find mr [MASK] in the morning i ll confess no i [MASK] t let them torment [MASK] no it s the only way your hand is hot [SEP] for a while billionaire ##k time for tv [MASK] you cold i ll [MASK] [MASK] a [MASK] of water you wait here is that the [MASK] of [MASK] go get [MASK] sadako go to the dressing room quick where s shigemori he s vanished what do we do we can t cancel we [MASK] go on mr toyama when [MASK] is [MASK] let s go away somewhere don t worry you ll be great you re beautiful we re going to open the doors it s all [MASK] the [MASK] touched him [SEP]\n",
            "INFO:tensorflow:input_ids: 2 6 128 4 153 4 4 164 209 4 19 7 310 6 47 2918 23 6 4 12 70 105 6516 4 23 11 8 7 130 118 27 371 17 478 3 28 10 327 7332 786 92 28 593 4 5 620 6 47 4 4 10 4 15 333 5 150 45 17 14 7 4 15 4 52 44 4 792 52 9 7 4845 301 888 103 8 3035 21 8 8678 16 31 20 31 20 34 12 2461 20 4 52 24 209 2067 90 4 17 4 70 8 52 163 756 30 12 351 5 47 37 167 5 33 365 20 33 106 9 326 7 2389 11 8 40 4 7 4 2433 60 3\n",
            "I0918 12:32:58.305224 140304780035968 create_pretraining_data.py:161] input_ids: 2 6 128 4 153 4 4 164 209 4 19 7 310 6 47 2918 23 6 4 12 70 105 6516 4 23 11 8 7 130 118 27 371 17 478 3 28 10 327 7332 786 92 28 593 4 5 620 6 47 4 4 10 4 15 333 5 150 45 17 14 7 4 15 4 52 44 4 792 52 9 7 4845 301 888 103 8 3035 21 8 8678 16 31 20 31 20 34 12 2461 20 4 52 24 209 2067 90 4 17 4 70 8 52 163 756 30 12 351 5 47 37 167 5 33 365 20 33 106 9 326 7 2389 11 8 40 4 7 4 2433 60 3\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0918 12:32:58.305392 140304780035968 create_pretraining_data.py:161] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0918 12:32:58.305557 140304780035968 create_pretraining_data.py:161] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:masked_lm_positions: 3 5 6 9 18 23 38 43 48 49 51 60 62 65 88 94 96 122 124 0\n",
            "I0918 12:32:58.305695 140304780035968 create_pretraining_data.py:161] masked_lm_positions: 3 5 6 9 18 23 38 43 48 49 51 60 62 65 88 94 96 122 124 0\n",
            "INFO:tensorflow:masked_lm_ids: 27 49 47 3035 158 5 573 38 44 5 464 362 11 725 47 22 120 54 231 0\n",
            "I0918 12:32:58.305809 140304780035968 create_pretraining_data.py:161] masked_lm_ids: 27 49 47 3035 158 5 573 38 44 5 464 362 11 725 47 22 120 54 231 0\n",
            "INFO:tensorflow:masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0\n",
            "I0918 12:32:58.305923 140304780035968 create_pretraining_data.py:161] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0\n",
            "INFO:tensorflow:next_sentence_labels: 0\n",
            "I0918 12:32:58.306019 140304780035968 create_pretraining_data.py:161] next_sentence_labels: 0\n",
            "INFO:tensorflow:*** Example ***\n",
            "I0918 12:32:58.306682 140304780035968 create_pretraining_data.py:149] *** Example ***\n",
            "INFO:tensorflow:tokens: [CLS] [MASK] [MASK] full of ##hate my brother java foreign guy [SEP] will you sign youryearbook picture [SEP]\n",
            "I0918 12:32:58.306844 140304780035968 create_pretraining_data.py:151] tokens: [CLS] [MASK] [MASK] full of ##hate my brother java foreign guy [SEP] will you sign youryearbook picture [SEP]\n",
            "INFO:tensorflow:input_ids: 2 4 4 481 15 21046 25 286 13126 3071 203 3 79 5 712 21700 696 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0918 12:32:58.307017 140304780035968 create_pretraining_data.py:161] input_ids: 2 4 4 481 15 21046 25 286 13126 3071 203 3 79 5 712 21700 696 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0918 12:32:58.307179 140304780035968 create_pretraining_data.py:161] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0918 12:32:58.307347 140304780035968 create_pretraining_data.py:161] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:masked_lm_positions: 1 2 8 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0918 12:32:58.307464 140304780035968 create_pretraining_data.py:161] masked_lm_positions: 1 2 8 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:masked_lm_ids: 6 139 95 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0918 12:32:58.307577 140304780035968 create_pretraining_data.py:161] masked_lm_ids: 6 139 95 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:masked_lm_weights: 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
            "I0918 12:32:58.307712 140304780035968 create_pretraining_data.py:161] masked_lm_weights: 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
            "INFO:tensorflow:next_sentence_labels: 0\n",
            "I0918 12:32:58.307815 140304780035968 create_pretraining_data.py:161] next_sentence_labels: 0\n",
            "INFO:tensorflow:*** Example ***\n",
            "I0918 12:32:58.308421 140304780035968 create_pretraining_data.py:149] *** Example ***\n",
            "INFO:tensorflow:tokens: [CLS] i know i am [MASK] loves you bill [MASK] verses [MASK] don [MASK] cry i shouldn t have told you don t worry [MASK] s ok i [MASK] t have no [MASK] think you ve got enough stuff would it make you feel better if i told you a secret what [MASK] you tell [MASK] [MASK] m [MASK] blind not yet but soon maybe sometime this [MASK] blind it s not as [SEP] it s a it s a family thing but blind [MASK] ve always known it from from [MASK] was a little [MASK] i knew sniffs and you re ok well i came to america [MASK] in [MASK] they can give gene an operation you know gene but [MASK] doesn t know about it [SEP]\n",
            "I0918 12:32:58.308601 140304780035968 create_pretraining_data.py:151] tokens: [CLS] i know i am [MASK] loves you bill [MASK] verses [MASK] don [MASK] cry i shouldn t have told you don t worry [MASK] s ok i [MASK] t have no [MASK] think you ve got enough stuff would it make you feel better if i told you a secret what [MASK] you tell [MASK] [MASK] m [MASK] blind not yet but soon maybe sometime this [MASK] blind it s not as [SEP] it s a it s a family thing but blind [MASK] ve always known it from from [MASK] was a little [MASK] i knew sniffs and you re ok well i came to america [MASK] in [MASK] they can give gene an operation you know gene but [MASK] doesn t know about it [SEP]\n",
            "INFO:tensorflow:input_ids: 2 6 36 6 139 4 1000 5 629 4 20309 4 30 4 961 6 564 12 29 196 5 30 12 351 4 8 192 6 4 12 29 23 4 74 5 73 63 235 376 107 11 122 5 199 182 59 6 196 5 10 749 16 4 5 104 4 4 26 4 1040 39 411 42 433 155 2575 22 4 1040 11 8 39 83 3 11 8 10 11 8 10 258 143 42 1040 4 73 184 930 11 81 81 4 35 10 111 4 6 313 5892 13 5 33 192 69 6 236 9 970 4 19 4 49 34 131 802 98 1112 5 36 802 42 4 208 12 36 62 11 3\n",
            "I0918 12:32:58.308782 140304780035968 create_pretraining_data.py:161] input_ids: 2 6 36 6 139 4 1000 5 629 4 20309 4 30 4 961 6 564 12 29 196 5 30 12 351 4 8 192 6 4 12 29 23 4 74 5 73 63 235 376 107 11 122 5 199 182 59 6 196 5 10 749 16 4 5 104 4 4 26 4 1040 39 411 42 433 155 2575 22 4 1040 11 8 39 83 3 11 8 10 11 8 10 258 143 42 1040 4 73 184 930 11 81 81 4 35 10 111 4 6 313 5892 13 5 33 192 69 6 236 9 970 4 19 4 49 34 131 802 98 1112 5 36 802 42 4 208 12 36 62 11 3\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0918 12:32:58.308922 140304780035968 create_pretraining_data.py:161] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0918 12:32:58.309045 140304780035968 create_pretraining_data.py:161] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:masked_lm_positions: 5 9 10 11 13 24 28 32 52 55 56 58 67 84 91 95 108 110 121 0\n",
            "I0918 12:32:58.309136 140304780035968 create_pretraining_data.py:161] masked_lm_positions: 5 9 10 11 13 24 28 32 52 55 56 58 67 84 91 95 108 110 121 0\n",
            "INFO:tensorflow:masked_lm_ids: 53 629 6848 477 12 11 564 6 93 18 6 106 422 6 6 231 134 970 21 0\n",
            "I0918 12:32:58.309247 140304780035968 create_pretraining_data.py:161] masked_lm_ids: 53 629 6848 477 12 11 564 6 93 18 6 106 422 6 6 231 134 970 21 0\n",
            "INFO:tensorflow:masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0\n",
            "I0918 12:32:58.309371 140304780035968 create_pretraining_data.py:161] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0\n",
            "INFO:tensorflow:next_sentence_labels: 0\n",
            "I0918 12:32:58.309475 140304780035968 create_pretraining_data.py:161] next_sentence_labels: 0\n",
            "INFO:tensorflow:*** Example ***\n",
            "I0918 12:32:58.310119 140304780035968 create_pretraining_data.py:149] *** Example ***\n",
            "INFO:tensorflow:tokens: [CLS] i don t know who i m up against [MASK] the deception don t try to hide [SEP] my [MASK] is boris and this is my family [MASK] sweden is samuel at [MASK] no [MASK] s not behaviour home he had to [MASK] on a little errand for the lord no [SEP]\n",
            "I0918 12:32:58.310294 140304780035968 create_pretraining_data.py:151] tokens: [CLS] i don t know who i m up against [MASK] the deception don t try to hide [SEP] my [MASK] is boris and this is my family [MASK] sweden is samuel at [MASK] no [MASK] s not behaviour home he had to [MASK] on a little errand for the lord no [SEP]\n",
            "INFO:tensorflow:input_ids: 2 6 30 12 36 75 6 26 51 603 4 7 3682 30 12 247 9 794 3 25 4 17 2226 13 22 17 25 258 4 9566 17 2878 64 4 23 4 8 39 4623 174 21 97 9 4 24 10 111 15345 28 7 630 23 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0918 12:32:58.310478 140304780035968 create_pretraining_data.py:161] input_ids: 2 6 30 12 36 75 6 26 51 603 4 7 3682 30 12 247 9 794 3 25 4 17 2226 13 22 17 25 258 4 9566 17 2878 64 4 23 4 8 39 4623 174 21 97 9 4 24 10 111 15345 28 7 630 23 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0918 12:32:58.310657 140304780035968 create_pretraining_data.py:161] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0918 12:32:58.403659 140304780035968 create_pretraining_data.py:161] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:masked_lm_positions: 10 15 20 28 33 35 38 43 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0918 12:32:58.404029 140304780035968 create_pretraining_data.py:161] masked_lm_positions: 10 15 20 28 33 35 38 43 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:masked_lm_ids: 168 247 187 81 174 21 64 218 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0918 12:32:58.404207 140304780035968 create_pretraining_data.py:161] masked_lm_ids: 168 247 187 81 174 21 64 218 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
            "I0918 12:32:58.404379 140304780035968 create_pretraining_data.py:161] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
            "INFO:tensorflow:next_sentence_labels: 1\n",
            "I0918 12:32:58.404526 140304780035968 create_pretraining_data.py:161] next_sentence_labels: 1\n",
            "INFO:tensorflow:*** Example ***\n",
            "I0918 12:32:58.405400 140304780035968 create_pretraining_data.py:149] *** Example ***\n",
            "INFO:tensorflow:tokens: [CLS] wait a minute you re saying debra got ray a dvd player because she wants something from him of course where you been wait that s so [MASK] [MASK] that s not her that s you [MASK] okay [SEP] did you ever think [MASK] that [SEP]\n",
            "I0918 12:32:58.405643 140304780035968 create_pretraining_data.py:151] tokens: [CLS] wait a minute you re saying debra got ray a dvd player because she wants something from him of course where you been wait that s so [MASK] [MASK] that s not her that s you [MASK] okay [SEP] did you ever think [MASK] that [SEP]\n",
            "INFO:tensorflow:input_ids: 2 150 10 457 5 33 341 3206 63 658 10 4405 2808 134 53 401 116 81 60 15 268 103 5 109 150 14 8 43 4 4 14 8 39 68 14 8 5 4 91 3 76 5 225 74 4 14 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0918 12:32:58.405848 140304780035968 create_pretraining_data.py:161] input_ids: 2 150 10 457 5 33 341 3206 63 658 10 4405 2808 134 53 401 116 81 60 15 268 103 5 109 150 14 8 43 4 4 14 8 39 68 14 8 5 4 91 3 76 5 225 74 4 14 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0918 12:32:58.406016 140304780035968 create_pretraining_data.py:161] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0918 12:32:58.406180 140304780035968 create_pretraining_data.py:161] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:masked_lm_positions: 5 28 29 31 37 43 44 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0918 12:32:58.406300 140304780035968 create_pretraining_data.py:161] masked_lm_positions: 5 28 29 31 37 43 44 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:masked_lm_ids: 33 20 24788 8 84 74 62 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0918 12:32:58.406409 140304780035968 create_pretraining_data.py:161] masked_lm_ids: 33 20 24788 8 84 74 62 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
            "I0918 12:32:58.406525 140304780035968 create_pretraining_data.py:161] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
            "INFO:tensorflow:next_sentence_labels: 1\n",
            "I0918 12:32:58.406638 140304780035968 create_pretraining_data.py:161] next_sentence_labels: 1\n",
            "INFO:tensorflow:*** Example ***\n",
            "I0918 12:32:58.407388 140304780035968 create_pretraining_data.py:149] *** Example ***\n",
            "INFO:tensorflow:tokens: [CLS] this is summit team annie garrett [MASK] that you it s elliot [MASK] [MASK] s this mont ##gomer ##y wick how many are you three [MASK] different [MASK] i m with peter garrett i thought [MASK] only climbed solo rescue missions are appreciated what s your jonnie west ridge 23 000 you ##trained have to climb faster tell garrett annie bricks edema [SEP] listen come with me rhythm man [SEP]\n",
            "I0918 12:32:58.407570 140304780035968 create_pretraining_data.py:151] tokens: [CLS] this is summit team annie garrett [MASK] that you it s elliot [MASK] [MASK] s this mont ##gomer ##y wick how many are you three [MASK] different [MASK] i m with peter garrett i thought [MASK] only climbed solo rescue missions are appreciated what s your jonnie west ridge 23 000 you ##trained have to climb faster tell garrett annie bricks edema [SEP] listen come with me rhythm man [SEP]\n",
            "INFO:tensorflow:input_ids: 2 22 17 2396 546 844 1782 4 14 5 11 8 2695 4 4 8 22 3643 3858 221 2011 67 302 38 5 222 4 480 4 6 26 41 799 1782 6 171 4 130 2671 5554 1125 7557 38 10872 16 8 27 19786 994 4830 2863 534 5 21058 29 9 1217 991 104 1782 844 24689 3935 3 229 58 41 18 4079 89 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0918 12:32:58.407776 140304780035968 create_pretraining_data.py:161] input_ids: 2 22 17 2396 546 844 1782 4 14 5 11 8 2695 4 4 8 22 3643 3858 221 2011 67 302 38 5 222 4 480 4 6 26 41 799 1782 6 171 4 130 2671 5554 1125 7557 38 10872 16 8 27 19786 994 4830 2863 534 5 21058 29 9 1217 991 104 1782 844 24689 3935 3 229 58 41 18 4079 89 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0918 12:32:58.407945 140304780035968 create_pretraining_data.py:161] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0918 12:32:58.408108 140304780035968 create_pretraining_data.py:161] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:masked_lm_positions: 7 13 14 26 28 36 40 43 47 53 61 0 0 0 0 0 0 0 0 0\n",
            "I0918 12:32:58.408221 140304780035968 create_pretraining_data.py:161] masked_lm_positions: 7 13 14 26 28 36 40 43 47 53 61 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:masked_lm_ids: 17 1576 75 1916 10522 5 1125 480 2915 47 126 0 0 0 0 0 0 0 0 0\n",
            "I0918 12:32:58.408330 140304780035968 create_pretraining_data.py:161] masked_lm_ids: 17 1576 75 1916 10522 5 1125 480 2915 47 126 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
            "I0918 12:32:58.408443 140304780035968 create_pretraining_data.py:161] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
            "INFO:tensorflow:next_sentence_labels: 1\n",
            "I0918 12:32:58.408540 140304780035968 create_pretraining_data.py:161] next_sentence_labels: 1\n",
            "INFO:tensorflow:*** Example ***\n",
            "I0918 12:32:58.409212 140304780035968 create_pretraining_data.py:149] *** Example ***\n",
            "INFO:tensorflow:tokens: [CLS] not exactly [MASK] [MASK] lovely you like [MASK] of course this couch is just like mine it s not like yours it is [MASK] in punctual bedroom you ll find your clothes your perfumes what are you playing at that s not all look [MASK] the view you like it you particle gone [MASK] far i m going [SEP] his name luis miranda ##dles [MASK] he lives at [UNK] si ##erra de [MASK] ##a he works on monte ##s ura ##les street real blue collar huh all [MASK] make it look like [MASK] robbery no people [MASK] trouble of [MASK] brother no people [MASK] trouble no shit all those who think that [MASK] s unfair need to know that it is ##n t so that life [SEP]\n",
            "I0918 12:32:58.409426 140304780035968 create_pretraining_data.py:151] tokens: [CLS] not exactly [MASK] [MASK] lovely you like [MASK] of course this couch is just like mine it s not like yours it is [MASK] in punctual bedroom you ll find your clothes your perfumes what are you playing at that s not all look [MASK] the view you like it you particle gone [MASK] far i m going [SEP] his name luis miranda ##dles [MASK] he lives at [UNK] si ##erra de [MASK] ##a he works on monte ##s ura ##les street real blue collar huh all [MASK] make it look like [MASK] robbery no people [MASK] trouble of [MASK] brother no people [MASK] trouble no shit all those who think that [MASK] s unfair need to know that it is ##n t so that life [SEP]\n",
            "INFO:tensorflow:input_ids: 2 39 441 4 4 1003 5 48 4 15 268 22 3675 17 46 48 367 11 8 39 48 506 11 17 4 19 21697 2616 5 47 164 27 1015 27 10173 16 38 5 716 64 14 8 39 40 82 4 7 1712 5 48 11 5 18166 330 4 470 6 26 106 3 87 187 4951 4513 28660 4 21 652 64 1 5023 9922 800 4 322 21 853 24 19262 57 31530 8949 664 256 706 3921 227 40 4 122 11 82 48 4 2820 23 138 4 610 15 4 286 23 138 4 610 23 176 40 181 75 74 14 4 8 5185 128 9 36 14 11 17 88 12 43 14 146 3\n",
            "I0918 12:32:58.409607 140304780035968 create_pretraining_data.py:161] input_ids: 2 39 441 4 4 1003 5 48 4 15 268 22 3675 17 46 48 367 11 8 39 48 506 11 17 4 19 21697 2616 5 47 164 27 1015 27 10173 16 38 5 716 64 14 8 39 40 82 4 7 1712 5 48 11 5 18166 330 4 470 6 26 106 3 87 187 4951 4513 28660 4 21 652 64 1 5023 9922 800 4 322 21 853 24 19262 57 31530 8949 664 256 706 3921 227 40 4 122 11 82 48 4 2820 23 138 4 610 15 4 286 23 138 4 610 23 176 40 181 75 74 14 4 8 5185 128 9 36 14 11 17 88 12 43 14 146 3\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0918 12:32:58.409802 140304780035968 create_pretraining_data.py:161] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0918 12:32:58.409974 140304780035968 create_pretraining_data.py:161] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:masked_lm_positions: 3 4 8 24 26 45 52 54 64 65 73 79 88 93 97 100 104 113 122 0\n",
            "I0918 12:32:58.410087 140304780035968 create_pretraining_data.py:161] masked_lm_positions: 3 4 8 24 26 45 52 54 64 65 73 79 88 93 97 100 104 113 122 0\n",
            "INFO:tensorflow:masked_lm_ids: 11 8 11 506 7 64 73 121 2968 579 13259 57 54 10 23 268 23 146 88 0\n",
            "I0918 12:32:58.410193 140304780035968 create_pretraining_data.py:161] masked_lm_ids: 11 8 11 506 7 64 73 121 2968 579 13259 57 54 10 23 268 23 146 88 0\n",
            "INFO:tensorflow:masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0\n",
            "I0918 12:32:58.410308 140304780035968 create_pretraining_data.py:161] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0\n",
            "INFO:tensorflow:next_sentence_labels: 1\n",
            "I0918 12:32:58.410404 140304780035968 create_pretraining_data.py:161] next_sentence_labels: 1\n",
            "INFO:tensorflow:*** Example ***\n",
            "I0918 12:32:58.411052 140304780035968 create_pretraining_data.py:149] *** Example ***\n",
            "INFO:tensorflow:tokens: [CLS] nothing s over if there s hope [MASK] something i should have known you [MASK] come here and i did that [MASK] why i came we re through you re evil [MASK] [MASK] want to see you again help us for old times sake he s lost in the master in pile [SEP] now i [MASK] if i wanted a boyfriend it would be you jeff i just don t want one [MASK] now no problem you know on the back to [MASK] the bike there yeah bye jeff i [MASK] t think it s very [MASK] riding the bike wearing glasses and all [MASK] bye jeff jeff are you ok yeah [MASK] [MASK] fine hi [MASK] hi [MASK] heading home pregnant yes wanna throw that [SEP]\n",
            "I0918 12:32:58.411260 140304780035968 create_pretraining_data.py:151] tokens: [CLS] nothing s over if there s hope [MASK] something i should have known you [MASK] come here and i did that [MASK] why i came we re through you re evil [MASK] [MASK] want to see you again help us for old times sake he s lost in the master in pile [SEP] now i [MASK] if i wanted a boyfriend it would be you jeff i just don t want one [MASK] now no problem you know on the back to [MASK] the bike there yeah bye jeff i [MASK] t think it s very [MASK] riding the bike wearing glasses and all [MASK] bye jeff jeff are you ok yeah [MASK] [MASK] fine hi [MASK] hi [MASK] heading home pregnant yes wanna throw that [SEP]\n",
            "INFO:tensorflow:input_ids: 2 166 8 120 59 50 8 375 4 116 6 133 29 930 5 4 58 45 13 6 76 14 4 78 6 236 20 33 262 5 33 1094 4 4 72 9 77 5 157 153 99 28 186 514 1107 21 8 305 19 7 1167 19 4550 3 65 6 4 59 6 246 10 1098 11 107 37 5 1059 6 46 30 12 72 61 4 65 23 291 5 36 24 7 85 9 4 7 1294 50 66 347 1059 6 4 12 74 11 8 124 4 1973 7 1294 1216 1371 13 40 4 347 1059 1059 38 5 192 66 4 4 230 217 4 217 4 1786 174 1828 84 243 828 14 3\n",
            "I0918 12:32:58.411445 140304780035968 create_pretraining_data.py:161] input_ids: 2 166 8 120 59 50 8 375 4 116 6 133 29 930 5 4 58 45 13 6 76 14 4 78 6 236 20 33 262 5 33 1094 4 4 72 9 77 5 157 153 99 28 186 514 1107 21 8 305 19 7 1167 19 4550 3 65 6 4 59 6 246 10 1098 11 107 37 5 1059 6 46 30 12 72 61 4 65 23 291 5 36 24 7 85 9 4 7 1294 50 66 347 1059 6 4 12 74 11 8 124 4 1973 7 1294 1216 1371 13 40 4 347 1059 1059 38 5 192 66 4 4 230 217 4 217 4 1786 174 1828 84 243 828 14 3\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0918 12:32:58.411605 140304780035968 create_pretraining_data.py:161] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0918 12:32:58.411801 140304780035968 create_pretraining_data.py:161] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:masked_lm_positions: 8 15 22 32 33 56 60 73 83 85 91 97 105 109 113 114 117 119 122 0\n",
            "I0918 12:32:58.411919 140304780035968 create_pretraining_data.py:161] masked_lm_positions: 8 15 22 32 33 56 60 73 83 85 91 97 105 109 113 114 117 119 122 0\n",
            "INFO:tensorflow:masked_lm_ids: 305 86 8 6 117 36 10 54 29 1294 30 589 397 38 6 26 397 629 56 0\n",
            "I0918 12:32:58.412047 140304780035968 create_pretraining_data.py:161] masked_lm_ids: 305 86 8 6 117 36 10 54 29 1294 30 589 397 38 6 26 397 629 56 0\n",
            "INFO:tensorflow:masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0\n",
            "I0918 12:32:58.412166 140304780035968 create_pretraining_data.py:161] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0\n",
            "INFO:tensorflow:next_sentence_labels: 1\n",
            "I0918 12:32:58.412265 140304780035968 create_pretraining_data.py:161] next_sentence_labels: 1\n",
            "INFO:tensorflow:*** Example ***\n",
            "I0918 12:32:58.412919 140304780035968 create_pretraining_data.py:149] *** Example ***\n",
            "INFO:tensorflow:tokens: [CLS] but why he has forest to do ##ukka [MASK] come [MASK] i housewife not [MASK] going [MASK] [MASK] to that i just want to get out of here come on ann sofie no i m not so sure jacob we can t [MASK] tomas here ingar is probably dead by now now we re going to leave [MASK] else in this [MASK] maybe she s [MASK] dead let s do this spinach morning when we wake up all [MASK] of us ##rumbled this goddamn ##ed forest and no more fucking suggestions now let s go home thank you ok short ##est [MASK] takes first watch please can t you just do what i m [SEP] ok it s [MASK] no [MASK] can take the first watch [SEP]\n",
            "I0918 12:32:58.413126 140304780035968 create_pretraining_data.py:151] tokens: [CLS] but why he has forest to do ##ukka [MASK] come [MASK] i housewife not [MASK] going [MASK] [MASK] to that i just want to get out of here come on ann sofie no i m not so sure jacob we can t [MASK] tomas here ingar is probably dead by now now we re going to leave [MASK] else in this [MASK] maybe she s [MASK] dead let s do this spinach morning when we wake up all [MASK] of us ##rumbled this goddamn ##ed forest and no more fucking suggestions now let s go home thank you ok short ##est [MASK] takes first watch please can t you just do what i m [SEP] ok it s [MASK] no [MASK] can take the first watch [SEP]\n",
            "INFO:tensorflow:input_ids: 2 42 78 21 126 3004 9 31 19462 4 58 4 6 7352 39 4 106 4 4 9 14 6 46 72 9 44 55 15 45 58 24 2589 9105 23 6 26 39 43 149 3195 20 34 12 4 5498 45 7101 17 429 244 119 65 65 20 33 106 9 218 4 274 19 22 4 155 53 8 4 244 70 8 31 22 12198 310 90 20 675 51 40 4 15 99 13971 22 648 161 3004 13 23 129 283 8543 65 70 8 52 174 147 5 192 684 986 4 733 175 324 141 34 12 5 46 31 16 6 26 3 192 11 8 4 23 4 34 94 7 175 324 3\n",
            "I0918 12:32:58.520905 140304780035968 create_pretraining_data.py:161] input_ids: 2 42 78 21 126 3004 9 31 19462 4 58 4 6 7352 39 4 106 4 4 9 14 6 46 72 9 44 55 15 45 58 24 2589 9105 23 6 26 39 43 149 3195 20 34 12 4 5498 45 7101 17 429 244 119 65 65 20 33 106 9 218 4 274 19 22 4 155 53 8 4 244 70 8 31 22 12198 310 90 20 675 51 40 4 15 99 13971 22 648 161 3004 13 23 129 283 8543 65 70 8 52 174 147 5 192 684 986 4 733 175 324 141 34 12 5 46 31 16 6 26 3 192 11 8 4 23 4 34 94 7 175 324 3\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0918 12:32:58.522210 140304780035968 create_pretraining_data.py:161] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0918 12:32:58.522599 140304780035968 create_pretraining_data.py:161] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:masked_lm_positions: 5 8 9 11 13 15 17 18 43 58 62 66 72 79 82 102 110 119 121 0\n",
            "I0918 12:32:58.522814 140304780035968 create_pretraining_data.py:161] masked_lm_positions: 5 8 9 11 13 15 17 18 43 58 62 66 72 79 82 102 110 119 121 0\n",
            "INFO:tensorflow:masked_lm_ids: 166 41 22 24 26 142 9 4369 218 249 17970 39 407 393 218 745 46 18 6 0\n",
            "I0918 12:32:58.522945 140304780035968 create_pretraining_data.py:161] masked_lm_ids: 166 41 22 24 26 142 9 4369 218 249 17970 39 407 393 218 745 46 18 6 0\n",
            "INFO:tensorflow:masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0\n",
            "I0918 12:32:58.523083 140304780035968 create_pretraining_data.py:161] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0\n",
            "INFO:tensorflow:next_sentence_labels: 0\n",
            "I0918 12:32:58.523191 140304780035968 create_pretraining_data.py:161] next_sentence_labels: 0\n",
            "INFO:tensorflow:*** Example ***\n",
            "I0918 12:32:58.524117 140304780035968 create_pretraining_data.py:149] *** Example ***\n",
            "INFO:tensorflow:tokens: [CLS] intonation are you staring at [SEP] [MASK] s more than one man who died in [MASK] last 12 years everyone who was there has [MASK] not one of the [MASK] at that demonstration is alive wholeheartedly do you have any idea where dr lkuma [MASK] be no 0 ##r his daughter sadako i don t know so we don t even know yet when the funeral ##cooperative be [SEP]\n",
            "I0918 12:32:58.524339 140304780035968 create_pretraining_data.py:151] tokens: [CLS] intonation are you staring at [SEP] [MASK] s more than one man who died in [MASK] last 12 years everyone who was there has [MASK] not one of the [MASK] at that demonstration is alive wholeheartedly do you have any idea where dr lkuma [MASK] be no 0 ##r his daughter sadako i don t know so we don t even know yet when the funeral ##cooperative be [SEP]\n",
            "INFO:tensorflow:input_ids: 2 21703 38 5 2291 64 3 4 8 129 197 61 89 75 575 19 4 200 905 213 405 75 35 50 126 4 39 61 15 7 4 64 14 6549 17 591 15419 31 5 29 152 328 103 473 5677 4 37 23 573 440 87 515 792 6 30 12 36 43 20 30 12 142 36 411 90 7 2056 29824 37 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0918 12:32:58.524523 140304780035968 create_pretraining_data.py:161] input_ids: 2 21703 38 5 2291 64 3 4 8 129 197 61 89 75 575 19 4 200 905 213 405 75 35 50 126 4 39 61 15 7 4 64 14 6549 17 591 15419 31 5 29 152 328 103 473 5677 4 37 23 573 440 87 515 792 6 30 12 36 43 20 30 12 142 36 411 90 7 2056 29824 37 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0918 12:32:58.524719 140304780035968 create_pretraining_data.py:161] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0918 12:32:58.524901 140304780035968 create_pretraining_data.py:161] segment_ids: 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:masked_lm_positions: 1 7 16 20 25 30 36 45 63 67 0 0 0 0 0 0 0 0 0 0\n",
            "I0918 12:32:58.525016 140304780035968 create_pretraining_data.py:161] masked_lm_positions: 1 7 16 20 25 30 36 45 63 67 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:masked_lm_ids: 16 11 7 405 575 7734 287 272 411 79 0 0 0 0 0 0 0 0 0 0\n",
            "I0918 12:32:58.525126 140304780035968 create_pretraining_data.py:161] masked_lm_ids: 16 11 7 405 575 7734 287 272 411 79 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
            "I0918 12:32:58.525242 140304780035968 create_pretraining_data.py:161] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
            "INFO:tensorflow:next_sentence_labels: 1\n",
            "I0918 12:32:58.525342 140304780035968 create_pretraining_data.py:161] next_sentence_labels: 1\n",
            "INFO:tensorflow:*** Example ***\n",
            "I0918 12:32:58.526116 140304780035968 create_pretraining_data.py:149] *** Example ***\n",
            "INFO:tensorflow:tokens: [CLS] thank you [MASK] what s all the [MASK] [SEP] a vampire in the lobby did i hear that right never a dull [MASK] we re done get out now can you believe this it s a sweep [MASK] ll never make [MASK] [MASK] what is it [MASK] readers shouldn [MASK] we have been memo ##ed [MASK] s [MASK] [MASK] re [MASK] random mind readings [MASK] s lil ##ah it looks like i won t be able [MASK] make the 1 00 great overboard [MASK] to say this is a shame it s just a shame whenever i hear of disloyal ##ty it hurts me saying [MASK] personally but this sort of thing must be deal ##t with quickly and cleanly and una ##mb ##ig ##uous ##ly [SEP]\n",
            "I0918 12:32:58.526335 140304780035968 create_pretraining_data.py:151] tokens: [CLS] thank you [MASK] what s all the [MASK] [SEP] a vampire in the lobby did i hear that right never a dull [MASK] we re done get out now can you believe this it s a sweep [MASK] ll never make [MASK] [MASK] what is it [MASK] readers shouldn [MASK] we have been memo ##ed [MASK] s [MASK] [MASK] re [MASK] random mind readings [MASK] s lil ##ah it looks like i won t be able [MASK] make the 1 00 great overboard [MASK] to say this is a shame it s just a shame whenever i hear of disloyal ##ty it hurts me saying [MASK] personally but this sort of thing must be deal ##t with quickly and cleanly and una ##mb ##ig ##uous ##ly [SEP]\n",
            "INFO:tensorflow:input_ids: 2 147 5 4 16 8 40 7 4 3 10 4085 19 7 5693 76 6 240 14 54 117 10 5499 4 20 33 277 44 55 65 34 5 223 22 11 8 10 5278 4 47 117 122 4 4 16 17 11 4 14375 564 4 20 29 109 7002 161 4 8 4 4 33 4 7189 300 7573 4 8 9672 4110 11 308 48 6 158 12 37 686 4 122 7 204 614 167 6257 4 9 96 22 17 10 1431 11 8 46 10 1431 2144 6 240 15 15949 4648 11 2073 18 341 4 2278 42 22 669 15 143 191 37 421 180 41 1724 13 22141 13 22820 20188 14467 15735 353 3\n",
            "I0918 12:32:58.526536 140304780035968 create_pretraining_data.py:161] input_ids: 2 147 5 4 16 8 40 7 4 3 10 4085 19 7 5693 76 6 240 14 54 117 10 5499 4 20 33 277 44 55 65 34 5 223 22 11 8 10 5278 4 47 117 122 4 4 16 17 11 4 14375 564 4 20 29 109 7002 161 4 8 4 4 33 4 7189 300 7573 4 8 9672 4110 11 308 48 6 158 12 37 686 4 122 7 204 614 167 6257 4 9 96 22 17 10 1431 11 8 46 10 1431 2144 6 240 15 15949 4648 11 2073 18 341 4 2278 42 22 669 15 143 191 37 421 180 41 1724 13 22141 13 22820 20188 14467 15735 353 3\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0918 12:32:58.526731 140304780035968 create_pretraining_data.py:161] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0918 12:32:58.526907 140304780035968 create_pretraining_data.py:161] segment_ids: 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:masked_lm_positions: 3 8 23 38 42 43 47 50 56 58 59 61 65 77 83 84 105 106 118 0\n",
            "I0918 12:32:58.527021 140304780035968 create_pretraining_data.py:161] masked_lm_positions: 3 8 23 38 42 43 47 50 56 58 59 61 65 77 83 84 105 106 118 0\n",
            "INFO:tensorflow:masked_lm_ids: 6957 4717 532 6 25 1065 300 12 14 78 49 343 11 9 6 29 2073 18 1724 0\n",
            "I0918 12:32:58.527129 140304780035968 create_pretraining_data.py:161] masked_lm_ids: 6957 4717 532 6 25 1065 300 12 14 78 49 343 11 9 6 29 2073 18 1724 0\n",
            "INFO:tensorflow:masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0\n",
            "I0918 12:32:58.527546 140304780035968 create_pretraining_data.py:161] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0\n",
            "INFO:tensorflow:next_sentence_labels: 0\n",
            "I0918 12:32:58.527742 140304780035968 create_pretraining_data.py:161] next_sentence_labels: 0\n",
            "INFO:tensorflow:*** Example ***\n",
            "I0918 12:32:58.528462 140304780035968 create_pretraining_data.py:149] *** Example ***\n",
            "INFO:tensorflow:tokens: [CLS] bim bim ##mer who [MASK] [MASK] nan s zi ##mmer it [MASK] t matter now she s [MASK] stone slim [MASK] [MASK] the aged wes side in the house cos [MASK] day they were just like you keep off the crack keep off the crack help the aged respect your nan [MASK] ##cake day [MASK] ll [MASK] [MASK] too shake ya batty shake ya batty help the aged jarvis the famous batty shaking the batty help [MASK] aged help yourself ##iced the aged jarvis big im up fank ##s for watchin today i ope you ave come away with [MASK] [SEP] tim my man it sucks not being part of lalapalabala yeah hey dudes skyler what are you doing [MASK] [SEP]\n",
            "I0918 12:32:58.528682 140304780035968 create_pretraining_data.py:151] tokens: [CLS] bim bim ##mer who [MASK] [MASK] nan s zi ##mmer it [MASK] t matter now she s [MASK] stone slim [MASK] [MASK] the aged wes side in the house cos [MASK] day they were just like you keep off the crack keep off the crack help the aged respect your nan [MASK] ##cake day [MASK] ll [MASK] [MASK] too shake ya batty shake ya batty help the aged jarvis the famous batty shaking the batty help [MASK] aged help yourself ##iced the aged jarvis big im up fank ##s for watchin today i ope you ave come away with [MASK] [SEP] tim my man it sucks not being part of lalapalabala yeah hey dudes skyler what are you doing [MASK] [SEP]\n",
            "INFO:tensorflow:input_ids: 2 6744 6744 13422 75 4 4 6979 8 12404 22507 11 4 12 325 65 53 8 4 2038 4383 4 4 7 5209 29717 555 19 7 266 1138 4 160 49 101 46 48 5 179 125 7 2229 179 125 7 2229 153 7 5209 1128 27 6979 4 6281 160 4 47 4 4 121 1354 582 8300 1354 582 8300 153 7 5209 11735 7 1569 8300 4100 7 8300 153 4 5209 153 259 22822 7 5209 11735 148 5351 51 22869 57 28 5998 287 6 14400 5 22434 58 163 41 4 3 4807 25 89 11 2553 39 293 399 15 26063 66 95 20659 16357 16 38 5 145 4 3 0 0 0 0 0 0\n",
            "I0918 12:32:58.528894 140304780035968 create_pretraining_data.py:161] input_ids: 2 6744 6744 13422 75 4 4 6979 8 12404 22507 11 4 12 325 65 53 8 4 2038 4383 4 4 7 5209 29717 555 19 7 266 1138 4 160 49 101 46 48 5 179 125 7 2229 179 125 7 2229 153 7 5209 1128 27 6979 4 6281 160 4 47 4 4 121 1354 582 8300 1354 582 8300 153 7 5209 11735 7 1569 8300 4100 7 8300 153 4 5209 153 259 22822 7 5209 11735 148 5351 51 22869 57 28 5998 287 6 14400 5 22434 58 163 41 4 3 4807 25 89 11 2553 39 293 399 15 26063 66 95 20659 16357 16 38 5 145 4 3 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0\n",
            "I0918 12:32:58.529064 140304780035968 create_pretraining_data.py:161] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0\n",
            "I0918 12:32:58.529226 140304780035968 create_pretraining_data.py:161] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0\n",
            "INFO:tensorflow:masked_lm_positions: 4 5 6 12 18 21 22 31 40 52 53 55 57 58 77 81 100 120 0 0\n",
            "I0918 12:32:58.529347 140304780035968 create_pretraining_data.py:161] masked_lm_positions: 4 5 6 12 18 21 22 31 40 52 53 55 57 58 77 81 100 120 0 0\n",
            "INFO:tensorflow:masked_lm_ids: 75 839 18 30 222 13422 153 61 7 1138 61 5 37 1902 7 153 7922 45 0 0\n",
            "I0918 12:32:58.529455 140304780035968 create_pretraining_data.py:161] masked_lm_ids: 75 839 18 30 222 13422 153 61 7 1138 61 5 37 1902 7 153 7922 45 0 0\n",
            "INFO:tensorflow:masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0 0.0\n",
            "I0918 12:32:58.529569 140304780035968 create_pretraining_data.py:161] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0 0.0\n",
            "INFO:tensorflow:next_sentence_labels: 1\n",
            "I0918 12:32:58.529693 140304780035968 create_pretraining_data.py:161] next_sentence_labels: 1\n",
            "INFO:tensorflow:*** Example ***\n",
            "I0918 12:32:58.530341 140304780035968 create_pretraining_data.py:149] *** Example ***\n",
            "INFO:tensorflow:tokens: [CLS] but that s part [MASK] the challenge don [MASK] you [MASK] tired of doing [MASK] yes [MASK] [SEP] who s that in the kimono fraud it s nothing but a vulgar magic show dr lkuma you re being [MASK] mother what s [MASK] [SEP]\n",
            "I0918 12:32:58.530508 140304780035968 create_pretraining_data.py:151] tokens: [CLS] but that s part [MASK] the challenge don [MASK] you [MASK] tired of doing [MASK] yes [MASK] [SEP] who s that in the kimono fraud it s nothing but a vulgar magic show dr lkuma you re being [MASK] mother what s [MASK] [SEP]\n",
            "INFO:tensorflow:input_ids: 2 42 14 8 399 4 7 2724 30 4 5 4 906 15 145 4 84 4 3 75 8 14 19 7 12599 3164 11 8 166 42 10 4570 1166 257 473 5677 5 33 293 4 296 16 8 4 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0918 12:32:58.530710 140304780035968 create_pretraining_data.py:161] input_ids: 2 42 14 8 399 4 7 2724 30 4 5 4 906 15 145 4 84 4 3 75 8 14 19 7 12599 3164 11 8 166 42 10 4570 1166 257 473 5677 5 33 293 4 296 16 8 4 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0918 12:32:58.608058 140304780035968 create_pretraining_data.py:161] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0918 12:32:58.608366 140304780035968 create_pretraining_data.py:161] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:masked_lm_positions: 5 9 11 15 17 39 43 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0918 12:32:58.608522 140304780035968 create_pretraining_data.py:161] masked_lm_positions: 5 9 11 15 17 39 43 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:masked_lm_ids: 15 12 44 1193 84 7511 254 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0918 12:32:58.608700 140304780035968 create_pretraining_data.py:161] masked_lm_ids: 15 12 44 1193 84 7511 254 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
            "I0918 12:32:58.608886 140304780035968 create_pretraining_data.py:161] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
            "INFO:tensorflow:next_sentence_labels: 1\n",
            "I0918 12:32:58.609028 140304780035968 create_pretraining_data.py:161] next_sentence_labels: 1\n",
            "INFO:tensorflow:*** Example ***\n",
            "I0918 12:32:58.609881 140304780035968 create_pretraining_data.py:149] *** Example ***\n",
            "INFO:tensorflow:tokens: [CLS] [MASK] let s go to chil ##aquil s [MASK] faster get down man step on it the window [SEP] the [MASK] that s it [MASK] and [MASK] are you ready [MASK] s your stake ten thousand [MASK] [MASK] 10 000 go on then you re on for 10 10 s the stake heat em up [SEP]\n",
            "I0918 12:32:58.610112 140304780035968 create_pretraining_data.py:151] tokens: [CLS] [MASK] let s go to chil ##aquil s [MASK] faster get down man step on it the window [SEP] the [MASK] that s it [MASK] and [MASK] are you ready [MASK] s your stake ten thousand [MASK] [MASK] 10 000 go on then you re on for 10 10 s the stake heat em up [SEP]\n",
            "INFO:tensorflow:input_ids: 2 4 70 8 52 9 10478 9030 8 4 991 44 115 89 795 24 11 7 931 3 7 4 14 8 11 4 13 4 38 5 345 4 8 27 2753 597 1465 4 4 554 534 52 24 110 5 33 24 28 554 554 8 7 2753 1718 428 51 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0918 12:32:58.610312 140304780035968 create_pretraining_data.py:161] input_ids: 2 4 70 8 52 9 10478 9030 8 4 991 44 115 89 795 24 11 7 931 3 7 4 14 8 11 4 13 4 38 5 345 4 8 27 2753 597 1465 4 4 554 534 52 24 110 5 33 24 28 554 554 8 7 2753 1718 428 51 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0918 12:32:58.610477 140304780035968 create_pretraining_data.py:161] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0918 12:32:58.610657 140304780035968 create_pretraining_data.py:161] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:masked_lm_positions: 1 9 21 25 27 31 37 38 52 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0918 12:32:58.610784 140304780035968 create_pretraining_data.py:161] masked_lm_positions: 1 9 21 25 27 31 37 38 52 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:masked_lm_ids: 486 935 931 2016 1884 16 192 28 2753 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0918 12:32:58.610903 140304780035968 create_pretraining_data.py:161] masked_lm_ids: 486 935 931 2016 1884 16 192 28 2753 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
            "I0918 12:32:58.611025 140304780035968 create_pretraining_data.py:161] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
            "INFO:tensorflow:next_sentence_labels: 0\n",
            "I0918 12:32:58.611124 140304780035968 create_pretraining_data.py:161] next_sentence_labels: 0\n",
            "INFO:tensorflow:*** Writing to output files ***\n",
            "I0918 12:33:04.209079 140061523146624 create_pretraining_data.py:457] *** Writing to output files ***\n",
            "INFO:tensorflow:  pretraining_data/shard_0001.tfrecord\n",
            "I0918 12:33:04.209486 140061523146624 create_pretraining_data.py:459]   pretraining_data/shard_0001.tfrecord\n",
            "WARNING:tensorflow:From bert/create_pretraining_data.py:101: The name tf.python_io.TFRecordWriter is deprecated. Please use tf.io.TFRecordWriter instead.\n",
            "\n",
            "W0918 12:33:04.209808 140061523146624 deprecation_wrapper.py:119] From bert/create_pretraining_data.py:101: The name tf.python_io.TFRecordWriter is deprecated. Please use tf.io.TFRecordWriter instead.\n",
            "\n",
            "INFO:tensorflow:*** Example ***\n",
            "I0918 12:33:04.211055 140061523146624 create_pretraining_data.py:149] *** Example ***\n",
            "INFO:tensorflow:tokens: [CLS] s [MASK] what has happened vissing call an ambulance now vissing wake up it s bjarne vissing bi there is an ambulance on its way his [MASK] [MASK] jesper [MASK] is your son arthur knew that jesper is [MASK] [MASK] that s why it was arthur who [UNUSED_222] her gotcha morphine it was of course you wrote the story about the drug addicts in ny [MASK] ##n [MASK] [UNK] [MASK] [MASK] for [MASK] woman you hadn t seen in fifteen years she was going [MASK] talk about the drug addicts those [SEP] about arthur you were to meet at a hotel in lt col ##bjorn ##sens ##gade but arthur beat you to it they [MASK] her dead of an overdose [MASK] woman was jesper ##sfer mother [SEP]\n",
            "I0918 12:33:04.211365 140061523146624 create_pretraining_data.py:151] tokens: [CLS] s [MASK] what has happened vissing call an ambulance now vissing wake up it s bjarne vissing bi there is an ambulance on its way his [MASK] [MASK] jesper [MASK] is your son arthur knew that jesper is [MASK] [MASK] that s why it was arthur who [UNUSED_222] her gotcha morphine it was of course you wrote the story about the drug addicts in ny [MASK] ##n [MASK] [UNK] [MASK] [MASK] for [MASK] woman you hadn t seen in fifteen years she was going [MASK] talk about the drug addicts those [SEP] about arthur you were to meet at a hotel in lt col ##bjorn ##sens ##gade but arthur beat you to it they [MASK] her dead of an overdose [MASK] woman was jesper ##sfer mother [SEP]\n",
            "INFO:tensorflow:input_ids: 2 8 4 16 126 260 14800 165 98 2494 65 14800 675 51 11 8 7926 14800 2784 50 17 98 2494 24 773 118 87 4 4 17234 4 17 27 263 5984 313 14 17234 17 4 4 14 8 78 11 35 5984 75 31970 68 9384 5934 11 35 15 268 5 1243 7 542 62 7 1928 9926 19 22596 4 88 4 1 4 4 28 4 270 5 1715 12 314 19 2995 213 53 35 106 4 172 62 7 1928 9926 181 3 62 5984 5 101 9 363 64 10 1044 19 543 6871 23420 30235 18680 42 5984 743 5 9 11 49 4 68 244 15 98 17489 4 270 35 17234 20668 296 3\n",
            "I0918 12:33:04.211591 140061523146624 create_pretraining_data.py:161] input_ids: 2 8 4 16 126 260 14800 165 98 2494 65 14800 675 51 11 8 7926 14800 2784 50 17 98 2494 24 773 118 87 4 4 17234 4 17 27 263 5984 313 14 17234 17 4 4 14 8 78 11 35 5984 75 31970 68 9384 5934 11 35 15 268 5 1243 7 542 62 7 1928 9926 19 22596 4 88 4 1 4 4 28 4 270 5 1715 12 314 19 2995 213 53 35 106 4 172 62 7 1928 9926 181 3 62 5984 5 101 9 363 64 10 1044 19 543 6871 23420 30235 18680 42 5984 743 5 9 11 49 4 68 244 15 98 17489 4 270 35 17234 20668 296 3\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0918 12:33:04.211804 140061523146624 create_pretraining_data.py:161] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0918 12:33:04.211993 140061523146624 create_pretraining_data.py:161] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:masked_lm_positions: 2 27 28 30 39 40 48 49 50 58 66 68 70 71 73 85 115 121 125 0\n",
            "I0918 12:33:04.212119 140061523146624 create_pretraining_data.py:161] masked_lm_positions: 2 27 28 30 39 40 48 49 50 58 66 68 70 71 73 85 115 121 125 0\n",
            "INFO:tensorflow:masked_lm_ids: 7926 187 17 21 27 263 435 68 7 7 25859 19 5 5397 10 9 312 14 8 0\n",
            "I0918 12:33:04.212229 140061523146624 create_pretraining_data.py:161] masked_lm_ids: 7926 187 17 21 27 263 435 68 7 7 25859 19 5 5397 10 9 312 14 8 0\n",
            "INFO:tensorflow:masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0\n",
            "I0918 12:33:04.212356 140061523146624 create_pretraining_data.py:161] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0\n",
            "INFO:tensorflow:next_sentence_labels: 0\n",
            "I0918 12:33:04.212461 140061523146624 create_pretraining_data.py:161] next_sentence_labels: 0\n",
            "INFO:tensorflow:*** Example ***\n",
            "I0918 12:33:04.213174 140061523146624 create_pretraining_data.py:149] *** Example ***\n",
            "INFO:tensorflow:tokens: [CLS] [MASK] don [MASK] worry it s nothing embarrassing not anything like baton twirl ##ing or anything so what s your talent oh ##weird i [MASK] sorry twirl ##ing can be a [MASK] art ##protective saw this cheerleader [MASK] it at a football game she lit [MASK] [MASK] on fire and did this sexy dance i [MASK] i could do something like that why can t [MASK] my parents don t like anything oste ##nta ##tious [SEP] and they really don t like fire cheryl i think you have as good a chance as anyone to win you [MASK] in yourself [MASK] have gotten this far right really [MASK] [MASK] re so nice and [MASK] smart [MASK] so sensitive you re definitely gonna win that s it [SEP]\n",
            "I0918 12:33:04.213399 140061523146624 create_pretraining_data.py:151] tokens: [CLS] [MASK] don [MASK] worry it s nothing embarrassing not anything like baton twirl ##ing or anything so what s your talent oh ##weird i [MASK] sorry twirl ##ing can be a [MASK] art ##protective saw this cheerleader [MASK] it at a football game she lit [MASK] [MASK] on fire and did this sexy dance i [MASK] i could do something like that why can t [MASK] my parents don t like anything oste ##nta ##tious [SEP] and they really don t like fire cheryl i think you have as good a chance as anyone to win you [MASK] in yourself [MASK] have gotten this far right really [MASK] [MASK] re so nice and [MASK] smart [MASK] so sensitive you re definitely gonna win that s it [SEP]\n",
            "INFO:tensorflow:input_ids: 2 4 30 4 351 11 8 166 2762 39 162 48 8823 5697 123 100 162 43 16 8 27 1419 56 24923 6 4 136 5697 123 34 37 10 4 940 19418 311 22 6312 4 11 64 10 3036 600 53 3007 4 4 24 558 13 76 22 1648 659 6 4 6 93 31 116 48 14 78 34 12 4 25 788 30 12 48 162 26973 27362 19055 3 13 49 108 30 12 48 558 1765 6 74 5 29 83 71 10 482 83 403 9 791 5 4 19 259 4 29 1265 22 470 54 108 4 4 33 43 194 13 4 719 4 43 2844 5 33 910 80 791 14 8 11 3\n",
            "I0918 12:33:04.213591 140061523146624 create_pretraining_data.py:161] input_ids: 2 4 30 4 351 11 8 166 2762 39 162 48 8823 5697 123 100 162 43 16 8 27 1419 56 24923 6 4 136 5697 123 34 37 10 4 940 19418 311 22 6312 4 11 64 10 3036 600 53 3007 4 4 24 558 13 76 22 1648 659 6 4 6 93 31 116 48 14 78 34 12 4 25 788 30 12 48 162 26973 27362 19055 3 13 49 108 30 12 48 558 1765 6 74 5 29 83 71 10 482 83 403 9 791 5 4 19 259 4 29 1265 22 470 54 108 4 4 33 43 194 13 4 719 4 43 2844 5 33 910 80 791 14 8 11 3\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0918 12:33:04.213804 140061523146624 create_pretraining_data.py:161] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0918 12:33:04.213976 140061523146624 create_pretraining_data.py:161] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:masked_lm_positions: 1 3 23 25 32 33 34 38 46 47 56 66 77 98 101 108 109 114 116 0\n",
            "I0918 12:33:04.214110 140061523146624 create_pretraining_data.py:161] masked_lm_positions: 1 3 23 25 32 33 34 38 46 47 56 66 77 98 101 108 109 114 116 0\n",
            "INFO:tensorflow:masked_lm_ids: 42 12 1765 26 256 940 6 145 68 7696 516 5 13 223 9 66 5 43 13 0\n",
            "I0918 12:33:04.214220 140061523146624 create_pretraining_data.py:161] masked_lm_ids: 42 12 1765 26 256 940 6 145 68 7696 516 5 13 223 9 66 5 43 13 0\n",
            "INFO:tensorflow:masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0\n",
            "I0918 12:33:04.214340 140061523146624 create_pretraining_data.py:161] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0\n",
            "INFO:tensorflow:next_sentence_labels: 0\n",
            "I0918 12:33:04.214441 140061523146624 create_pretraining_data.py:161] next_sentence_labels: 0\n",
            "INFO:tensorflow:*** Example ***\n",
            "I0918 12:33:04.215118 140061523146624 create_pretraining_data.py:149] *** Example ***\n",
            "INFO:tensorflow:tokens: [CLS] god i did [MASK] and if [MASK] anyone tries to hurt condense of my new friends i would [MASK] them out i would make them suffer so much they d wish they were never born and if they circumvent weezing would hunt them down thank you kathy a brief shining moment and then that mouth helps if you pull it out good luck ladies i wanted to rub the crown for luck frank [MASK] it to get it polished i ll [MASK] it by the [MASK] they announce the [MASK] my god [MASK] s the crown yes it is [MASK] can taste it now [MASK] no no not the [SEP] this in the finale positions yes wear [MASK] crown be the crown you [MASK] the crown [SEP]\n",
            "I0918 12:33:04.215335 140061523146624 create_pretraining_data.py:151] tokens: [CLS] god i did [MASK] and if [MASK] anyone tries to hurt condense of my new friends i would [MASK] them out i would make them suffer so much they d wish they were never born and if they circumvent weezing would hunt them down thank you kathy a brief shining moment and then that mouth helps if you pull it out good luck ladies i wanted to rub the crown for luck frank [MASK] it to get it polished i ll [MASK] it by the [MASK] they announce the [MASK] my god [MASK] s the crown yes it is [MASK] can taste it now [MASK] no no not the [SEP] this in the finale positions yes wear [MASK] crown be the crown you [MASK] the crown [SEP]\n",
            "INFO:tensorflow:input_ids: 2 137 6 76 4 13 59 4 403 3563 9 439 16286 15 25 170 342 6 107 4 105 55 6 107 122 105 1834 43 140 49 86 516 49 101 117 976 13 59 49 23725 21559 107 2138 105 115 147 5 899 10 4664 4588 532 13 110 14 736 3692 59 5 626 11 55 71 518 550 6 246 9 2672 7 1476 28 518 966 4 11 9 44 11 10164 6 47 4 11 119 7 4 49 5929 7 4 25 137 4 8 7 1476 84 11 17 4 34 1236 11 65 4 23 23 39 7 3 22 19 7 4453 5160 84 690 4 1476 37 7 1476 5 4 7 1476 3\n",
            "I0918 12:33:04.215537 140061523146624 create_pretraining_data.py:161] input_ids: 2 137 6 76 4 13 59 4 403 3563 9 439 16286 15 25 170 342 6 107 4 105 55 6 107 122 105 1834 43 140 49 86 516 49 101 117 976 13 59 49 23725 21559 107 2138 105 115 147 5 899 10 4664 4588 532 13 110 14 736 3692 59 5 626 11 55 71 518 550 6 246 9 2672 7 1476 28 518 966 4 11 9 44 11 10164 6 47 4 11 119 7 4 49 5929 7 4 25 137 4 8 7 1476 84 11 17 4 34 1236 11 65 4 23 23 39 7 3 22 19 7 4453 5160 84 690 4 1476 37 7 1476 5 4 7 1476 3\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0918 12:33:04.215730 140061523146624 create_pretraining_data.py:161] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0918 12:33:04.215903 140061523146624 create_pretraining_data.py:161] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:masked_lm_positions: 4 7 12 19 26 33 34 39 40 70 74 82 86 90 93 100 105 118 124 0\n",
            "I0918 12:33:04.216032 140061523146624 create_pretraining_data.py:161] masked_lm_positions: 4 7 12 19 26 33 34 39 40 70 74 82 86 90 93 100 105 118 124 0\n",
            "INFO:tensorflow:masked_lm_ids: 11 403 61 94 1834 101 117 996 6 1476 366 29 92 1886 11 5 23 7 38 0\n",
            "I0918 12:33:04.216145 140061523146624 create_pretraining_data.py:161] masked_lm_ids: 11 403 61 94 1834 101 117 996 6 1476 366 29 92 1886 11 5 23 7 38 0\n",
            "INFO:tensorflow:masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0\n",
            "I0918 12:33:04.216267 140061523146624 create_pretraining_data.py:161] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0\n",
            "INFO:tensorflow:next_sentence_labels: 0\n",
            "I0918 12:33:04.216373 140061523146624 create_pretraining_data.py:161] next_sentence_labels: 0\n",
            "INFO:tensorflow:*** Example ***\n",
            "I0918 12:33:04.217018 140061523146624 create_pretraining_data.py:149] *** Example ***\n",
            "INFO:tensorflow:tokens: [CLS] the word is desecrated [SEP] that s not right come on so instead [MASK] a 13 [MASK] roam it s [UNK] but it s still just [MASK] number [SEP]\n",
            "I0918 12:33:04.217181 140061523146624 create_pretraining_data.py:151] tokens: [CLS] the word is desecrated [SEP] that s not right come on so instead [MASK] a 13 [MASK] roam it s [UNK] but it s still just [MASK] number [SEP]\n",
            "INFO:tensorflow:input_ids: 2 7 458 17 10681 3 14 8 39 54 58 24 43 1178 4 10 1708 4 10008 11 8 1 42 11 8 159 46 4 618 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0918 12:33:04.217357 140061523146624 create_pretraining_data.py:161] input_ids: 2 7 458 17 10681 3 14 8 39 54 58 24 43 1178 4 10 1708 4 10008 11 8 1 42 11 8 159 46 4 618 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0918 12:33:04.217522 140061523146624 create_pretraining_data.py:161] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0918 12:33:04.217698 140061523146624 create_pretraining_data.py:161] segment_ids: 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:masked_lm_positions: 14 17 18 27 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0918 12:33:04.217828 140061523146624 create_pretraining_data.py:161] masked_lm_positions: 14 17 18 27 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:masked_lm_ids: 15 422 1085 10 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0918 12:33:04.217941 140061523146624 create_pretraining_data.py:161] masked_lm_ids: 15 422 1085 10 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:masked_lm_weights: 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
            "I0918 12:33:04.218070 140061523146624 create_pretraining_data.py:161] masked_lm_weights: 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
            "INFO:tensorflow:next_sentence_labels: 1\n",
            "I0918 12:33:04.257788 140061523146624 create_pretraining_data.py:161] next_sentence_labels: 1\n",
            "INFO:tensorflow:*** Example ***\n",
            "I0918 12:33:04.258825 140061523146624 create_pretraining_data.py:149] *** Example ***\n",
            "INFO:tensorflow:tokens: [CLS] i did that no [MASK] did that and [MASK] [MASK] of highly specialize ##d federal manicurists some people that make you you know like [MASK] you [MASK] what you are under [MASK] get in the car no you think you saved something tonight [MASK] all you did was [MASK] [MASK] the dream of young women all over this splen what you think their dream is to get blown up you really got a good shot at that [MASK] plea yeah well i earned it honey twenty five years [MASK] [MASK] ##g [MASK] queens and what do i get fired they steal [MASK] life they [MASK] my beauty pageant hey hey it is not a beauty pageant [MASK] is [MASK] scholarship program yeah [SEP] is it serious [SEP]\n",
            "I0918 12:33:04.259153 140061523146624 create_pretraining_data.py:151] tokens: [CLS] i did that no [MASK] did that and [MASK] [MASK] of highly specialize ##d federal manicurists some people that make you you know like [MASK] you [MASK] what you are under [MASK] get in the car no you think you saved something tonight [MASK] all you did was [MASK] [MASK] the dream of young women all over this splen what you think their dream is to get blown up you really got a good shot at that [MASK] plea yeah well i earned it honey twenty five years [MASK] [MASK] ##g [MASK] queens and what do i get fired they steal [MASK] life they [MASK] my beauty pageant hey hey it is not a beauty pageant [MASK] is [MASK] scholarship program yeah [SEP] is it serious [SEP]\n",
            "INFO:tensorflow:input_ids: 2 6 76 14 23 4 76 14 13 4 4 15 2323 10585 206 2541 11721 102 138 14 122 5 5 36 48 4 5 4 16 5 38 423 4 44 19 7 201 23 5 74 5 1018 116 420 4 40 5 76 35 4 4 7 628 15 451 449 40 120 22 21990 16 5 74 193 628 17 9 44 2658 51 5 108 63 10 71 540 64 14 4 5592 66 69 6 3187 11 380 1334 354 213 4 4 1271 4 4341 13 16 31 6 44 1478 49 1160 4 146 49 4 25 863 964 95 95 11 17 39 10 863 964 4 17 4 2838 2010 66 3 17 11 581 3\n",
            "I0918 12:33:04.259387 140061523146624 create_pretraining_data.py:161] input_ids: 2 6 76 14 23 4 76 14 13 4 4 15 2323 10585 206 2541 11721 102 138 14 122 5 5 36 48 4 5 4 16 5 38 423 4 44 19 7 201 23 5 74 5 1018 116 420 4 40 5 76 35 4 4 7 628 15 451 449 40 120 22 21990 16 5 74 193 628 17 9 44 2658 51 5 108 63 10 71 540 64 14 4 5592 66 69 6 3187 11 380 1334 354 213 4 4 1271 4 4341 13 16 31 6 44 1478 49 1160 4 146 49 4 25 863 964 95 95 11 17 39 10 863 964 4 17 4 2838 2010 66 3 17 11 581 3\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0918 12:33:04.259572 140061523146624 create_pretraining_data.py:161] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1\n",
            "I0918 12:33:04.259768 140061523146624 create_pretraining_data.py:161] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1\n",
            "INFO:tensorflow:masked_lm_positions: 5 9 10 25 27 32 44 49 50 59 78 89 90 92 93 102 105 117 119 0\n",
            "I0918 12:33:04.259892 140061523146624 create_pretraining_data.py:161] masked_lm_positions: 5 9 10 25 27 32 44 49 50 59 78 89 90 92 93 102 105 117 119 0\n",
            "INFO:tensorflow:masked_lm_ids: 2584 10 546 365 36 1420 42 9 1440 692 5457 15 28709 863 4341 25 1160 11 10 0\n",
            "I0918 12:33:04.260016 140061523146624 create_pretraining_data.py:161] masked_lm_ids: 2584 10 546 365 36 1420 42 9 1440 692 5457 15 28709 863 4341 25 1160 11 10 0\n",
            "INFO:tensorflow:masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0\n",
            "I0918 12:33:04.260146 140061523146624 create_pretraining_data.py:161] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0\n",
            "INFO:tensorflow:next_sentence_labels: 1\n",
            "I0918 12:33:04.260251 140061523146624 create_pretraining_data.py:161] next_sentence_labels: 1\n",
            "INFO:tensorflow:*** Example ***\n",
            "I0918 12:33:04.261022 140061523146624 create_pretraining_data.py:149] *** Example ***\n",
            "INFO:tensorflow:tokens: [CLS] i m just thinking this this [MASK] it s a [MASK] it doesn [MASK] suck are you boyzvoice i m as ##bjorn [MASK] organize ##r hi there [MASK] spoke [MASK] the [MASK] i see you brought a whole team we only [MASK] one rule here no punching old ladies in [MASK] we ll have none of that where are your vocal ##ists by [MASK] way can you believe the crap those newspapers print no [MASK] here will suspect you of playback thurm everything triumvirate live we [MASK] all our music on cd we need to play this you can t [SEP] [MASK] is live [MASK] what do you mean we don t have [SEP]\n",
            "I0918 12:33:04.261260 140061523146624 create_pretraining_data.py:151] tokens: [CLS] i m just thinking this this [MASK] it s a [MASK] it doesn [MASK] suck are you boyzvoice i m as ##bjorn [MASK] organize ##r hi there [MASK] spoke [MASK] the [MASK] i see you brought a whole team we only [MASK] one rule here no punching old ladies in [MASK] we ll have none of that where are your vocal ##ists by [MASK] way can you believe the crap those newspapers print no [MASK] here will suspect you of playback thurm everything triumvirate live we [MASK] all our music on cd we need to play this you can t [SEP] [MASK] is live [MASK] what do you mean we don t have [SEP]\n",
            "INFO:tensorflow:input_ids: 2 6 26 46 427 22 22 4 11 8 10 4 11 208 4 1332 38 5 4286 6 26 83 23420 4 9360 440 217 50 4 1386 4 7 4 6 77 5 524 10 359 546 20 130 4 61 1705 45 23 19056 186 550 19 4 20 47 29 1010 15 14 103 38 27 11946 7720 119 4 118 34 5 223 7 1012 181 8752 3966 23 4 45 79 954 5 15 12321 31382 189 23411 316 20 4 40 114 584 24 7035 20 128 9 391 22 5 34 12 3 4 17 316 4 16 31 5 132 20 30 12 29 3 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0918 12:33:04.261460 140061523146624 create_pretraining_data.py:161] input_ids: 2 6 26 46 427 22 22 4 11 8 10 4 11 208 4 1332 38 5 4286 6 26 83 23420 4 9360 440 217 50 4 1386 4 7 4 6 77 5 524 10 359 546 20 130 4 61 1705 45 23 19056 186 550 19 4 20 47 29 1010 15 14 103 38 27 11946 7720 119 4 118 34 5 223 7 1012 181 8752 3966 23 4 45 79 954 5 15 12321 31382 189 23411 316 20 4 40 114 584 24 7035 20 128 9 391 22 5 34 12 3 4 17 316 4 16 31 5 132 20 30 12 29 3 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0918 12:33:04.261652 140061523146624 create_pretraining_data.py:161] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0918 12:33:04.261830 140061523146624 create_pretraining_data.py:161] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:masked_lm_positions: 7 11 14 23 28 30 32 42 51 64 75 82 84 87 102 105 110 0 0 0\n",
            "I0918 12:33:04.261954 140061523146624 create_pretraining_data.py:161] masked_lm_positions: 7 11 14 23 28 30 32 42 51 64 75 82 84 87 102 105 110 0 0 0\n",
            "INFO:tensorflow:masked_lm_ids: 2553 111 12 7 20 24 443 29 2372 7 61 45 8 29 189 45 20 0 0 0\n",
            "I0918 12:33:04.262080 140061523146624 create_pretraining_data.py:161] masked_lm_ids: 2553 111 12 7 20 24 443 29 2372 7 61 45 8 29 189 45 20 0 0 0\n",
            "INFO:tensorflow:masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0\n",
            "I0918 12:33:04.262197 140061523146624 create_pretraining_data.py:161] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0\n",
            "INFO:tensorflow:next_sentence_labels: 0\n",
            "I0918 12:33:04.262303 140061523146624 create_pretraining_data.py:161] next_sentence_labels: 0\n",
            "INFO:tensorflow:*** Example ***\n",
            "I0918 12:33:04.262969 140061523146624 create_pretraining_data.py:149] *** Example ***\n",
            "INFO:tensorflow:tokens: [CLS] not this [SEP] you go [MASK] where am i gonna put my [MASK] [SEP]\n",
            "I0918 12:33:04.263144 140061523146624 create_pretraining_data.py:151] tokens: [CLS] not this [SEP] you go [MASK] where am i gonna put my [MASK] [SEP]\n",
            "INFO:tensorflow:input_ids: 2 39 22 3 5 52 4 103 139 6 80 156 25 4 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0918 12:33:04.263312 140061523146624 create_pretraining_data.py:161] input_ids: 2 39 22 3 5 52 4 103 139 6 80 156 25 4 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0918 12:33:04.263487 140061523146624 create_pretraining_data.py:161] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0918 12:33:04.263670 140061523146624 create_pretraining_data.py:161] segment_ids: 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:masked_lm_positions: 6 13 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0918 12:33:04.263794 140061523146624 create_pretraining_data.py:161] masked_lm_positions: 6 13 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:masked_lm_ids: 231 461 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0918 12:33:04.263905 140061523146624 create_pretraining_data.py:161] masked_lm_ids: 231 461 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:masked_lm_weights: 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
            "I0918 12:33:04.264033 140061523146624 create_pretraining_data.py:161] masked_lm_weights: 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
            "INFO:tensorflow:next_sentence_labels: 1\n",
            "I0918 12:33:04.264140 140061523146624 create_pretraining_data.py:161] next_sentence_labels: 1\n",
            "INFO:tensorflow:*** Example ***\n",
            "I0918 12:33:04.264796 140061523146624 create_pretraining_data.py:149] *** Example ***\n",
            "INFO:tensorflow:tokens: [CLS] but this [MASK] this is [MASK] much better than [MASK] [MASK] [MASK] even better and better than very very best moment in my life [SEP] well when you choose to go it ll be ##your choice [MASK] on to they ##outh minister you need church mom why [MASK] doing this [SEP]\n",
            "I0918 12:33:04.264993 140061523146624 create_pretraining_data.py:151] tokens: [CLS] but this [MASK] this is [MASK] much better than [MASK] [MASK] [MASK] even better and better than very very best moment in my life [SEP] well when you choose to go it ll be ##your choice [MASK] on to they ##outh minister you need church mom why [MASK] doing this [SEP]\n",
            "INFO:tensorflow:input_ids: 2 42 22 4 22 17 4 140 182 197 4 4 4 142 182 13 182 197 124 124 253 532 19 25 146 3 69 90 5 1480 9 52 11 47 37 1802 1070 4 24 9 49 27523 5198 5 128 1078 298 78 4 145 22 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0918 12:33:04.265176 140061523146624 create_pretraining_data.py:161] input_ids: 2 42 22 4 22 17 4 140 182 197 4 4 4 142 182 13 182 197 124 124 253 532 19 25 146 3 69 90 5 1480 9 52 11 47 37 1802 1070 4 24 9 49 27523 5198 5 128 1078 298 78 4 145 22 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0918 12:33:04.265334 140061523146624 create_pretraining_data.py:161] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0918 12:33:04.265505 140061523146624 create_pretraining_data.py:161] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:masked_lm_positions: 3 6 10 11 12 37 41 48 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0918 12:33:04.265645 140061523146624 create_pretraining_data.py:161] masked_lm_positions: 3 6 10 11 12 37 41 48 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:masked_lm_ids: 22 124 593 11 8 241 27523 3252 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0918 12:33:04.265765 140061523146624 create_pretraining_data.py:161] masked_lm_ids: 22 124 593 11 8 241 27523 3252 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
            "I0918 12:33:04.265879 140061523146624 create_pretraining_data.py:161] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
            "INFO:tensorflow:next_sentence_labels: 1\n",
            "I0918 12:33:04.265990 140061523146624 create_pretraining_data.py:161] next_sentence_labels: 1\n",
            "INFO:tensorflow:*** Example ***\n",
            "I0918 12:33:04.266633 140061523146624 create_pretraining_data.py:149] *** Example ***\n",
            "INFO:tensorflow:tokens: [CLS] oh god that was lapps [MASK] was a kiss with your wet gross tongue hanging out ooh is [MASK] how boys back east kiss that s how everybody kisses charlotte [SEP] good [MASK] good job i got [MASK] something i could ##n [MASK] [MASK] ate pizza you [MASK] panties you re wild we [MASK] on this remember [SEP]\n",
            "I0918 12:33:04.266819 140061523146624 create_pretraining_data.py:151] tokens: [CLS] oh god that was lapps [MASK] was a kiss with your wet gross tongue hanging out ooh is [MASK] how boys back east kiss that s how everybody kisses charlotte [SEP] good [MASK] good job i got [MASK] something i could ##n [MASK] [MASK] ate pizza you [MASK] panties you re wild we [MASK] on this remember [SEP]\n",
            "INFO:tensorflow:input_ids: 2 56 137 14 35 16493 4 35 10 729 41 27 2984 3219 2462 1609 55 616 17 4 67 549 85 1297 729 14 8 67 335 3918 4289 3 71 4 71 309 6 63 4 116 6 93 88 4 4 3291 1559 5 4 2677 5 33 1325 20 4 24 22 239 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0918 12:33:04.267010 140061523146624 create_pretraining_data.py:161] input_ids: 2 56 137 14 35 16493 4 35 10 729 41 27 2984 3219 2462 1609 55 616 17 4 67 549 85 1297 729 14 8 67 335 3918 4289 3 71 4 71 309 6 63 4 116 6 93 88 4 4 3291 1559 5 4 2677 5 33 1325 20 4 24 22 239 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0918 12:33:04.361268 140061523146624 create_pretraining_data.py:161] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0918 12:33:04.361577 140061523146624 create_pretraining_data.py:161] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:masked_lm_positions: 5 6 19 33 38 43 44 48 54 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0918 12:33:04.361757 140061523146624 create_pretraining_data.py:161] masked_lm_positions: 5 6 19 33 38 43 44 48 54 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:masked_lm_ids: 1414 11 14 309 5 12 5 839 847 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0918 12:33:04.361898 140061523146624 create_pretraining_data.py:161] masked_lm_ids: 1414 11 14 309 5 12 5 839 847 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
            "I0918 12:33:04.362048 140061523146624 create_pretraining_data.py:161] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
            "INFO:tensorflow:next_sentence_labels: 1\n",
            "I0918 12:33:04.362174 140061523146624 create_pretraining_data.py:161] next_sentence_labels: 1\n",
            "INFO:tensorflow:*** Example ***\n",
            "I0918 12:33:04.363023 140061523146624 create_pretraining_data.py:149] *** Example ***\n",
            "INFO:tensorflow:tokens: [CLS] can ##mtex believe it jason surrender ##ed himself to colchis and this [MASK] [MASK] is very beautiful actually she is very beautiful you fools they lost faith i do not think jason abandon us he [MASK] forfiet ##residency [MASK] what does she treated to [MASK] [SEP] what does she means to us [SEP]\n",
            "I0918 12:33:04.363278 140061523146624 create_pretraining_data.py:151] tokens: [CLS] can ##mtex believe it jason surrender ##ed himself to colchis and this [MASK] [MASK] is very beautiful actually she is very beautiful you fools they lost faith i do not think jason abandon us he [MASK] forfiet ##residency [MASK] what does she treated to [MASK] [SEP] what does she means to us [SEP]\n",
            "INFO:tensorflow:input_ids: 2 34 16944 223 11 2924 5289 161 693 9 15389 13 22 4 4 17 124 365 387 53 17 124 365 5 7399 49 305 1200 6 31 39 74 2924 2802 99 21 4 26317 15019 4 16 210 53 2628 9 4 3 16 210 53 553 9 99 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0918 12:33:04.363497 140061523146624 create_pretraining_data.py:161] input_ids: 2 34 16944 223 11 2924 5289 161 693 9 15389 13 22 4 4 17 124 365 387 53 17 124 365 5 7399 49 305 1200 6 31 39 74 2924 2802 99 21 4 26317 15019 4 16 210 53 2628 9 4 3 16 210 53 553 9 99 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0918 12:33:04.363692 140061523146624 create_pretraining_data.py:161] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0918 12:33:04.363892 140061523146624 create_pretraining_data.py:161] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:masked_lm_positions: 2 13 14 36 38 39 43 45 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0918 12:33:04.364025 140061523146624 create_pretraining_data.py:161] masked_lm_positions: 2 13 14 36 38 39 43 45 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:masked_lm_ids: 5 1804 53 107 87 7833 553 60 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0918 12:33:04.364149 140061523146624 create_pretraining_data.py:161] masked_lm_ids: 5 1804 53 107 87 7833 553 60 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
            "I0918 12:33:04.364283 140061523146624 create_pretraining_data.py:161] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
            "INFO:tensorflow:next_sentence_labels: 0\n",
            "I0918 12:33:04.364417 140061523146624 create_pretraining_data.py:161] next_sentence_labels: 0\n",
            "INFO:tensorflow:*** Example ***\n",
            "I0918 12:33:04.365163 140061523146624 create_pretraining_data.py:149] *** Example ***\n",
            "INFO:tensorflow:tokens: [CLS] [MASK] [SEP] what are you doing [SEP]\n",
            "I0918 12:33:04.365359 140061523146624 create_pretraining_data.py:151] tokens: [CLS] [MASK] [SEP] what are you doing [SEP]\n",
            "INFO:tensorflow:input_ids: 2 4 3 16 38 5 145 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0918 12:33:04.365563 140061523146624 create_pretraining_data.py:161] input_ids: 2 4 3 16 38 5 145 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0918 12:33:04.365763 140061523146624 create_pretraining_data.py:161] input_mask: 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:segment_ids: 0 0 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0918 12:33:04.365936 140061523146624 create_pretraining_data.py:161] segment_ids: 0 0 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:masked_lm_positions: 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0918 12:33:04.366072 140061523146624 create_pretraining_data.py:161] masked_lm_positions: 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:masked_lm_ids: 149 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0918 12:33:04.366195 140061523146624 create_pretraining_data.py:161] masked_lm_ids: 149 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:masked_lm_weights: 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
            "I0918 12:33:04.366337 140061523146624 create_pretraining_data.py:161] masked_lm_weights: 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
            "INFO:tensorflow:next_sentence_labels: 0\n",
            "I0918 12:33:04.366454 140061523146624 create_pretraining_data.py:161] next_sentence_labels: 0\n",
            "INFO:tensorflow:*** Example ***\n",
            "I0918 12:33:04.367215 140061523146624 create_pretraining_data.py:149] *** Example ***\n",
            "INFO:tensorflow:tokens: [CLS] george oh that cycles in particular we [MASK] together like this me and george that s what [MASK] me you re worried about [MASK] flying junkie you [MASK] mystery solver roll up roll up [SEP] you better solve this [MASK] the fuck could they release that album [MASK] me on the cover [SEP]\n",
            "I0918 12:33:04.367433 140061523146624 create_pretraining_data.py:151] tokens: [CLS] george oh that cycles in particular we [MASK] together like this me and george that s what [MASK] me you re worried about [MASK] flying junkie you [MASK] mystery solver roll up roll up [SEP] you better solve this [MASK] the fuck could they release that album [MASK] me on the cover [SEP]\n",
            "INFO:tensorflow:input_ids: 2 1145 56 14 3289 19 3185 20 4 269 48 22 18 13 1145 14 8 16 4 18 5 33 1051 62 4 1502 5761 5 4 2761 11155 1182 51 1182 51 3 5 182 2258 22 4 7 275 93 49 1579 14 3618 4 18 24 7 947 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0918 12:33:04.367646 140061523146624 create_pretraining_data.py:161] input_ids: 2 1145 56 14 3289 19 3185 20 4 269 48 22 18 13 1145 14 8 16 4 18 5 33 1051 62 4 1502 5761 5 4 2761 11155 1182 51 1182 51 3 5 182 2258 22 4 7 275 93 49 1579 14 3618 4 18 24 7 947 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0918 12:33:04.367835 140061523146624 create_pretraining_data.py:161] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0918 12:33:04.368010 140061523146624 create_pretraining_data.py:161] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:masked_lm_positions: 4 8 18 24 28 40 41 48 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0918 12:33:04.368136 140061523146624 create_pretraining_data.py:161] masked_lm_positions: 4 8 18 24 28 40 41 48 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:masked_lm_ids: 3618 1607 3714 102 148 67 7 321 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0918 12:33:04.368261 140061523146624 create_pretraining_data.py:161] masked_lm_ids: 3618 1607 3714 102 148 67 7 321 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
            "I0918 12:33:04.368404 140061523146624 create_pretraining_data.py:161] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
            "INFO:tensorflow:next_sentence_labels: 0\n",
            "I0918 12:33:04.368521 140061523146624 create_pretraining_data.py:161] next_sentence_labels: 0\n",
            "INFO:tensorflow:*** Example ***\n",
            "I0918 12:33:04.369253 140061523146624 create_pretraining_data.py:149] *** Example ***\n",
            "INFO:tensorflow:tokens: [CLS] your application is a novel idea however it is [MASK] the role of [MASK] court to evaluate novel ideas and as such i [MASK] grant your [MASK] [MASK] honor ms [MASK] will not see justice [MASK] an arrest warrant [MASK] [MASK] are you going to appeal this decision yes [MASK] honor good because i ve already passed the paperwork [MASK] to an appell ##ate term judge in anticipation horrend stash appeal you have yes i have because [MASK] my decision is reversed i hope [MASK] s done soon enough to do you some good [SEP] this hearing is adjourned ms kraft you didn t [MASK] the rest of his decision it s going to [MASK] appealed it s going [MASK] be okay it s not [MASK] [SEP]\n",
            "I0918 12:33:04.369485 140061523146624 create_pretraining_data.py:151] tokens: [CLS] your application is a novel idea however it is [MASK] the role of [MASK] court to evaluate novel ideas and as such i [MASK] grant your [MASK] [MASK] honor ms [MASK] will not see justice [MASK] an arrest warrant [MASK] [MASK] are you going to appeal this decision yes [MASK] honor good because i ve already passed the paperwork [MASK] to an appell ##ate term judge in anticipation horrend stash appeal you have yes i have because [MASK] my decision is reversed i hope [MASK] s done soon enough to do you some good [SEP] this hearing is adjourned ms kraft you didn t [MASK] the rest of his decision it s going to [MASK] appealed it s going [MASK] be okay it s not [MASK] [SEP]\n",
            "INFO:tensorflow:input_ids: 2 27 5666 17 10 7895 328 2124 11 17 4 7 3240 15 4 776 9 10229 7895 2421 13 83 357 6 4 3656 27 4 4 912 7765 4 79 39 77 2662 4 98 1420 3817 4 4 38 5 106 9 8479 22 1331 84 4 912 71 134 6 73 323 1269 7 4819 4 9 98 22501 3220 3403 1397 19 13032 30044 6095 8479 5 29 84 6 29 134 4 25 1331 17 14937 6 375 4 8 277 433 235 9 31 5 102 71 3 22 2005 17 6029 7765 7172 5 112 12 4 7 499 15 87 1331 11 8 106 9 4 14897 11 8 106 4 37 91 11 8 39 4 3\n",
            "I0918 12:33:04.369710 140061523146624 create_pretraining_data.py:161] input_ids: 2 27 5666 17 10 7895 328 2124 11 17 4 7 3240 15 4 776 9 10229 7895 2421 13 83 357 6 4 3656 27 4 4 912 7765 4 79 39 77 2662 4 98 1420 3817 4 4 38 5 106 9 8479 22 1331 84 4 912 71 134 6 73 323 1269 7 4819 4 9 98 22501 3220 3403 1397 19 13032 30044 6095 8479 5 29 84 6 29 134 4 25 1331 17 14937 6 375 4 8 277 433 235 9 31 5 102 71 3 22 2005 17 6029 7765 7172 5 112 12 4 7 499 15 87 1331 11 8 106 9 4 14897 11 8 106 4 37 91 11 8 39 4 3\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0918 12:33:04.369912 140061523146624 create_pretraining_data.py:161] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0918 12:33:04.370084 140061523146624 create_pretraining_data.py:161] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:masked_lm_positions: 10 14 24 27 28 31 36 40 41 50 60 69 70 78 85 105 115 120 126 0\n",
            "I0918 12:33:04.370213 140061523146624 create_pretraining_data.py:161] masked_lm_positions: 10 14 24 27 28 31 36 40 41 50 60 69 70 78 85 105 115 120 126 0\n",
            "INFO:tensorflow:masked_lm_ids: 39 22 689 5666 27 7172 836 17 12778 27 24 15 98 59 11 240 37 9 91 0\n",
            "I0918 12:33:04.466611 140061523146624 create_pretraining_data.py:161] masked_lm_ids: 39 22 689 5666 27 7172 836 17 12778 27 24 15 98 59 11 240 37 9 91 0\n",
            "INFO:tensorflow:masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0\n",
            "I0918 12:33:04.466958 140061523146624 create_pretraining_data.py:161] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0\n",
            "INFO:tensorflow:next_sentence_labels: 0\n",
            "I0918 12:33:04.467112 140061523146624 create_pretraining_data.py:161] next_sentence_labels: 0\n",
            "INFO:tensorflow:*** Example ***\n",
            "I0918 12:33:04.467989 140061523146624 create_pretraining_data.py:149] *** Example ***\n",
            "INFO:tensorflow:tokens: [CLS] incomplete yes and [MASK] said [SEP] jesus is just [MASK] right ##with me us jesus [MASK] [MASK] all right oh yeah jesus is just all right ##with me jesus [MASK] just all right ##with me okay let [MASK] take a look atyour pictures kitty what doyou see when you think ##ofgod [SEP]\n",
            "I0918 12:33:04.468213 140061523146624 create_pretraining_data.py:151] tokens: [CLS] incomplete yes and [MASK] said [SEP] jesus is just [MASK] right ##with me us jesus [MASK] [MASK] all right oh yeah jesus is just all right ##with me jesus [MASK] just all right ##with me okay let [MASK] take a look atyour pictures kitty what doyou see when you think ##ofgod [SEP]\n",
            "INFO:tensorflow:input_ids: 2 10758 84 13 4 135 3 454 17 46 4 54 3852 18 99 454 4 4 40 54 56 66 454 17 46 40 54 3852 18 454 4 46 40 54 3852 18 91 70 4 94 10 82 15107 1554 2708 16 5410 77 90 5 74 26929 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0918 12:33:04.468396 140061523146624 create_pretraining_data.py:161] input_ids: 2 10758 84 13 4 135 3 454 17 46 4 54 3852 18 99 454 4 4 40 54 56 66 454 17 46 40 54 3852 18 454 4 46 40 54 3852 18 91 70 4 94 10 82 15107 1554 2708 16 5410 77 90 5 74 26929 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0918 12:33:04.468574 140061523146624 create_pretraining_data.py:161] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0918 12:33:04.468758 140061523146624 create_pretraining_data.py:161] segment_ids: 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:masked_lm_positions: 1 4 10 16 17 30 38 49 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0918 12:33:04.468877 140061523146624 create_pretraining_data.py:161] masked_lm_positions: 1 4 10 16 17 30 38 49 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:masked_lm_ids: 8060 137 40 17 46 17 8 5 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0918 12:33:04.468997 140061523146624 create_pretraining_data.py:161] masked_lm_ids: 8060 137 40 17 46 17 8 5 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
            "I0918 12:33:04.469107 140061523146624 create_pretraining_data.py:161] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
            "INFO:tensorflow:next_sentence_labels: 1\n",
            "I0918 12:33:04.469202 140061523146624 create_pretraining_data.py:161] next_sentence_labels: 1\n",
            "INFO:tensorflow:*** Example ***\n",
            "I0918 12:33:04.469966 140061523146624 create_pretraining_data.py:149] *** Example ***\n",
            "INFO:tensorflow:tokens: [CLS] fucking strong i always look people in the eye when i [MASK] talking [MASK] them i don t make [MASK] unnecessary moves the first ten words are enough first five amigo [MASK] gestures and i know [MASK] in his psyche fear is lurking he s not [MASK] [MASK] the fact that he s just about to foul his agents [MASK] know why because his weak psyche just mailed his inch [MASK] turd saying there s [MASK] meeting down [MASK] trousers this is incredible i have to go [MASK] the john what do you mean i [MASK] get a immi [SEP] they r e still in it [SEP]\n",
            "I0918 12:33:04.470173 140061523146624 create_pretraining_data.py:151] tokens: [CLS] fucking strong i always look people in the eye when i [MASK] talking [MASK] them i don t make [MASK] unnecessary moves the first ten words are enough first five amigo [MASK] gestures and i know [MASK] in his psyche fear is lurking he s not [MASK] [MASK] the fact that he s just about to foul his agents [MASK] know why because his weak psyche just mailed his inch [MASK] turd saying there s [MASK] meeting down [MASK] trousers this is incredible i have to go [MASK] the john what do you mean i [MASK] get a immi [SEP] they r e still in it [SEP]\n",
            "INFO:tensorflow:input_ids: 2 283 742 6 184 82 138 19 7 671 90 6 4 271 4 105 6 30 12 122 4 6125 2687 7 175 597 713 38 235 175 354 15536 4 6733 13 6 36 4 19 87 8738 1136 17 10709 21 8 39 4 4 7 769 14 21 8 46 62 9 5980 87 1812 4 36 78 134 87 1996 8738 46 15197 87 2907 4 7607 341 50 8 4 849 115 4 5179 22 17 1451 6 29 9 52 4 7 563 16 31 5 132 6 4 44 10 22789 3 49 998 721 159 19 11 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0918 12:33:04.470340 140061523146624 create_pretraining_data.py:161] input_ids: 2 283 742 6 184 82 138 19 7 671 90 6 4 271 4 105 6 30 12 122 4 6125 2687 7 175 597 713 38 235 175 354 15536 4 6733 13 6 36 4 19 87 8738 1136 17 10709 21 8 39 4 4 7 769 14 21 8 46 62 9 5980 87 1812 4 36 78 134 87 1996 8738 46 15197 87 2907 4 7607 341 50 8 4 849 115 4 5179 22 17 1451 6 29 9 52 4 7 563 16 31 5 132 6 4 44 10 22789 3 49 998 721 159 19 11 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0918 12:33:04.470498 140061523146624 create_pretraining_data.py:161] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0918 12:33:04.470669 140061523146624 create_pretraining_data.py:161] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:masked_lm_positions: 2 12 14 20 32 37 47 48 59 60 71 76 79 88 96 99 0 0 0 0\n",
            "I0918 12:33:04.470804 140061523146624 create_pretraining_data.py:161] masked_lm_positions: 2 12 14 20 32 37 47 48 59 60 71 76 79 88 96 99 0 0 0 0\n",
            "INFO:tensorflow:masked_lm_ids: 742 26 9 152 8 14 2269 15 813 5 123 10 87 9 133 5588 0 0 0 0\n",
            "I0918 12:33:04.470959 140061523146624 create_pretraining_data.py:161] masked_lm_ids: 742 26 9 152 8 14 2269 15 813 5 123 10 87 9 133 5588 0 0 0 0\n",
            "INFO:tensorflow:masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0\n",
            "I0918 12:33:04.471075 140061523146624 create_pretraining_data.py:161] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0\n",
            "INFO:tensorflow:next_sentence_labels: 1\n",
            "I0918 12:33:04.471174 140061523146624 create_pretraining_data.py:161] next_sentence_labels: 1\n",
            "INFO:tensorflow:*** Example ***\n",
            "I0918 12:33:04.471889 140061523146624 create_pretraining_data.py:149] *** Example ***\n",
            "INFO:tensorflow:tokens: [CLS] i think you might have been right frank is kathy morningside s [MASK] disgusting pervert ##ed frank he cleared under another name i ran a new cc [MASK] [MASK] [MASK] even a weapons charge [SEP] ##dogs we doing full deployment [MASK] didn t want to ##ser about [MASK] [SEP]\n",
            "I0918 12:33:04.472096 140061523146624 create_pretraining_data.py:151] tokens: [CLS] i think you might have been right frank is kathy morningside s [MASK] disgusting pervert ##ed frank he cleared under another name i ran a new cc [MASK] [MASK] [MASK] even a weapons charge [SEP] ##dogs we doing full deployment [MASK] didn t want to ##ser about [MASK] [SEP]\n",
            "INFO:tensorflow:input_ids: 2 6 74 5 272 29 109 54 966 17 899 2199 8 4 1414 2321 161 966 21 2856 423 255 187 6 996 10 170 24973 4 4 4 142 10 1517 1117 3 25089 20 145 481 11023 4 112 12 72 9 25386 62 4 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0918 12:33:04.472265 140061523146624 create_pretraining_data.py:161] input_ids: 2 6 74 5 272 29 109 54 966 17 899 2199 8 4 1414 2321 161 966 21 2856 423 255 187 6 996 10 170 24973 4 4 4 142 10 1517 1117 3 25089 20 145 481 11023 4 112 12 72 9 25386 62 4 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0918 12:33:04.472457 140061523146624 create_pretraining_data.py:161] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0918 12:33:04.472648 140061523146624 create_pretraining_data.py:161] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:masked_lm_positions: 13 28 29 30 36 41 46 48 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0918 12:33:04.472774 140061523146624 create_pretraining_data.py:161] masked_lm_positions: 13 28 29 30 36 41 46 48 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:masked_lm_ids: 263 578 19212 3705 38 2678 240 11 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0918 12:33:04.473181 140061523146624 create_pretraining_data.py:161] masked_lm_ids: 263 578 19212 3705 38 2678 240 11 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
            "I0918 12:33:04.473360 140061523146624 create_pretraining_data.py:161] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
            "INFO:tensorflow:next_sentence_labels: 0\n",
            "I0918 12:33:04.473457 140061523146624 create_pretraining_data.py:161] next_sentence_labels: 0\n",
            "INFO:tensorflow:*** Example ***\n",
            "I0918 12:33:04.474807 140061523146624 create_pretraining_data.py:149] *** Example ***\n",
            "INFO:tensorflow:tokens: [CLS] the one that said ##ema [MASK] name [SEP] now [SEP]\n",
            "I0918 12:33:04.475077 140061523146624 create_pretraining_data.py:151] tokens: [CLS] the one that said ##ema [MASK] name [SEP] now [SEP]\n",
            "INFO:tensorflow:input_ids: 2 7 61 14 135 18918 4 187 3 65 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0918 12:33:04.475274 140061523146624 create_pretraining_data.py:161] input_ids: 2 7 61 14 135 18918 4 187 3 65 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0918 12:33:04.475465 140061523146624 create_pretraining_data.py:161] input_mask: 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0918 12:33:04.475665 140061523146624 create_pretraining_data.py:161] segment_ids: 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:masked_lm_positions: 5 6 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0918 12:33:04.475795 140061523146624 create_pretraining_data.py:161] masked_lm_positions: 5 6 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:masked_lm_ids: 6342 8 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0918 12:33:04.476493 140061523146624 create_pretraining_data.py:161] masked_lm_ids: 6342 8 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:masked_lm_weights: 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
            "I0918 12:33:04.476699 140061523146624 create_pretraining_data.py:161] masked_lm_weights: 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
            "INFO:tensorflow:next_sentence_labels: 1\n",
            "I0918 12:33:04.476824 140061523146624 create_pretraining_data.py:161] next_sentence_labels: 1\n",
            "INFO:tensorflow:*** Example ***\n",
            "I0918 12:33:04.477560 140061523146624 create_pretraining_data.py:149] *** Example ***\n",
            "INFO:tensorflow:tokens: [CLS] jean jesus something ble ##w this way here thanks and here [SEP] he had [MASK] the money and claimed to know your bodyguard he came to collect [MASK] assured conclusion maybe he was [MASK] witted [MASK] was witted enough to nick the case any idea whose this vol ##ks ##wag ##en is [MASK] have ##n t seen it [MASK] exactly it [MASK] been here for a couple of days now [MASK] m [MASK] [MASK] take a closer look hey bolec i have this weird feeling like [MASK] seeing this face the face of the guy who sent [MASK] the bullet it [MASK] really weird [MASK] a sip you know i remember just one thing [MASK] vividly about that evening yes that doll on the dancing pole [SEP]\n",
            "I0918 12:33:04.478290 140061523146624 create_pretraining_data.py:151] tokens: [CLS] jean jesus something ble ##w this way here thanks and here [SEP] he had [MASK] the money and claimed to know your bodyguard he came to collect [MASK] assured conclusion maybe he was [MASK] witted [MASK] was witted enough to nick the case any idea whose this vol ##ks ##wag ##en is [MASK] have ##n t seen it [MASK] exactly it [MASK] been here for a couple of days now [MASK] m [MASK] [MASK] take a closer look hey bolec i have this weird feeling like [MASK] seeing this face the face of the guy who sent [MASK] the bullet it [MASK] really weird [MASK] a sip you know i remember just one thing [MASK] vividly about that evening yes that doll on the dancing pole [SEP]\n",
            "INFO:tensorflow:input_ids: 2 999 454 116 8206 2236 22 118 45 211 13 45 3 21 97 4 7 188 13 5817 9 36 27 6200 21 236 9 3530 4 6741 6198 155 21 35 4 11868 4 35 11868 235 9 3065 7 459 152 328 1668 22 8948 11118 31519 1287 17 4 29 88 12 314 11 4 441 11 4 109 45 28 10 604 15 360 65 4 26 4 4 94 10 1370 82 95 4763 6 29 22 821 571 48 4 855 22 332 7 332 15 7 203 75 866 4 7 2581 11 4 108 821 4 10 9441 5 36 6 239 46 61 143 4 10398 62 14 708 84 14 2003 24 7 1109 2362 3\n",
            "I0918 12:33:04.567014 140061523146624 create_pretraining_data.py:161] input_ids: 2 999 454 116 8206 2236 22 118 45 211 13 45 3 21 97 4 7 188 13 5817 9 36 27 6200 21 236 9 3530 4 6741 6198 155 21 35 4 11868 4 35 11868 235 9 3065 7 459 152 328 1668 22 8948 11118 31519 1287 17 4 29 88 12 314 11 4 441 11 4 109 45 28 10 604 15 360 65 4 26 4 4 94 10 1370 82 95 4763 6 29 22 821 571 48 4 855 22 332 7 332 15 7 203 75 866 4 7 2581 11 4 108 821 4 10 9441 5 36 6 239 46 61 143 4 10398 62 14 708 84 14 2003 24 7 1109 2362 3\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0918 12:33:04.567416 140061523146624 create_pretraining_data.py:161] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0918 12:33:04.567633 140061523146624 create_pretraining_data.py:161] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:masked_lm_positions: 15 18 28 29 34 36 46 53 59 62 71 73 74 87 98 102 105 115 117 0\n",
            "I0918 12:33:04.567774 140061523146624 create_pretraining_data.py:161] masked_lm_positions: 15 18 28 29 34 36 46 53 59 62 71 73 74 87 98 102 105 115 117 0\n",
            "INFO:tensorflow:masked_lm_ids: 524 13 7 3369 9748 21 1668 6 195 8 6 106 9 4720 18 8 94 602 62 0\n",
            "I0918 12:33:04.567892 140061523146624 create_pretraining_data.py:161] masked_lm_ids: 524 13 7 3369 9748 21 1668 6 195 8 6 106 9 4720 18 8 94 602 62 0\n",
            "INFO:tensorflow:masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0\n",
            "I0918 12:33:04.568025 140061523146624 create_pretraining_data.py:161] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0\n",
            "INFO:tensorflow:next_sentence_labels: 1\n",
            "I0918 12:33:04.568147 140061523146624 create_pretraining_data.py:161] next_sentence_labels: 1\n",
            "INFO:tensorflow:*** Example ***\n",
            "I0918 12:33:04.568898 140061523146624 create_pretraining_data.py:149] *** Example ***\n",
            "INFO:tensorflow:tokens: [CLS] [MASK] lord he s prov ##ing this shit ain t gonna [MASK] us all what was that [MASK] said this [MASK] [MASK] t gonna kill us all somebody s always gonna see the other side you feeling it they [MASK] them pink tops are pretty good i went to see this [MASK] the one about [MASK] they [MASK] to the jews in the war you went to see a movie lord what they did to them people what ##oratory of dope fiend [MASK] to the goddamn movies the germans decided that they were ##n [MASK] human no more they just [SEP] i hate his guts but i hate farnsworth even more now that he s so hot that hot beard lurk [MASK] what [MASK] my beard [SEP]\n",
            "I0918 12:33:04.569166 140061523146624 create_pretraining_data.py:151] tokens: [CLS] [MASK] lord he s prov ##ing this shit ain t gonna [MASK] us all what was that [MASK] said this [MASK] [MASK] t gonna kill us all somebody s always gonna see the other side you feeling it they [MASK] them pink tops are pretty good i went to see this [MASK] the one about [MASK] they [MASK] to the jews in the war you went to see a movie lord what they did to them people what ##oratory of dope fiend [MASK] to the goddamn movies the germans decided that they were ##n [MASK] human no more they just [SEP] i hate his guts but i hate farnsworth even more now that he s so hot that hot beard lurk [MASK] what [MASK] my beard [SEP]\n",
            "INFO:tensorflow:input_ids: 2 4 630 21 8 14598 123 22 176 382 12 80 4 99 40 16 35 14 4 135 22 4 4 12 80 228 99 40 364 8 184 80 77 7 183 555 5 571 11 49 4 105 1842 3562 38 350 71 6 250 9 77 22 4 7 61 62 4 49 4 9 7 2473 19 7 636 5 250 9 77 10 870 630 16 49 76 9 105 138 16 25361 15 4441 10592 4 9 7 648 1504 7 2134 921 14 49 101 88 4 605 23 129 49 46 3 6 551 87 3430 42 6 551 12545 142 129 65 14 21 8 43 478 14 478 5718 18189 4 16 4 25 5718 3\n",
            "I0918 12:33:04.569369 140061523146624 create_pretraining_data.py:161] input_ids: 2 4 630 21 8 14598 123 22 176 382 12 80 4 99 40 16 35 14 4 135 22 4 4 12 80 228 99 40 364 8 184 80 77 7 183 555 5 571 11 49 4 105 1842 3562 38 350 71 6 250 9 77 22 4 7 61 62 4 49 4 9 7 2473 19 7 636 5 250 9 77 10 870 630 16 49 76 9 105 138 16 25361 15 4441 10592 4 9 7 648 1504 7 2134 921 14 49 101 88 4 605 23 129 49 46 3 6 551 87 3430 42 6 551 12545 142 129 65 14 21 8 43 478 14 478 5718 18189 4 16 4 25 5718 3\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0918 12:33:04.569541 140061523146624 create_pretraining_data.py:161] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0918 12:33:04.569724 140061523146624 create_pretraining_data.py:161] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:masked_lm_positions: 1 10 12 18 21 22 35 40 52 56 58 79 83 95 109 112 121 122 124 0\n",
            "I0918 12:33:04.569850 140061523146624 create_pretraining_data.py:161] masked_lm_positions: 1 10 12 18 21 22 35 40 52 56 58 79 83 95 109 112 121 122 124 0\n",
            "INFO:tensorflow:masked_lm_ids: 84 12 228 6 176 382 555 96 870 16 76 251 460 12 60 65 161 2022 62 0\n",
            "I0918 12:33:04.569962 140061523146624 create_pretraining_data.py:161] masked_lm_ids: 84 12 228 6 176 382 555 96 870 16 76 251 460 12 60 65 161 2022 62 0\n",
            "INFO:tensorflow:masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0\n",
            "I0918 12:33:04.570090 140061523146624 create_pretraining_data.py:161] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0\n",
            "INFO:tensorflow:next_sentence_labels: 1\n",
            "I0918 12:33:04.570195 140061523146624 create_pretraining_data.py:161] next_sentence_labels: 1\n",
            "INFO:tensorflow:*** Example ***\n",
            "I0918 12:33:04.570868 140061523146624 create_pretraining_data.py:149] *** Example ***\n",
            "INFO:tensorflow:tokens: [CLS] gentlemen one moment are peak going to [MASK] off my hand because of some fucking case how am [MASK] going to look like [SEP] i [MASK] t want to be crippled for [MASK] rest of my life i have a family holiday plans i am a businessman [MASK] need [MASK] afterward to work pushup my laptop and to scratch rubbers [MASK] i m sure i have the key in question somewhere here then start looking for it sugar now [MASK] well oh sorry you fucking [MASK] what have you fucking done to me you thug stop whining boys don t cry it had to [MASK] so wonderful this is the answering [MASK] of kuba brenner leave your message after [MASK] beep kuba i know you are [SEP]\n",
            "I0918 12:33:04.571098 140061523146624 create_pretraining_data.py:151] tokens: [CLS] gentlemen one moment are peak going to [MASK] off my hand because of some fucking case how am [MASK] going to look like [SEP] i [MASK] t want to be crippled for [MASK] rest of my life i have a family holiday plans i am a businessman [MASK] need [MASK] afterward to work pushup my laptop and to scratch rubbers [MASK] i m sure i have the key in question somewhere here then start looking for it sugar now [MASK] well oh sorry you fucking [MASK] what have you fucking done to me you thug stop whining boys don t cry it had to [MASK] so wonderful this is the answering [MASK] of kuba brenner leave your message after [MASK] beep kuba i know you are [SEP]\n",
            "INFO:tensorflow:input_ids: 2 833 61 532 38 8793 106 9 4 125 25 371 134 15 102 283 459 67 139 4 106 9 82 48 3 6 4 12 72 9 37 12277 28 4 499 15 25 146 6 29 10 258 4850 1435 6 139 10 6270 4 128 4 15352 9 154 27840 25 8659 13 9 2486 10826 4 6 26 149 6 29 7 1035 19 512 756 45 110 306 280 28 11 1606 65 4 69 56 136 5 283 4 16 29 5 283 277 9 18 5 13964 168 4938 549 30 12 961 11 97 9 4 43 598 22 17 7 5140 4 15 1990 5242 218 27 1164 202 4 5259 1990 6 36 5 38 3\n",
            "I0918 12:33:04.571294 140061523146624 create_pretraining_data.py:161] input_ids: 2 833 61 532 38 8793 106 9 4 125 25 371 134 15 102 283 459 67 139 4 106 9 82 48 3 6 4 12 72 9 37 12277 28 4 499 15 25 146 6 29 10 258 4850 1435 6 139 10 6270 4 128 4 15352 9 154 27840 25 8659 13 9 2486 10826 4 6 26 149 6 29 7 1035 19 512 756 45 110 306 280 28 11 1606 65 4 69 56 136 5 283 4 16 29 5 283 277 9 18 5 13964 168 4938 549 30 12 961 11 97 9 4 43 598 22 17 7 5140 4 15 1990 5242 218 27 1164 202 4 5259 1990 6 36 5 38 3\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0918 12:33:04.571470 140061523146624 create_pretraining_data.py:161] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0918 12:33:04.571650 140061523146624 create_pretraining_data.py:161] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:masked_lm_positions: 5 8 19 26 33 47 48 50 51 54 60 61 80 86 89 93 105 112 120 0\n",
            "I0918 12:33:04.571780 140061523146624 create_pretraining_data.py:161] masked_lm_positions: 5 8 19 26 33 47 48 50 51 54 60 61 80 86 89 93 105 112 120 0\n",
            "INFO:tensorflow:masked_lm_ids: 5 2886 6 30 7 6270 6 22 371 24 25 303 124 936 5 18 37 809 7 0\n",
            "I0918 12:33:04.571892 140061523146624 create_pretraining_data.py:161] masked_lm_ids: 5 2886 6 30 7 6270 6 22 371 24 25 303 124 936 5 18 37 809 7 0\n",
            "INFO:tensorflow:masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0\n",
            "I0918 12:33:04.572007 140061523146624 create_pretraining_data.py:161] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0\n",
            "INFO:tensorflow:next_sentence_labels: 0\n",
            "I0918 12:33:04.572168 140061523146624 create_pretraining_data.py:161] next_sentence_labels: 0\n",
            "INFO:tensorflow:Wrote 91978 total instances\n",
            "I0918 12:33:43.256667 140304780035968 create_pretraining_data.py:166] Wrote 91978 total instances\n",
            "WARNING:tensorflow:From bert/create_pretraining_data.py:469: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.\n",
            "\n",
            "WARNING:tensorflow:From bert/create_pretraining_data.py:437: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.\n",
            "\n",
            "W0918 12:33:48.266330 139910923954048 deprecation_wrapper.py:119] From bert/create_pretraining_data.py:437: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.\n",
            "\n",
            "WARNING:tensorflow:From bert/create_pretraining_data.py:437: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.\n",
            "\n",
            "W0918 12:33:48.267108 139910923954048 deprecation_wrapper.py:119] From bert/create_pretraining_data.py:437: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/bert/tokenization.py:125: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n",
            "W0918 12:33:48.267349 139910923954048 deprecation_wrapper.py:119] From /content/bert/tokenization.py:125: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n",
            "WARNING:tensorflow:From bert/create_pretraining_data.py:444: The name tf.gfile.Glob is deprecated. Please use tf.io.gfile.glob instead.\n",
            "\n",
            "W0918 12:33:48.435526 139910923954048 deprecation_wrapper.py:119] From bert/create_pretraining_data.py:444: The name tf.gfile.Glob is deprecated. Please use tf.io.gfile.glob instead.\n",
            "\n",
            "WARNING:tensorflow:From bert/create_pretraining_data.py:446: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n",
            "\n",
            "W0918 12:33:48.437375 139910923954048 deprecation_wrapper.py:119] From bert/create_pretraining_data.py:446: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n",
            "\n",
            "INFO:tensorflow:*** Reading from input files ***\n",
            "I0918 12:33:48.437764 139910923954048 create_pretraining_data.py:446] *** Reading from input files ***\n",
            "INFO:tensorflow:  ./shards/shard_0002\n",
            "I0918 12:33:48.437910 139910923954048 create_pretraining_data.py:448]   ./shards/shard_0002\n",
            "INFO:tensorflow:Wrote 104109 total instances\n",
            "I0918 12:33:55.174242 140061523146624 create_pretraining_data.py:166] Wrote 104109 total instances\n",
            "WARNING:tensorflow:From bert/create_pretraining_data.py:469: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.\n",
            "\n",
            "WARNING:tensorflow:From bert/create_pretraining_data.py:437: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.\n",
            "\n",
            "W0918 12:33:59.982513 140477288433536 deprecation_wrapper.py:119] From bert/create_pretraining_data.py:437: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.\n",
            "\n",
            "WARNING:tensorflow:From bert/create_pretraining_data.py:437: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.\n",
            "\n",
            "W0918 12:33:59.983172 140477288433536 deprecation_wrapper.py:119] From bert/create_pretraining_data.py:437: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/bert/tokenization.py:125: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n",
            "W0918 12:33:59.983407 140477288433536 deprecation_wrapper.py:119] From /content/bert/tokenization.py:125: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n",
            "WARNING:tensorflow:From bert/create_pretraining_data.py:444: The name tf.gfile.Glob is deprecated. Please use tf.io.gfile.glob instead.\n",
            "\n",
            "W0918 12:34:00.141533 140477288433536 deprecation_wrapper.py:119] From bert/create_pretraining_data.py:444: The name tf.gfile.Glob is deprecated. Please use tf.io.gfile.glob instead.\n",
            "\n",
            "WARNING:tensorflow:From bert/create_pretraining_data.py:446: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n",
            "\n",
            "W0918 12:34:00.143169 140477288433536 deprecation_wrapper.py:119] From bert/create_pretraining_data.py:446: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n",
            "\n",
            "INFO:tensorflow:*** Reading from input files ***\n",
            "I0918 12:34:00.143443 140477288433536 create_pretraining_data.py:446] *** Reading from input files ***\n",
            "INFO:tensorflow:  ./shards/shard_0003\n",
            "I0918 12:34:00.143557 140477288433536 create_pretraining_data.py:448]   ./shards/shard_0003\n",
            "INFO:tensorflow:*** Writing to output files ***\n",
            "I0918 12:35:35.776520 139910923954048 create_pretraining_data.py:457] *** Writing to output files ***\n",
            "INFO:tensorflow:  pretraining_data/shard_0002.tfrecord\n",
            "I0918 12:35:35.776937 139910923954048 create_pretraining_data.py:459]   pretraining_data/shard_0002.tfrecord\n",
            "WARNING:tensorflow:From bert/create_pretraining_data.py:101: The name tf.python_io.TFRecordWriter is deprecated. Please use tf.io.TFRecordWriter instead.\n",
            "\n",
            "W0918 12:35:35.777232 139910923954048 deprecation_wrapper.py:119] From bert/create_pretraining_data.py:101: The name tf.python_io.TFRecordWriter is deprecated. Please use tf.io.TFRecordWriter instead.\n",
            "\n",
            "INFO:tensorflow:*** Example ***\n",
            "I0918 12:35:35.778509 139910923954048 create_pretraining_data.py:149] *** Example ***\n",
            "INFO:tensorflow:tokens: [CLS] did you say something my baby [MASK] that you yeah [MASK] s me i love you i would never hurt you schem know ##eeeeeeeeeeeeeeee don t you i know you re my child you [MASK] to go you have to go [SEP] meeting ##in the office [MASK] [MASK] in the hall [SEP]\n",
            "I0918 12:35:35.778843 139910923954048 create_pretraining_data.py:151] tokens: [CLS] did you say something my baby [MASK] that you yeah [MASK] s me i love you i would never hurt you schem know ##eeeeeeeeeeeeeeee don t you i know you re my child you [MASK] to go you have to go [SEP] meeting ##in the office [MASK] [MASK] in the hall [SEP]\n",
            "INFO:tensorflow:input_ids: 2 76 5 96 116 25 238 4 14 5 66 4 8 18 6 113 5 6 107 117 439 5 12517 36 21029 30 12 5 6 36 5 33 25 498 5 4 9 52 5 29 9 52 3 849 494 7 694 4 4 19 7 2716 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0918 12:35:35.779052 139910923954048 create_pretraining_data.py:161] input_ids: 2 76 5 96 116 25 238 4 14 5 66 4 8 18 6 113 5 6 107 117 439 5 12517 36 21029 30 12 5 6 36 5 33 25 498 5 4 9 52 5 29 9 52 3 849 494 7 694 4 4 19 7 2716 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0918 12:35:35.779224 139910923954048 create_pretraining_data.py:161] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0918 12:35:35.779381 139910923954048 create_pretraining_data.py:161] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:masked_lm_positions: 7 11 22 24 35 45 47 48 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0918 12:35:35.779494 139910923954048 create_pretraining_data.py:161] masked_lm_positions: 7 11 22 24 35 45 47 48 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:masked_lm_ids: 17 11 5 14 29 7 10 849 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0918 12:35:35.779639 139910923954048 create_pretraining_data.py:161] masked_lm_ids: 17 11 5 14 29 7 10 849 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
            "I0918 12:35:35.779779 139910923954048 create_pretraining_data.py:161] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
            "INFO:tensorflow:next_sentence_labels: 1\n",
            "I0918 12:35:35.779882 139910923954048 create_pretraining_data.py:161] next_sentence_labels: 1\n",
            "INFO:tensorflow:*** Example ***\n",
            "I0918 12:35:35.780580 139910923954048 create_pretraining_data.py:149] *** Example ***\n",
            "INFO:tensorflow:tokens: [CLS] dog [MASK] mendoza sick can you believe that [MASK] [MASK] sick dog it [MASK] horrible my mother my [MASK] kept telling us how much fun we were having but we were ##n t having any fun my dad drove himself crazy trying to [MASK] sure we [MASK] fun it s okay [MASK] we know [MASK] you feel yeah dad we know exactly howyou feel barking oh [SEP] [MASK] honey i m okay [MASK] m all right beth at rad we re out ofthe bug zone honey richard [MASK] s it we re taking a night off ##from this [MASK] we re staying in a hotel brennan yes beth the dog [MASK] eaten up all our reserve cash we can t afford to stay in a hotel [SEP]\n",
            "I0918 12:35:35.780850 139910923954048 create_pretraining_data.py:151] tokens: [CLS] dog [MASK] mendoza sick can you believe that [MASK] [MASK] sick dog it [MASK] horrible my mother my [MASK] kept telling us how much fun we were having but we were ##n t having any fun my dad drove himself crazy trying to [MASK] sure we [MASK] fun it s okay [MASK] we know [MASK] you feel yeah dad we know exactly howyou feel barking oh [SEP] [MASK] honey i m okay [MASK] m all right beth at rad we re out ofthe bug zone honey richard [MASK] s it we re taking a night off ##from this [MASK] we re staying in a hotel brennan yes beth the dog [MASK] eaten up all our reserve cash we can t afford to stay in a hotel [SEP]\n",
            "INFO:tensorflow:input_ids: 2 304 4 18273 608 34 5 223 14 4 4 608 304 11 4 1983 25 296 25 4 1210 678 99 67 140 445 20 101 400 42 20 101 88 12 400 152 445 25 216 2239 693 414 329 9 4 149 20 4 445 11 8 91 4 20 36 4 5 199 66 216 20 36 441 23119 199 2641 56 3 4 380 6 26 91 4 26 40 54 4185 64 11147 20 33 55 2847 2962 3353 380 1516 4 8 11 20 33 509 10 169 125 9003 22 4 20 33 1580 19 10 1044 6117 84 4185 7 304 4 2479 51 40 114 6892 1529 20 34 12 2205 9 214 19 10 1044 3\n",
            "I0918 12:35:35.781044 139910923954048 create_pretraining_data.py:161] input_ids: 2 304 4 18273 608 34 5 223 14 4 4 608 304 11 4 1983 25 296 25 4 1210 678 99 67 140 445 20 101 400 42 20 101 88 12 400 152 445 25 216 2239 693 414 329 9 4 149 20 4 445 11 8 91 4 20 36 4 5 199 66 216 20 36 441 23119 199 2641 56 3 4 380 6 26 91 4 26 40 54 4185 64 11147 20 33 55 2847 2962 3353 380 1516 4 8 11 20 33 509 10 169 125 9003 22 4 20 33 1580 19 10 1044 6117 84 4185 7 304 4 2479 51 40 114 6892 1529 20 34 12 2205 9 214 19 10 1044 3\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0918 12:35:35.781241 139910923954048 create_pretraining_data.py:161] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0918 12:35:35.781409 139910923954048 create_pretraining_data.py:161] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:masked_lm_positions: 2 3 9 10 14 19 23 39 42 44 47 52 55 68 73 79 88 99 111 0\n",
            "I0918 12:35:35.781519 139910923954048 create_pretraining_data.py:161] masked_lm_positions: 2 3 9 10 14 19 23 39 42 44 47 52 55 68 73 79 88 99 111 0\n",
            "INFO:tensorflow:masked_lm_ids: 35 201 10 201 35 296 67 2239 329 122 97 431 67 823 6 502 14 1814 126 0\n",
            "I0918 12:35:35.781648 139910923954048 create_pretraining_data.py:161] masked_lm_ids: 35 201 10 201 35 296 67 2239 329 122 97 431 67 823 6 502 14 1814 126 0\n",
            "INFO:tensorflow:masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0\n",
            "I0918 12:35:35.781773 139910923954048 create_pretraining_data.py:161] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0\n",
            "INFO:tensorflow:next_sentence_labels: 0\n",
            "I0918 12:35:35.781871 139910923954048 create_pretraining_data.py:161] next_sentence_labels: 0\n",
            "INFO:tensorflow:*** Example ***\n",
            "I0918 12:35:35.782532 139910923954048 create_pretraining_data.py:149] *** Example ***\n",
            "INFO:tensorflow:tokens: [CLS] if we can condition the mind to prolong ##ed activity [SEP] we [MASK] halfway to creating a clone no at least give me a [MASK] to prove it [SEP]\n",
            "I0918 12:35:35.782713 139910923954048 create_pretraining_data.py:151] tokens: [CLS] if we can condition the mind to prolong ##ed activity [SEP] we [MASK] halfway to creating a clone no at least give me a [MASK] to prove it [SEP]\n",
            "INFO:tensorflow:input_ids: 2 59 20 34 2644 7 300 9 15763 161 3684 3 20 4 6271 9 5063 10 739 23 64 502 131 18 10 4 9 1309 11 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0918 12:35:35.782887 139910923954048 create_pretraining_data.py:161] input_ids: 2 59 20 34 2644 7 300 9 15763 161 3684 3 20 4 6271 9 5063 10 739 23 64 502 131 18 10 4 9 1309 11 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0918 12:35:35.783049 139910923954048 create_pretraining_data.py:161] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0918 12:35:35.783217 139910923954048 create_pretraining_data.py:161] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:masked_lm_positions: 13 15 23 25 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0918 12:35:35.783330 139910923954048 create_pretraining_data.py:161] masked_lm_positions: 13 15 23 25 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:masked_lm_ids: 33 9 18 482 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0918 12:35:35.783434 139910923954048 create_pretraining_data.py:161] masked_lm_ids: 33 9 18 482 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:masked_lm_weights: 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
            "I0918 12:35:35.783552 139910923954048 create_pretraining_data.py:161] masked_lm_weights: 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
            "INFO:tensorflow:next_sentence_labels: 0\n",
            "I0918 12:35:35.783676 139910923954048 create_pretraining_data.py:161] next_sentence_labels: 0\n",
            "INFO:tensorflow:*** Example ***\n",
            "I0918 12:35:35.784310 139910923954048 create_pretraining_data.py:149] *** Example ***\n",
            "INFO:tensorflow:tokens: [CLS] very important [MASK] s what [MASK] re looking [MASK] don who s behind this stan [SEP] while [MASK] was deliveri ##ng some merchandise in my escargot i suddenly found myself amids ##t a storm [SEP]\n",
            "I0918 12:35:35.784472 139910923954048 create_pretraining_data.py:151] tokens: [CLS] very important [MASK] s what [MASK] re looking [MASK] don who s behind this stan [SEP] while [MASK] was deliveri ##ng some merchandise in my escargot i suddenly found myself amids ##t a storm [SEP]\n",
            "INFO:tensorflow:input_ids: 2 124 430 4 8 16 4 33 280 4 30 75 8 528 22 1198 3 327 4 35 31476 1230 102 5871 19 25 13503 6 1317 312 377 28864 180 10 1396 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0918 12:35:35.784672 139910923954048 create_pretraining_data.py:161] input_ids: 2 124 430 4 8 16 4 33 280 4 30 75 8 528 22 1198 3 327 4 35 31476 1230 102 5871 19 25 13503 6 1317 312 377 28864 180 10 1396 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0918 12:35:35.784836 139910923954048 create_pretraining_data.py:161] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0918 12:35:35.785001 139910923954048 create_pretraining_data.py:161] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:masked_lm_positions: 3 6 9 18 21 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0918 12:35:35.785121 139910923954048 create_pretraining_data.py:161] masked_lm_positions: 3 6 9 18 21 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:masked_lm_ids: 14 20 28 6 1230 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0918 12:35:35.785228 139910923954048 create_pretraining_data.py:161] masked_lm_ids: 14 20 28 6 1230 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
            "I0918 12:35:35.785340 139910923954048 create_pretraining_data.py:161] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
            "INFO:tensorflow:next_sentence_labels: 1\n",
            "I0918 12:35:35.785435 139910923954048 create_pretraining_data.py:161] next_sentence_labels: 1\n",
            "INFO:tensorflow:*** Example ***\n",
            "I0918 12:35:35.786067 139910923954048 create_pretraining_data.py:149] *** Example ***\n",
            "INFO:tensorflow:tokens: [CLS] well manel what [MASK] it [MASK] was the [MASK] that finished me and the cold you ve got to fight [SEP] what s happening to [MASK] [SEP]\n",
            "I0918 12:35:35.786230 139910923954048 create_pretraining_data.py:151] tokens: [CLS] well manel what [MASK] it [MASK] was the [MASK] that finished me and the cold you ve got to fight [SEP] what s happening to [MASK] [SEP]\n",
            "INFO:tensorflow:input_ids: 2 69 4388 16 4 11 4 35 7 4 14 793 18 13 7 620 5 73 63 9 624 3 16 8 846 9 4 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0918 12:35:35.786404 139910923954048 create_pretraining_data.py:161] input_ids: 2 69 4388 16 4 11 4 35 7 4 14 793 18 13 7 620 5 73 63 9 624 3 16 8 846 9 4 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0918 12:35:35.786576 139910923954048 create_pretraining_data.py:161] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0918 12:35:35.786760 139910923954048 create_pretraining_data.py:161] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:masked_lm_positions: 4 6 9 26 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0918 12:35:35.787380 139910923954048 create_pretraining_data.py:161] masked_lm_positions: 4 6 9 26 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:masked_lm_ids: 17 11 3783 4200 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0918 12:35:35.787502 139910923954048 create_pretraining_data.py:161] masked_lm_ids: 17 11 3783 4200 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:masked_lm_weights: 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
            "I0918 12:35:35.787664 139910923954048 create_pretraining_data.py:161] masked_lm_weights: 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
            "INFO:tensorflow:next_sentence_labels: 1\n",
            "I0918 12:35:35.787774 139910923954048 create_pretraining_data.py:161] next_sentence_labels: 1\n",
            "INFO:tensorflow:*** Example ***\n",
            "I0918 12:35:35.788418 139910923954048 create_pretraining_data.py:149] *** Example ***\n",
            "INFO:tensorflow:tokens: [CLS] now [MASK] nolan this is top [MASK] we re after a hardened ##crafts what i need you to do [MASK] stake out the bank can you handle that no problem all right now what i m [MASK] is shut your [MASK] on this one i mean it hush don t say [MASK] na ##da [MASK] with me all right if you can do that we might find a place for [MASK] on [MASK] force you d be in in the bureau right in the bureau probably you d get the f but you won t [MASK] the bi until some years have gone [MASK] [SEP] right cos there s some work involved [MASK] [MASK] the bank work [MASK] m all over it [MASK] maintained damn trent [SEP]\n",
            "I0918 12:35:35.788671 139910923954048 create_pretraining_data.py:151] tokens: [CLS] now [MASK] nolan this is top [MASK] we re after a hardened ##crafts what i need you to do [MASK] stake out the bank can you handle that no problem all right now what i m [MASK] is shut your [MASK] on this one i mean it hush don t say [MASK] na ##da [MASK] with me all right if you can do that we might find a place for [MASK] on [MASK] force you d be in in the bureau right in the bureau probably you d get the f but you won t [MASK] the bi until some years have gone [MASK] [SEP] right cos there s some work involved [MASK] [MASK] the bank work [MASK] m all over it [MASK] maintained damn trent [SEP]\n",
            "INFO:tensorflow:input_ids: 2 65 4 4476 22 17 633 4 20 33 202 10 7807 29588 16 6 128 5 9 31 4 2753 55 7 771 34 5 878 14 23 291 40 54 65 16 6 26 4 17 373 27 4 24 22 61 6 132 11 3977 30 12 96 4 1890 5399 4 41 18 40 54 59 5 34 31 14 20 272 164 10 224 28 4 24 4 868 5 86 37 19 19 7 5046 54 19 7 5046 429 5 86 44 7 574 42 5 158 12 4 7 2784 412 102 213 29 330 4 3 54 1138 50 8 102 154 1620 4 4 7 771 154 4 26 40 120 11 4 14312 290 1673 3\n",
            "I0918 12:35:35.788878 139910923954048 create_pretraining_data.py:161] input_ids: 2 65 4 4476 22 17 633 4 20 33 202 10 7807 29588 16 6 128 5 9 31 4 2753 55 7 771 34 5 878 14 23 291 40 54 65 16 6 26 4 17 373 27 4 24 22 61 6 132 11 3977 30 12 96 4 1890 5399 4 41 18 40 54 59 5 34 31 14 20 272 164 10 224 28 4 24 4 868 5 86 37 19 19 7 5046 54 19 7 5046 429 5 86 44 7 574 42 5 158 12 4 7 2784 412 102 213 29 330 4 3 54 1138 50 8 102 154 1620 4 4 7 771 154 4 26 40 120 11 4 14312 290 1673 3\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0918 12:35:35.789071 139910923954048 create_pretraining_data.py:161] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0918 12:35:35.789257 139910923954048 create_pretraining_data.py:161] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:masked_lm_positions: 2 7 13 19 20 37 41 52 55 71 73 83 96 104 113 114 118 123 124 0\n",
            "I0918 12:35:35.789404 139910923954048 create_pretraining_data.py:161] masked_lm_positions: 2 7 13 19 20 37 41 52 55 71 73 83 96 104 113 114 118 123 124 0\n",
            "INFO:tensorflow:masked_lm_ids: 229 749 2499 31 17 341 736 1203 5 5 7 19 44 119 441 48 6 347 478 0\n",
            "I0918 12:35:35.789515 139910923954048 create_pretraining_data.py:161] masked_lm_ids: 229 749 2499 31 17 341 736 1203 5 5 7 19 44 119 441 48 6 347 478 0\n",
            "INFO:tensorflow:masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0\n",
            "I0918 12:35:35.789686 139910923954048 create_pretraining_data.py:161] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0\n",
            "INFO:tensorflow:next_sentence_labels: 0\n",
            "I0918 12:35:35.789818 139910923954048 create_pretraining_data.py:161] next_sentence_labels: 0\n",
            "INFO:tensorflow:*** Example ***\n",
            "I0918 12:35:35.790460 139910923954048 create_pretraining_data.py:149] *** Example ***\n",
            "INFO:tensorflow:tokens: [CLS] and what s that got to do with fives it took [MASK] trained to close her up i [MASK] t like fives [SEP] that s [MASK] let s hit it let s go let s go hon will you take a [MASK] of [MASK] with my new camera wait [MASK] [MASK] let s [MASK] come on [MASK] on i m gonna miss you [SEP]\n",
            "I0918 12:35:35.790692 139910923954048 create_pretraining_data.py:151] tokens: [CLS] and what s that got to do with fives it took [MASK] trained to close her up i [MASK] t like fives [SEP] that s [MASK] let s hit it let s go let s go hon will you take a [MASK] of [MASK] with my new camera wait [MASK] [MASK] let s [MASK] come on [MASK] on i m gonna miss you [SEP]\n",
            "INFO:tensorflow:input_ids: 2 13 16 8 14 63 9 31 41 7596 11 366 4 4273 9 463 68 51 6 4 12 48 7596 3 14 8 4 70 8 446 11 70 8 52 70 8 52 7600 79 5 94 10 4 15 4 41 25 170 1279 150 4 4 70 8 4 58 24 4 24 6 26 80 284 5 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0918 12:35:35.790904 139910923954048 create_pretraining_data.py:161] input_ids: 2 13 16 8 14 63 9 31 41 7596 11 366 4 4273 9 463 68 51 6 4 12 48 7596 3 14 8 4 70 8 446 11 70 8 52 70 8 52 7600 79 5 94 10 4 15 4 41 25 170 1279 150 4 4 70 8 4 58 24 4 24 6 26 80 284 5 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0918 12:35:35.791064 139910923954048 create_pretraining_data.py:161] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0918 12:35:35.791231 139910923954048 create_pretraining_data.py:161] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:masked_lm_positions: 12 13 19 26 42 44 50 51 54 57 0 0 0 0 0 0 0 0 0 0\n",
            "I0918 12:35:35.791355 139910923954048 create_pretraining_data.py:161] masked_lm_positions: 12 13 19 26 42 44 50 51 54 57 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:masked_lm_ids: 3677 3943 30 11 696 99 40 190 52 58 0 0 0 0 0 0 0 0 0 0\n",
            "I0918 12:35:35.791472 139910923954048 create_pretraining_data.py:161] masked_lm_ids: 3677 3943 30 11 696 99 40 190 52 58 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
            "I0918 12:35:35.791600 139910923954048 create_pretraining_data.py:161] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
            "INFO:tensorflow:next_sentence_labels: 0\n",
            "I0918 12:35:35.791723 139910923954048 create_pretraining_data.py:161] next_sentence_labels: 0\n",
            "INFO:tensorflow:*** Example ***\n",
            "I0918 12:35:35.792338 139910923954048 create_pretraining_data.py:149] *** Example ***\n",
            "INFO:tensorflow:tokens: [CLS] [MASK] order to kill mt holy and exterminate our tribe to do so they needed the seed of hwa ##san royal family soo the chief of mae tempted the king of haw ##san [MASK] and gave a birth to vee who s to complete the sword [MASK] it wasn t [MASK] [SEP] here to protect our tribe and mt holy if vee is here [MASK] protect us why sending her [MASK] [MASK] [UNUSED_101] when the black [MASK] appears in [MASK] few days it ll be the last [MASK] for mae to perfect the sword they ll [MASK] to get hold of vee and complete [MASK] holy sword so mt [MASK] [MASK] using her as the sacrifice it s the wisdom of mt holy [MASK] protect our [SEP]\n",
            "I0918 12:35:35.792569 139910923954048 create_pretraining_data.py:151] tokens: [CLS] [MASK] order to kill mt holy and exterminate our tribe to do so they needed the seed of hwa ##san royal family soo the chief of mae tempted the king of haw ##san [MASK] and gave a birth to vee who s to complete the sword [MASK] it wasn t [MASK] [SEP] here to protect our tribe and mt holy if vee is here [MASK] protect us why sending her [MASK] [MASK] [UNUSED_101] when the black [MASK] appears in [MASK] few days it ll be the last [MASK] for mae to perfect the sword they ll [MASK] to get hold of vee and complete [MASK] holy sword so mt [MASK] [MASK] using her as the sacrifice it s the wisdom of mt holy [MASK] protect our [SEP]\n",
            "INFO:tensorflow:input_ids: 2 4 601 9 228 8234 734 13 11132 114 2270 9 31 43 49 812 7 9214 15 10138 19141 4018 258 24707 7 1500 15 2944 8004 7 974 15 31381 19141 4 13 435 10 2954 9 4154 75 8 9 1640 7 1677 4 11 282 12 4 3 45 9 1032 114 2270 13 8234 734 59 4154 17 45 4 1032 99 78 2783 68 4 4 31849 90 7 501 4 2752 19 4 398 360 11 47 37 7 200 4 28 2944 9 611 7 1677 49 47 4 9 44 252 15 4154 13 1640 4 734 1677 43 8234 4 4 1179 68 83 7 2627 11 8 7 4458 15 8234 734 4 1032 114 3\n",
            "I0918 12:35:35.792782 139910923954048 create_pretraining_data.py:161] input_ids: 2 4 601 9 228 8234 734 13 11132 114 2270 9 31 43 49 812 7 9214 15 10138 19141 4018 258 24707 7 1500 15 2944 8004 7 974 15 31381 19141 4 13 435 10 2954 9 4154 75 8 9 1640 7 1677 4 11 282 12 4 3 45 9 1032 114 2270 13 8234 734 59 4154 17 45 4 1032 99 78 2783 68 4 4 31849 90 7 501 4 2752 19 4 398 360 11 47 37 7 200 4 28 2944 9 611 7 1677 49 47 4 9 44 252 15 4154 13 1640 4 734 1677 43 8234 4 4 1179 68 83 7 2627 11 8 7 4458 15 8234 734 4 1032 114 3\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0918 12:35:35.792947 139910923954048 create_pretraining_data.py:161] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0918 12:35:35.793104 139910923954048 create_pretraining_data.py:161] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:masked_lm_positions: 1 34 47 51 65 71 72 73 77 80 88 89 97 105 110 111 121 124 125 0\n",
            "I0918 12:35:35.793215 139910923954048 create_pretraining_data.py:161] masked_lm_positions: 1 34 47 51 65 71 72 73 77 80 88 89 97 105 110 111 121 124 125 0\n",
            "INFO:tensorflow:masked_lm_ids: 19 6146 42 320 9 9 8234 734 1391 10 482 28 247 7 734 17 15 9 1032 0\n",
            "I0918 12:35:35.793327 139910923954048 create_pretraining_data.py:161] masked_lm_ids: 19 6146 42 320 9 9 8234 734 1391 10 482 28 247 7 734 17 15 9 1032 0\n",
            "INFO:tensorflow:masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0\n",
            "I0918 12:35:35.793444 139910923954048 create_pretraining_data.py:161] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0\n",
            "INFO:tensorflow:next_sentence_labels: 0\n",
            "I0918 12:35:35.793546 139910923954048 create_pretraining_data.py:161] next_sentence_labels: 0\n",
            "INFO:tensorflow:*** Example ***\n",
            "I0918 12:35:35.794191 139910923954048 create_pretraining_data.py:149] *** Example ***\n",
            "INFO:tensorflow:tokens: [CLS] let her go hey hey hey [SEP] s that left it [MASK] i know damn i ve been tricked it quote be done [MASK] those [MASK] i won t let [MASK] get [MASK] [MASK] s stone take the sacred stone [MASK] the mountains await further instructions there do you want me to do anything for ru bing [MASK] what master you like ru bing do you not [MASK] can give up my life for her i am touched by your [MASK] master everything [MASK] be back in order once we get [MASK] the [MASK] s [MASK] i will betroth ru bing to you then magnani ##mous of me is ##n t it love is [MASK] love does but the [MASK] stone is [UNUSED_227] [MASK] huan jen [SEP]\n",
            "I0918 12:35:35.794399 139910923954048 create_pretraining_data.py:151] tokens: [CLS] let her go hey hey hey [SEP] s that left it [MASK] i know damn i ve been tricked it quote be done [MASK] those [MASK] i won t let [MASK] get [MASK] [MASK] s stone take the sacred stone [MASK] the mountains await further instructions there do you want me to do anything for ru bing [MASK] what master you like ru bing do you not [MASK] can give up my life for her i am touched by your [MASK] master everything [MASK] be back in order once we get [MASK] the [MASK] s [MASK] i will betroth ru bing to you then magnani ##mous of me is ##n t it love is [MASK] love does but the [MASK] stone is [UNUSED_227] [MASK] huan jen [SEP]\n",
            "INFO:tensorflow:input_ids: 2 70 68 52 95 95 95 3 8 14 237 11 4 6 36 290 6 73 109 5135 11 6509 37 277 4 181 4 6 158 12 70 4 44 4 4 8 2038 94 7 2456 2038 4 7 3520 8062 1510 8910 50 31 5 72 18 9 31 162 28 4916 5329 4 16 1167 5 48 4916 5329 31 5 39 4 34 131 51 25 146 28 68 6 139 2433 119 27 4 1167 189 4 37 85 19 601 348 20 44 4 7 4 8 4 6 79 16387 4916 5329 9 5 110 29283 30415 15 18 17 88 12 11 113 17 4 113 210 42 7 4 2038 17 31975 4 6840 3849 3\n",
            "I0918 12:35:35.794584 139910923954048 create_pretraining_data.py:161] input_ids: 2 70 68 52 95 95 95 3 8 14 237 11 4 6 36 290 6 73 109 5135 11 6509 37 277 4 181 4 6 158 12 70 4 44 4 4 8 2038 94 7 2456 2038 4 7 3520 8062 1510 8910 50 31 5 72 18 9 31 162 28 4916 5329 4 16 1167 5 48 4916 5329 31 5 39 4 34 131 51 25 146 28 68 6 139 2433 119 27 4 1167 189 4 37 85 19 601 348 20 44 4 7 4 8 4 6 79 16387 4916 5329 9 5 110 29283 30415 15 18 17 88 12 11 113 17 4 113 210 42 7 4 2038 17 31975 4 6840 3849 3\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0918 12:35:35.794783 139910923954048 create_pretraining_data.py:161] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0918 12:35:35.794948 139910923954048 create_pretraining_data.py:161] segment_ids: 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:masked_lm_positions: 12 21 24 26 31 33 34 41 58 68 81 84 92 94 96 115 120 123 124 0\n",
            "I0918 12:35:35.795056 139910923954048 create_pretraining_data.py:161] masked_lm_positions: 12 21 24 26 31 33 34 41 58 68 81 84 92 94 96 115 120 123 124 0\n",
            "INFO:tensorflow:masked_lm_ids: 50 191 119 7908 403 7 973 9 1167 6 113 79 85 973 2038 83 2456 65 41 0\n",
            "I0918 12:35:35.795161 139910923954048 create_pretraining_data.py:161] masked_lm_ids: 50 191 119 7908 403 7 973 9 1167 6 113 79 85 973 2038 83 2456 65 41 0\n",
            "INFO:tensorflow:masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0\n",
            "I0918 12:35:35.795269 139910923954048 create_pretraining_data.py:161] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0\n",
            "INFO:tensorflow:next_sentence_labels: 1\n",
            "I0918 12:35:35.795363 139910923954048 create_pretraining_data.py:161] next_sentence_labels: 1\n",
            "INFO:tensorflow:*** Example ***\n",
            "I0918 12:35:35.795993 139910923954048 create_pretraining_data.py:149] *** Example ***\n",
            "INFO:tensorflow:tokens: [CLS] you don t love [MASK] you don t love me at all sobs you [MASK] any better [MASK] y are i got toast oh thanks love what [MASK] you mum i [MASK] i wanted it off my [MASK] i delvian [MASK] re mad you know it it was nothin faith you won t [MASK] anything will you to your sisters mum if i was enrich say anything i d [MASK] said it years ago [MASK] [SEP] sorry oh what [MASK] i done mum what am i gonna do [MASK] has ##n t ever looked [MASK] me how he did in that park [MASK] ever that s cos all [MASK] s seein is [MASK] sex and nothing else and that s how men are i [MASK] sorry [SEP]\n",
            "I0918 12:35:35.796211 139910923954048 create_pretraining_data.py:151] tokens: [CLS] you don t love [MASK] you don t love me at all sobs you [MASK] any better [MASK] y are i got toast oh thanks love what [MASK] you mum i [MASK] i wanted it off my [MASK] i delvian [MASK] re mad you know it it was nothin faith you won t [MASK] anything will you to your sisters mum if i was enrich say anything i d [MASK] said it years ago [MASK] [SEP] sorry oh what [MASK] i done mum what am i gonna do [MASK] has ##n t ever looked [MASK] me how he did in that park [MASK] ever that s cos all [MASK] s seein is [MASK] sex and nothing else and that s how men are i [MASK] sorry [SEP]\n",
            "INFO:tensorflow:input_ids: 2 5 30 12 113 4 5 30 12 113 18 64 40 6848 5 4 152 182 4 612 38 6 63 2400 56 211 113 16 4 5 1807 6 4 6 246 11 125 25 4 6 8078 4 33 885 5 36 11 11 35 1203 1200 5 158 12 4 162 79 5 9 27 2928 1807 59 6 35 21928 96 162 6 86 4 135 11 213 349 4 3 136 56 16 4 6 277 1807 16 139 6 80 31 4 126 88 12 225 766 4 18 67 21 76 19 14 1082 4 225 14 8 1138 40 4 8 22769 17 4 726 13 166 274 13 14 8 67 404 38 6 4 136 3\n",
            "I0918 12:35:35.796388 139910923954048 create_pretraining_data.py:161] input_ids: 2 5 30 12 113 4 5 30 12 113 18 64 40 6848 5 4 152 182 4 612 38 6 63 2400 56 211 113 16 4 5 1807 6 4 6 246 11 125 25 4 6 8078 4 33 885 5 36 11 11 35 1203 1200 5 158 12 4 162 79 5 9 27 2928 1807 59 6 35 21928 96 162 6 86 4 135 11 213 349 4 3 136 56 16 4 6 277 1807 16 139 6 80 31 4 126 88 12 225 766 4 18 67 21 76 19 14 1082 4 225 14 8 1138 40 4 8 22769 17 4 726 13 166 274 13 14 8 67 404 38 6 4 136 3\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0918 12:35:35.796562 139910923954048 create_pretraining_data.py:161] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0918 12:35:35.796752 139910923954048 create_pretraining_data.py:161] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:masked_lm_positions: 5 15 18 28 32 38 40 41 54 65 70 75 80 89 95 103 109 113 125 0\n",
            "I0918 12:35:35.796865 139910923954048 create_pretraining_data.py:161] masked_lm_positions: 5 15 18 28 32 38 40 41 54 65 70 75 80 89 95 103 109 113 125 0\n",
            "INFO:tensorflow:masked_lm_ids: 18 3180 45 5321 246 1775 171 5 96 80 29 6 29 21 64 1200 21 7 26 0\n",
            "I0918 12:35:35.796970 139910923954048 create_pretraining_data.py:161] masked_lm_ids: 18 3180 45 5321 246 1775 171 5 96 80 29 6 29 21 64 1200 21 7 26 0\n",
            "INFO:tensorflow:masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0\n",
            "I0918 12:35:35.797082 139910923954048 create_pretraining_data.py:161] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0\n",
            "INFO:tensorflow:next_sentence_labels: 0\n",
            "I0918 12:35:35.797177 139910923954048 create_pretraining_data.py:161] next_sentence_labels: 0\n",
            "INFO:tensorflow:*** Example ***\n",
            "I0918 12:35:35.797844 139910923954048 create_pretraining_data.py:149] *** Example ***\n",
            "INFO:tensorflow:tokens: [CLS] advertisement in the supermarket red mountain ##bike missing [SEP] shortlisted for best laure tv illusionist groves ##nor house on the 23 ##rd amazing you wouldn t think that was possible same as a hurricane driving a [MASK] of grass into a tree [MASK] maybe they have graduate t made a decision [MASK] it for your after dinners it s in the wrist action with my luck [MASK] [MASK] take a shuffle toupee ##s off talking of wrist action jonathan ross called i agreed [MASK] [MASK] [MASK] talk show at a [MASK] bar mitz [MASK] last [MASK] i wonder if i should cancel the guy s so hip and [MASK] ##ext ##ual with the [MASK] last time [MASK] said two words and the whole place fell about [SEP]\n",
            "I0918 12:35:35.798058 139910923954048 create_pretraining_data.py:151] tokens: [CLS] advertisement in the supermarket red mountain ##bike missing [SEP] shortlisted for best laure tv illusionist groves ##nor house on the 23 ##rd amazing you wouldn t think that was possible same as a hurricane driving a [MASK] of grass into a tree [MASK] maybe they have graduate t made a decision [MASK] it for your after dinners it s in the wrist action with my luck [MASK] [MASK] take a shuffle toupee ##s off talking of wrist action jonathan ross called i agreed [MASK] [MASK] [MASK] talk show at a [MASK] bar mitz [MASK] last [MASK] i wonder if i should cancel the guy s so hip and [MASK] ##ext ##ual with the [MASK] last time [MASK] said two words and the whole place fell about [SEP]\n",
            "INFO:tensorflow:input_ids: 2 11390 19 7 11759 751 1491 28727 1412 3 21367 28 253 22365 593 21516 18813 19223 266 24 7 2863 3482 1084 5 318 12 74 14 35 901 281 83 10 3507 1186 10 4 15 3210 173 10 779 4 155 49 29 7447 12 226 10 1331 4 11 28 27 202 13896 11 8 19 7 6619 1242 41 25 518 4 4 94 10 15767 14827 57 125 271 15 6619 1242 2076 1360 343 6 1977 4 4 4 172 257 64 10 4 1302 18893 4 200 4 6 757 59 6 133 2461 7 203 8 43 3875 13 4 31257 13234 41 7 4 200 92 4 135 127 713 13 7 359 224 838 62 3\n",
            "I0918 12:35:35.891359 139910923954048 create_pretraining_data.py:161] input_ids: 2 11390 19 7 11759 751 1491 28727 1412 3 21367 28 253 22365 593 21516 18813 19223 266 24 7 2863 3482 1084 5 318 12 74 14 35 901 281 83 10 3507 1186 10 4 15 3210 173 10 779 4 155 49 29 7447 12 226 10 1331 4 11 28 27 202 13896 11 8 19 7 6619 1242 41 25 518 4 4 94 10 15767 14827 57 125 271 15 6619 1242 2076 1360 343 6 1977 4 4 4 172 257 64 10 4 1302 18893 4 200 4 6 757 59 6 133 2461 7 203 8 43 3875 13 4 31257 13234 41 7 4 200 92 4 135 127 713 13 7 359 224 838 62 3\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0918 12:35:35.891725 139910923954048 create_pretraining_data.py:161] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0918 12:35:35.891955 139910923954048 create_pretraining_data.py:161] segment_ids: 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:masked_lm_positions: 13 23 37 43 47 52 67 68 71 74 84 85 86 91 94 96 109 114 117 0\n",
            "I0918 12:35:35.892134 139910923954048 create_pretraining_data.py:161] masked_lm_positions: 13 23 37 43 47 52 67 68 71 74 84 85 86 91 94 96 109 114 117 0\n",
            "INFO:tensorflow:masked_lm_ids: 2203 1084 4378 21367 88 340 6 86 398 125 9 31 87 11945 19078 507 31510 3317 21 0\n",
            "I0918 12:35:35.892295 139910923954048 create_pretraining_data.py:161] masked_lm_ids: 2203 1084 4378 21367 88 340 6 86 398 125 9 31 87 11945 19078 507 31510 3317 21 0\n",
            "INFO:tensorflow:masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0\n",
            "I0918 12:35:35.892465 139910923954048 create_pretraining_data.py:161] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0\n",
            "INFO:tensorflow:next_sentence_labels: 1\n",
            "I0918 12:35:35.892604 139910923954048 create_pretraining_data.py:161] next_sentence_labels: 1\n",
            "INFO:tensorflow:*** Example ***\n",
            "I0918 12:35:35.893571 139910923954048 create_pretraining_data.py:149] *** Example ***\n",
            "INFO:tensorflow:tokens: [CLS] apart from you that is we re just going [MASK] sleep next to each other aren t we nothing else [MASK] good good night [MASK] i [MASK] t understand it s damn strange [SEP] [MASK] can sit and laugh but this is serious barbara understand [SEP]\n",
            "I0918 12:35:35.893817 139910923954048 create_pretraining_data.py:151] tokens: [CLS] apart from you that is we re just going [MASK] sleep next to each other aren t we nothing else [MASK] good good night [MASK] i [MASK] t understand it s damn strange [SEP] [MASK] can sit and laugh but this is serious barbara understand [SEP]\n",
            "INFO:tensorflow:input_ids: 2 1282 81 5 14 17 20 33 46 106 4 416 288 9 471 183 438 12 20 166 274 4 71 71 169 4 6 4 12 234 11 8 290 683 3 4 34 395 13 981 42 22 17 581 12182 234 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0918 12:35:35.894011 139910923954048 create_pretraining_data.py:161] input_ids: 2 1282 81 5 14 17 20 33 46 106 4 416 288 9 471 183 438 12 20 166 274 4 71 71 169 4 6 4 12 234 11 8 290 683 3 4 34 395 13 981 42 22 17 581 12182 234 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0918 12:35:35.894189 139910923954048 create_pretraining_data.py:161] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0918 12:35:35.894348 139910923954048 create_pretraining_data.py:161] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:masked_lm_positions: 10 15 21 25 27 35 44 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0918 12:35:35.894457 139910923954048 create_pretraining_data.py:161] masked_lm_positions: 10 15 21 25 27 35 44 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:masked_lm_ids: 9 183 23 2917 30 5 5 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0918 12:35:35.894564 139910923954048 create_pretraining_data.py:161] masked_lm_ids: 9 183 23 2917 30 5 5 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
            "I0918 12:35:35.894697 139910923954048 create_pretraining_data.py:161] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
            "INFO:tensorflow:next_sentence_labels: 1\n",
            "I0918 12:35:35.894796 139910923954048 create_pretraining_data.py:161] next_sentence_labels: 1\n",
            "INFO:tensorflow:*** Example ***\n",
            "I0918 12:35:35.895539 139910923954048 create_pretraining_data.py:149] *** Example ***\n",
            "INFO:tensorflow:tokens: [CLS] i ve been in bad patches so many times and came home with so much stock little [MASK] like [MASK] [MASK] [MASK] pack it on the pier i [MASK] find the fish always and i will this time so don t fuck [MASK] me aye aye skip put them closer murph closer give them a goddamn [MASK] aye aye cap you heard him boys boss ain t happy double time [SEP] all right let debbie [MASK] to get some sleep [MASK] s easy for you to say [MASK] [MASK] t think you d even [MASK] talk to me sherry and i m not a little girl any more and i know that you ve probably heard some things that i m [MASK] very [MASK] [MASK] well [SEP]\n",
            "I0918 12:35:35.895789 139910923954048 create_pretraining_data.py:151] tokens: [CLS] i ve been in bad patches so many times and came home with so much stock little [MASK] like [MASK] [MASK] [MASK] pack it on the pier i [MASK] find the fish always and i will this time so don t fuck [MASK] me aye aye skip put them closer murph closer give them a goddamn [MASK] aye aye cap you heard him boys boss ain t happy double time [SEP] all right let debbie [MASK] to get some sleep [MASK] s easy for you to say [MASK] [MASK] t think you d even [MASK] talk to me sherry and i m not a little girl any more and i know that you ve probably heard some things that i m [MASK] very [MASK] [MASK] well [SEP]\n",
            "INFO:tensorflow:input_ids: 2 6 73 109 19 215 6148 43 302 514 13 236 174 41 43 140 3286 111 4 48 4 4 4 1387 11 24 7 3181 6 4 164 7 596 184 13 6 79 22 92 43 30 12 275 4 18 1722 1722 775 156 105 1370 1185 1370 131 105 10 648 4 1722 1722 1108 5 319 60 549 782 382 12 294 867 92 3 40 54 70 1827 4 9 44 102 416 4 8 320 28 5 9 96 4 4 12 74 5 86 142 4 172 9 18 1187 13 6 26 39 10 111 231 152 129 13 6 36 14 5 73 429 319 102 185 14 6 26 4 124 4 4 69 3\n",
            "I0918 12:35:35.895998 139910923954048 create_pretraining_data.py:161] input_ids: 2 6 73 109 19 215 6148 43 302 514 13 236 174 41 43 140 3286 111 4 48 4 4 4 1387 11 24 7 3181 6 4 164 7 596 184 13 6 79 22 92 43 30 12 275 4 18 1722 1722 775 156 105 1370 1185 1370 131 105 10 648 4 1722 1722 1108 5 319 60 549 782 382 12 294 867 92 3 40 54 70 1827 4 9 44 102 416 4 8 320 28 5 9 96 4 4 12 74 5 86 142 4 172 9 18 1187 13 6 26 39 10 111 231 152 129 13 6 36 14 5 73 429 319 102 185 14 6 26 4 124 4 4 69 3\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0918 12:35:35.896170 139910923954048 create_pretraining_data.py:161] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0918 12:35:35.896327 139910923954048 create_pretraining_data.py:161] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:masked_lm_positions: 18 20 21 22 29 43 57 75 76 81 88 89 95 96 111 120 122 124 125 0\n",
            "I0918 12:35:35.896436 139910923954048 create_pretraining_data.py:161] masked_lm_positions: 18 20 21 22 29 43 57 75 76 81 88 89 95 96 111 120 122 124 125 0\n",
            "INFO:tensorflow:masked_lm_ids: 549 5 97 9 184 41 6328 8 247 14 6 112 243 172 36 6 39 989 15 0\n",
            "I0918 12:35:35.896544 139910923954048 create_pretraining_data.py:161] masked_lm_ids: 549 5 97 9 184 41 6328 8 247 14 6 112 243 172 36 6 39 989 15 0\n",
            "INFO:tensorflow:masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0\n",
            "I0918 12:35:35.896675 139910923954048 create_pretraining_data.py:161] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0\n",
            "INFO:tensorflow:next_sentence_labels: 1\n",
            "I0918 12:35:35.896783 139910923954048 create_pretraining_data.py:161] next_sentence_labels: 1\n",
            "INFO:tensorflow:*** Example ***\n",
            "I0918 12:35:35.897457 139910923954048 create_pretraining_data.py:149] *** Example ***\n",
            "INFO:tensorflow:tokens: [CLS] oh god his skull ain t even fused together man [SEP] gettin scoop ##ed up [MASK] the field nothingness [SEP]\n",
            "I0918 12:35:35.897626 139910923954048 create_pretraining_data.py:151] tokens: [CLS] oh god his skull ain t even fused together man [SEP] gettin scoop ##ed up [MASK] the field nothingness [SEP]\n",
            "INFO:tensorflow:input_ids: 2 56 137 87 3871 382 12 142 10858 269 89 3 1228 10734 161 51 4 7 1313 20323 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0918 12:35:35.897810 139910923954048 create_pretraining_data.py:161] input_ids: 2 56 137 87 3871 382 12 142 10858 269 89 3 1228 10734 161 51 4 7 1313 20323 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0918 12:35:35.897979 139910923954048 create_pretraining_data.py:161] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0918 12:35:35.898136 139910923954048 create_pretraining_data.py:161] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:masked_lm_positions: 1 16 19 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0918 12:35:35.898243 139910923954048 create_pretraining_data.py:161] masked_lm_positions: 1 16 19 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:masked_lm_ids: 56 119 19260 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0918 12:35:35.898345 139910923954048 create_pretraining_data.py:161] masked_lm_ids: 56 119 19260 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:masked_lm_weights: 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
            "I0918 12:35:35.898457 139910923954048 create_pretraining_data.py:161] masked_lm_weights: 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
            "INFO:tensorflow:next_sentence_labels: 1\n",
            "I0918 12:35:35.898564 139910923954048 create_pretraining_data.py:161] next_sentence_labels: 1\n",
            "INFO:tensorflow:*** Example ***\n",
            "I0918 12:35:35.899245 139910923954048 create_pretraining_data.py:149] *** Example ***\n",
            "INFO:tensorflow:tokens: [CLS] ryan [MASK] t swear [SEP] [MASK] [MASK] true is that he s exhausted so we [MASK] to try to find [MASK] [MASK] other than the haldol to help him [MASK] good thank you i ll have dr presto ##p ##nik write up a prescription hello chris sister [SEP]\n",
            "I0918 12:35:35.899405 139910923954048 create_pretraining_data.py:151] tokens: [CLS] ryan [MASK] t swear [SEP] [MASK] [MASK] true is that he s exhausted so we [MASK] to try to find [MASK] [MASK] other than the haldol to help him [MASK] good thank you i ll have dr presto ##p ##nik write up a prescription hello chris sister [SEP]\n",
            "INFO:tensorflow:input_ids: 2 7219 4 12 1264 3 4 4 381 17 14 21 8 5696 43 20 4 9 247 9 164 4 4 183 197 7 14686 9 153 60 4 71 147 5 6 47 29 473 8255 2402 16861 918 51 10 5495 212 3214 417 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0918 12:35:35.899578 139910923954048 create_pretraining_data.py:161] input_ids: 2 7219 4 12 1264 3 4 4 381 17 14 21 8 5696 43 20 4 9 247 9 164 4 4 183 197 7 14686 9 153 60 4 71 147 5 6 47 29 473 8255 2402 16861 918 51 10 5495 212 3214 417 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0918 12:35:35.899774 139910923954048 create_pretraining_data.py:161] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0918 12:35:35.899933 139910923954048 create_pretraining_data.py:161] segment_ids: 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:masked_lm_positions: 2 6 7 16 21 22 30 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0918 12:35:35.900052 139910923954048 create_pretraining_data.py:161] masked_lm_positions: 2 6 7 16 21 22 30 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:masked_lm_ids: 30 16 17 128 10 2883 416 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0918 12:35:35.900156 139910923954048 create_pretraining_data.py:161] masked_lm_ids: 30 16 17 128 10 2883 416 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
            "I0918 12:35:35.900267 139910923954048 create_pretraining_data.py:161] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
            "INFO:tensorflow:next_sentence_labels: 0\n",
            "I0918 12:35:35.900360 139910923954048 create_pretraining_data.py:161] next_sentence_labels: 0\n",
            "INFO:tensorflow:*** Example ***\n",
            "I0918 12:35:35.901061 139910923954048 create_pretraining_data.py:149] *** Example ***\n",
            "INFO:tensorflow:tokens: [CLS] evacuation warning evacuation warning evacuation [MASK] [MASK] warning [SEP] the area get everyone away [MASK] the [MASK] core [MASK] radiation gear is on [MASK] 10 commander javio wait sir this prowler is non operational there s [MASK] corpses component in the in the fro ##oni ##um drive causing instabilit ##ies in the stabilise ##r it may have been fixed if i could just have a look very [MASK] chiana i ##misunderstanding the commander was [MASK] be the last one to evacuate it s funny i believe just the opposite we could both leave continue our earlier discussion it won t work twice what was that the tissue sample [MASK] succeeded then i m [MASK] going [MASK] die [MASK] you once said to me [MASK] [MASK] die [SEP]\n",
            "I0918 12:35:35.901299 139910923954048 create_pretraining_data.py:151] tokens: [CLS] evacuation warning evacuation warning evacuation [MASK] [MASK] warning [SEP] the area get everyone away [MASK] the [MASK] core [MASK] radiation gear is on [MASK] 10 commander javio wait sir this prowler is non operational there s [MASK] corpses component in the in the fro ##oni ##um drive causing instabilit ##ies in the stabilise ##r it may have been fixed if i could just have a look very [MASK] chiana i ##misunderstanding the commander was [MASK] be the last one to evacuate it s funny i believe just the opposite we could both leave continue our earlier discussion it won t work twice what was that the tissue sample [MASK] succeeded then i m [MASK] going [MASK] die [MASK] you once said to me [MASK] [MASK] die [SEP]\n",
            "INFO:tensorflow:input_ids: 2 4928 1862 4928 1862 4928 4 4 1862 3 7 1383 44 405 163 4 7 4 5494 4 6821 4315 17 24 4 554 2178 9531 150 205 22 2987 17 5086 11124 50 8 4 8381 10938 19 7 19 7 10266 22658 3816 617 6253 19079 1364 19 7 14707 440 11 245 29 109 2281 59 6 93 46 29 10 82 124 4 1662 6 4968 7 2178 35 4 37 7 200 61 9 4374 11 8 519 6 223 46 7 4632 20 93 378 218 1337 114 1582 2966 11 158 12 154 1066 16 35 14 7 3798 3737 4 7544 110 6 26 4 106 4 307 4 5 348 135 9 18 4 4 307 3\n",
            "I0918 12:35:35.901498 139910923954048 create_pretraining_data.py:161] input_ids: 2 4928 1862 4928 1862 4928 4 4 1862 3 7 1383 44 405 163 4 7 4 5494 4 6821 4315 17 24 4 554 2178 9531 150 205 22 2987 17 5086 11124 50 8 4 8381 10938 19 7 19 7 10266 22658 3816 617 6253 19079 1364 19 7 14707 440 11 245 29 109 2281 59 6 93 46 29 10 82 124 4 1662 6 4968 7 2178 35 4 37 7 200 61 9 4374 11 8 519 6 223 46 7 4632 20 93 378 218 1337 114 1582 2966 11 158 12 154 1066 16 35 14 7 3798 3737 4 7544 110 6 26 4 106 4 307 4 5 348 135 9 18 4 4 307 3\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0918 12:35:35.999590 139910923954048 create_pretraining_data.py:161] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0918 12:35:35.999995 139910923954048 create_pretraining_data.py:161] segment_ids: 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:masked_lm_positions: 6 7 15 17 19 24 37 38 41 61 68 71 75 109 114 116 118 124 125 0\n",
            "I0918 12:35:36.009329 139910923954048 create_pretraining_data.py:161] masked_lm_positions: 6 7 15 17 19 24 37 38 41 61 68 71 75 109 114 116 118 124 125 0\n",
            "INFO:tensorflow:masked_lm_ids: 1862 4928 81 6995 1413 1459 10 15200 7 6 71 171 9 941 39 9 83 5 79 0\n",
            "I0918 12:35:36.009573 139910923954048 create_pretraining_data.py:161] masked_lm_ids: 1862 4928 81 6995 1413 1459 10 15200 7 6 71 171 9 941 39 9 83 5 79 0\n",
            "INFO:tensorflow:masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0\n",
            "I0918 12:35:36.009747 139910923954048 create_pretraining_data.py:161] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0\n",
            "INFO:tensorflow:next_sentence_labels: 0\n",
            "I0918 12:35:36.009867 139910923954048 create_pretraining_data.py:161] next_sentence_labels: 0\n",
            "INFO:tensorflow:*** Example ***\n",
            "I0918 12:35:36.010805 139910923954048 create_pretraining_data.py:149] *** Example ***\n",
            "INFO:tensorflow:tokens: [CLS] i [MASK] seen them come and go [MASK] day [MASK] laid eyes on you i said [MASK] s gonna be a good one you can t be good [MASK] you love it [SEP] do you [MASK] me governor do you [SEP]\n",
            "I0918 12:35:36.011048 139910923954048 create_pretraining_data.py:151] tokens: [CLS] i [MASK] seen them come and go [MASK] day [MASK] laid eyes on you i said [MASK] s gonna be a good one you can t be good [MASK] you love it [SEP] do you [MASK] me governor do you [SEP]\n",
            "INFO:tensorflow:input_ids: 2 6 4 314 105 58 13 52 4 160 4 2162 413 24 5 6 135 4 8 80 37 10 71 61 5 34 12 37 71 4 5 113 11 3 31 5 4 18 3541 31 5 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0918 12:35:36.011242 139910923954048 create_pretraining_data.py:161] input_ids: 2 6 4 314 105 58 13 52 4 160 4 2162 413 24 5 6 135 4 8 80 37 10 71 61 5 34 12 37 71 4 5 113 11 3 31 5 4 18 3541 31 5 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0918 12:35:36.011423 139910923954048 create_pretraining_data.py:161] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0918 12:35:36.011590 139910923954048 create_pretraining_data.py:161] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:masked_lm_positions: 2 8 10 17 29 36 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0918 12:35:36.011734 139910923954048 create_pretraining_data.py:161] masked_lm_positions: 2 8 10 17 29 36 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:masked_lm_ids: 73 7 6 53 836 447 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0918 12:35:36.011851 139910923954048 create_pretraining_data.py:161] masked_lm_ids: 73 7 6 53 836 447 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
            "I0918 12:35:36.011988 139910923954048 create_pretraining_data.py:161] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
            "INFO:tensorflow:next_sentence_labels: 1\n",
            "I0918 12:35:36.012104 139910923954048 create_pretraining_data.py:161] next_sentence_labels: 1\n",
            "INFO:tensorflow:*** Example ***\n",
            "I0918 12:35:36.013029 139910923954048 create_pretraining_data.py:149] *** Example ***\n",
            "INFO:tensorflow:tokens: [CLS] but [MASK] decides she doesn t want [MASK] [MASK] either until she find ##s out that ernie does [MASK] then she s got somethin to bargain with ernie had this bright red full ##y restored [UNK] camar ##o i mean [MASK] beauty and she wants it so he [MASK] his car for her daughter novalee oh my god [MASK] he told me that [MASK] i knew he was the pick of the litter i [MASK] so happy [MASK] finally found me a [MASK] oh i m also [MASK] what both [SEP] eight [MASK] nine then eight then nine eight and then nine eight and nine but the one i ve been used to [MASK] [MASK] eight and a half then eight then eight and a half [SEP]\n",
            "I0918 12:35:36.013289 139910923954048 create_pretraining_data.py:151] tokens: [CLS] but [MASK] decides she doesn t want [MASK] [MASK] either until she find ##s out that ernie does [MASK] then she s got somethin to bargain with ernie had this bright red full ##y restored [UNK] camar ##o i mean [MASK] beauty and she wants it so he [MASK] his car for her daughter novalee oh my god [MASK] he told me that [MASK] i knew he was the pick of the litter i [MASK] so happy [MASK] finally found me a [MASK] oh i m also [MASK] what both [SEP] eight [MASK] nine then eight then nine eight and then nine eight and nine but the one i ve been used to [MASK] [MASK] eight and a half then eight then eight and a half [SEP]\n",
            "INFO:tensorflow:input_ids: 2 42 4 6084 53 208 12 72 4 4 625 412 53 164 57 55 14 3471 210 4 110 53 8 63 1111 9 9573 41 3471 97 22 1837 751 481 221 8169 1 19183 299 6 132 4 863 13 53 401 11 43 21 4 87 201 28 68 515 1322 56 25 137 4 21 196 18 14 4 6 313 21 35 7 505 15 7 3979 6 4 43 294 4 715 312 18 10 4 56 6 26 465 4 16 378 3 728 4 928 110 728 110 928 728 13 110 928 728 13 928 42 7 61 6 73 109 352 9 4 4 728 13 10 450 110 728 110 728 13 10 450 3\n",
            "I0918 12:35:36.013492 139910923954048 create_pretraining_data.py:161] input_ids: 2 42 4 6084 53 208 12 72 4 4 625 412 53 164 57 55 14 3471 210 4 110 53 8 63 1111 9 9573 41 3471 97 22 1837 751 481 221 8169 1 19183 299 6 132 4 863 13 53 401 11 43 21 4 87 201 28 68 515 1322 56 25 137 4 21 196 18 14 4 6 313 21 35 7 505 15 7 3979 6 4 43 294 4 715 312 18 10 4 56 6 26 465 4 16 378 3 728 4 928 110 728 110 928 728 13 110 928 728 13 928 42 7 61 6 73 109 352 9 4 4 728 13 10 450 110 728 110 728 13 10 450 3\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0918 12:35:36.013704 139910923954048 create_pretraining_data.py:161] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0918 12:35:36.013884 139910923954048 create_pretraining_data.py:161] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:masked_lm_positions: 2 8 9 19 28 35 36 41 49 59 64 75 78 83 88 93 102 114 115 0\n",
            "I0918 12:35:36.014005 139910923954048 create_pretraining_data.py:161] masked_lm_positions: 2 8 9 19 28 35 36 41 49 59 64 75 78 83 88 93 102 114 115 0\n",
            "INFO:tensorflow:masked_lm_ids: 53 3360 2589 13 3471 8169 1 10 13414 90 1322 139 6 1886 1828 13 928 17 184 0\n",
            "I0918 12:35:36.014116 139910923954048 create_pretraining_data.py:161] masked_lm_ids: 53 3360 2589 13 3471 8169 1 10 13414 90 1322 139 6 1886 1828 13 928 17 184 0\n",
            "INFO:tensorflow:masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0\n",
            "I0918 12:35:36.014229 139910923954048 create_pretraining_data.py:161] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0\n",
            "INFO:tensorflow:next_sentence_labels: 1\n",
            "I0918 12:35:36.014325 139910923954048 create_pretraining_data.py:161] next_sentence_labels: 1\n",
            "INFO:tensorflow:*** Example ***\n",
            "I0918 12:35:36.015133 139910923954048 create_pretraining_data.py:149] *** Example ***\n",
            "INFO:tensorflow:tokens: [CLS] a [MASK] emph ##ys ##ema it [MASK] nothin serious you know he makes that noise whenever he [MASK] ##s himself who s thorny forney forney hull brilliant man lives in the libary brilliant there [MASK] no tellin what he might have done in this [MASK] if he d been allowed to finish his [MASK] why didn t he the lord gives us obstacles i hope you re not hungry cause it s tuesday friday [MASK] the best breakfast day they [MASK] [MASK] i m lexie lexie coop hi hi where d all these flowers come from all [MASK] you re a big celebrity they re reporters here [MASK] up see tv they ve [MASK] here all night [SEP] i know [MASK] thing [SEP]\n",
            "I0918 12:35:36.015379 139910923954048 create_pretraining_data.py:151] tokens: [CLS] a [MASK] emph ##ys ##ema it [MASK] nothin serious you know he makes that noise whenever he [MASK] ##s himself who s thorny forney forney hull brilliant man lives in the libary brilliant there [MASK] no tellin what he might have done in this [MASK] if he d been allowed to finish his [MASK] why didn t he the lord gives us obstacles i hope you re not hungry cause it s tuesday friday [MASK] the best breakfast day they [MASK] [MASK] i m lexie lexie coop hi hi where d all these flowers come from all [MASK] you re a big celebrity they re reporters here [MASK] up see tv they ve [MASK] here all night [SEP] i know [MASK] thing [SEP]\n",
            "INFO:tensorflow:input_ids: 2 10 4 28519 11253 18918 11 4 1203 581 5 36 21 472 14 1840 2144 21 4 57 693 75 8 14946 1349 1349 6502 2352 89 652 19 7 12168 2352 50 4 23 4348 16 21 272 29 277 19 22 4 59 21 86 109 1702 9 1001 87 4 78 112 12 21 7 630 1497 99 13696 6 375 5 33 39 948 338 11 8 2355 1274 4 7 253 1506 160 49 4 4 6 26 3487 3487 13448 217 217 103 86 40 151 1318 58 81 40 4 5 33 10 148 8109 49 33 7734 45 4 51 77 593 49 73 4 45 40 169 3 6 36 4 143 3 0 0 0 0\n",
            "I0918 12:35:36.015588 139910923954048 create_pretraining_data.py:161] input_ids: 2 10 4 28519 11253 18918 11 4 1203 581 5 36 21 472 14 1840 2144 21 4 57 693 75 8 14946 1349 1349 6502 2352 89 652 19 7 12168 2352 50 4 23 4348 16 21 272 29 277 19 22 4 59 21 86 109 1702 9 1001 87 4 78 112 12 21 7 630 1497 99 13696 6 375 5 33 39 948 338 11 8 2355 1274 4 7 253 1506 160 49 4 4 6 26 3487 3487 13448 217 217 103 86 40 151 1318 58 81 40 4 5 33 10 148 8109 49 33 7734 45 4 51 77 593 49 73 4 45 40 169 3 6 36 4 143 3 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0\n",
            "I0918 12:35:36.015778 139910923954048 create_pretraining_data.py:161] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 0 0 0 0\n",
            "I0918 12:35:36.015953 139910923954048 create_pretraining_data.py:161] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 0 0 0 0\n",
            "INFO:tensorflow:masked_lm_positions: 2 7 18 35 45 54 59 60 75 81 82 87 98 100 102 108 114 119 121 0\n",
            "I0918 12:35:36.016074 139910923954048 create_pretraining_data.py:161] masked_lm_positions: 2 7 18 35 45 54 59 60 75 81 82 87 98 100 102 108 114 119 121 0\n",
            "INFO:tensorflow:masked_lm_ids: 111 8 11982 8 242 20406 7 630 17 29 5120 13448 120 33 148 3634 109 6 10 0\n",
            "I0918 12:35:36.016182 139910923954048 create_pretraining_data.py:161] masked_lm_ids: 111 8 11982 8 242 20406 7 630 17 29 5120 13448 120 33 148 3634 109 6 10 0\n",
            "INFO:tensorflow:masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0\n",
            "I0918 12:35:36.016292 139910923954048 create_pretraining_data.py:161] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0\n",
            "INFO:tensorflow:next_sentence_labels: 1\n",
            "I0918 12:35:36.016388 139910923954048 create_pretraining_data.py:161] next_sentence_labels: 1\n",
            "INFO:tensorflow:*** Example ***\n",
            "I0918 12:35:36.017126 139910923954048 create_pretraining_data.py:149] *** Example ***\n",
            "INFO:tensorflow:tokens: [CLS] is this because i forgot how can you forget something like that how can you forget something like what don t you remember who died don t you remember who died don t [MASK] [MASK] [MASK] after where are we where [MASK] [MASK] meditate to be why is this happening to me [MASK] you were starting to become cold i think your time has come now time to open the box don t listen to her she s a [MASK] do not [MASK] a word he says listen to [MASK] i [MASK] [MASK] it s difficult to grasp what s going on and you are what the other side the other side [SEP] i am [MASK] other side [MASK] other side of [MASK] but not you [SEP]\n",
            "I0918 12:35:36.017336 139910923954048 create_pretraining_data.py:151] tokens: [CLS] is this because i forgot how can you forget something like that how can you forget something like what don t you remember who died don t you remember who died don t [MASK] [MASK] [MASK] after where are we where [MASK] [MASK] meditate to be why is this happening to me [MASK] you were starting to become cold i think your time has come now time to open the box don t listen to her she s a [MASK] do not [MASK] a word he says listen to [MASK] i [MASK] [MASK] it s difficult to grasp what s going on and you are what the other side the other side [SEP] i am [MASK] other side [MASK] other side of [MASK] but not you [SEP]\n",
            "INFO:tensorflow:input_ids: 2 17 22 134 6 852 67 34 5 410 116 48 14 67 34 5 410 116 48 16 30 12 5 239 75 575 30 12 5 239 75 575 30 12 4 4 4 202 103 38 20 103 4 4 11092 9 37 78 17 22 846 9 18 4 5 101 1162 9 619 620 6 74 27 92 126 58 65 92 9 326 7 1069 30 12 229 9 68 53 8 10 4 31 39 4 10 458 21 369 229 9 4 6 4 4 11 8 1599 9 7797 16 8 106 24 13 5 38 16 7 183 555 7 183 555 3 6 139 4 183 555 4 183 555 15 4 42 39 5 3\n",
            "I0918 12:35:36.017532 139910923954048 create_pretraining_data.py:161] input_ids: 2 17 22 134 6 852 67 34 5 410 116 48 14 67 34 5 410 116 48 16 30 12 5 239 75 575 30 12 5 239 75 575 30 12 4 4 4 202 103 38 20 103 4 4 11092 9 37 78 17 22 846 9 18 4 5 101 1162 9 619 620 6 74 27 92 126 58 65 92 9 326 7 1069 30 12 229 9 68 53 8 10 4 31 39 4 10 458 21 369 229 9 4 6 4 4 11 8 1599 9 7797 16 8 106 24 13 5 38 16 7 183 555 7 183 555 3 6 139 4 183 555 4 183 555 15 4 42 39 5 3\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0918 12:35:36.099116 139910923954048 create_pretraining_data.py:161] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0918 12:35:36.099478 139910923954048 create_pretraining_data.py:161] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:masked_lm_positions: 25 31 34 35 36 37 42 43 44 53 68 80 83 90 92 93 116 119 123 0\n",
            "I0918 12:35:36.099636 139910923954048 create_pretraining_data.py:161] masked_lm_positions: 25 31 34 35 36 37 42 43 44 53 68 80 83 90 92 93 116 119 123 0\n",
            "INFO:tensorflow:masked_lm_ids: 575 575 5 239 75 575 5 108 72 134 9 1656 223 18 234 14 7 7 68 0\n",
            "I0918 12:35:36.099763 139910923954048 create_pretraining_data.py:161] masked_lm_ids: 575 575 5 239 75 575 5 108 72 134 9 1656 223 18 234 14 7 7 68 0\n",
            "INFO:tensorflow:masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0\n",
            "I0918 12:35:36.099906 139910923954048 create_pretraining_data.py:161] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0\n",
            "INFO:tensorflow:next_sentence_labels: 0\n",
            "I0918 12:35:36.100018 139910923954048 create_pretraining_data.py:161] next_sentence_labels: 0\n",
            "INFO:tensorflow:*** Writing to output files ***\n",
            "I0918 12:35:40.721508 140477288433536 create_pretraining_data.py:457] *** Writing to output files ***\n",
            "INFO:tensorflow:  pretraining_data/shard_0003.tfrecord\n",
            "I0918 12:35:40.721939 140477288433536 create_pretraining_data.py:459]   pretraining_data/shard_0003.tfrecord\n",
            "WARNING:tensorflow:From bert/create_pretraining_data.py:101: The name tf.python_io.TFRecordWriter is deprecated. Please use tf.io.TFRecordWriter instead.\n",
            "\n",
            "W0918 12:35:40.722234 140477288433536 deprecation_wrapper.py:119] From bert/create_pretraining_data.py:101: The name tf.python_io.TFRecordWriter is deprecated. Please use tf.io.TFRecordWriter instead.\n",
            "\n",
            "INFO:tensorflow:*** Example ***\n",
            "I0918 12:35:40.723427 140477288433536 create_pretraining_data.py:149] *** Example ***\n",
            "INFO:tensorflow:tokens: [CLS] what good s having [MASK] unless you spend it huh this is this is so extravagant i i m embarrassed don midnight take up smoking but if it s good enough for ##toilet duke of windsor [MASK] well i m really [MASK] and my little bernard shaw is so [MASK] no [SEP] you to [MASK] how unbelievabl ##y proud i am of you david this is [MASK] insignificant maybe i m talking out of turn here but [MASK] ve just developed [MASK] much and i i just feel that refugee belong in a [MASK] of society and [MASK] culture now [MASK] s frustrating because you should continue growing you magog be branch ##ing out there [MASK] paris and rome and the great [MASK] houses and museums [SEP]\n",
            "I0918 12:35:40.723787 140477288433536 create_pretraining_data.py:151] tokens: [CLS] what good s having [MASK] unless you spend it huh this is this is so extravagant i i m embarrassed don midnight take up smoking but if it s good enough for ##toilet duke of windsor [MASK] well i m really [MASK] and my little bernard shaw is so [MASK] no [SEP] you to [MASK] how unbelievabl ##y proud i am of you david this is [MASK] insignificant maybe i m talking out of turn here but [MASK] ve just developed [MASK] much and i i just feel that refugee belong in a [MASK] of society and [MASK] culture now [MASK] s frustrating because you should continue growing you magog be branch ##ing out there [MASK] paris and rome and the great [MASK] houses and museums [SEP]\n",
            "INFO:tensorflow:input_ids: 2 16 71 8 400 4 836 5 908 11 227 22 17 22 17 43 13014 6 6 26 2713 30 2925 94 51 1572 42 59 11 8 71 235 28 25052 3674 15 5794 4 69 6 26 108 4 13 25 111 6019 6851 17 43 4 23 3 5 9 4 67 6773 221 989 6 139 15 5 627 22 17 4 7066 155 6 26 271 55 15 289 45 42 4 73 46 3801 4 140 13 6 6 46 199 14 6896 1675 19 10 4 15 2732 13 4 2937 65 4 8 10652 134 5 133 1337 1496 5 7216 37 6459 123 55 50 4 1542 13 2629 13 7 167 4 2992 13 6490 3\n",
            "I0918 12:35:40.724020 140477288433536 create_pretraining_data.py:161] input_ids: 2 16 71 8 400 4 836 5 908 11 227 22 17 22 17 43 13014 6 6 26 2713 30 2925 94 51 1572 42 59 11 8 71 235 28 25052 3674 15 5794 4 69 6 26 108 4 13 25 111 6019 6851 17 43 4 23 3 5 9 4 67 6773 221 989 6 139 15 5 627 22 17 4 7066 155 6 26 271 55 15 289 45 42 4 73 46 3801 4 140 13 6 6 46 199 14 6896 1675 19 10 4 15 2732 13 4 2937 65 4 8 10652 134 5 133 1337 1496 5 7216 37 6459 123 55 50 4 1542 13 2629 13 7 167 4 2992 13 6490 3\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0918 12:35:40.724198 140477288433536 create_pretraining_data.py:161] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0918 12:35:40.724367 140477288433536 create_pretraining_data.py:161] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:masked_lm_positions: 5 16 22 33 37 42 50 55 60 67 78 82 90 94 98 101 110 116 123 0\n",
            "I0918 12:35:40.724488 140477288433536 create_pretraining_data.py:161] masked_lm_positions: 5 16 22 33 37 42 50 55 60 67 78 82 90 94 98 101 110 116 123 0\n",
            "INFO:tensorflow:masked_lm_ids: 1389 13014 12 7 54 7353 7066 36 6 39 5 43 5 242 434 11 133 8 2290 0\n",
            "I0918 12:35:40.724599 140477288433536 create_pretraining_data.py:161] masked_lm_ids: 1389 13014 12 7 54 7353 7066 36 6 39 5 43 5 242 434 11 133 8 2290 0\n",
            "INFO:tensorflow:masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0\n",
            "I0918 12:35:40.724757 140477288433536 create_pretraining_data.py:161] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0\n",
            "INFO:tensorflow:next_sentence_labels: 0\n",
            "I0918 12:35:40.724868 140477288433536 create_pretraining_data.py:161] next_sentence_labels: 0\n",
            "INFO:tensorflow:*** Example ***\n",
            "I0918 12:35:40.725518 140477288433536 create_pretraining_data.py:149] *** Example ***\n",
            "INFO:tensorflow:tokens: [CLS] you wanna be a socialite [SEP] [MASK] [MASK] nuts [SEP]\n",
            "I0918 12:35:40.725708 140477288433536 create_pretraining_data.py:151] tokens: [CLS] you wanna be a socialite [SEP] [MASK] [MASK] nuts [SEP]\n",
            "INFO:tensorflow:input_ids: 2 5 243 37 10 9581 3 4 4 1168 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0918 12:35:40.725888 140477288433536 create_pretraining_data.py:161] input_ids: 2 5 243 37 10 9581 3 4 4 1168 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0918 12:35:40.726054 140477288433536 create_pretraining_data.py:161] input_mask: 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0918 12:35:40.726212 140477288433536 create_pretraining_data.py:161] segment_ids: 0 0 0 0 0 0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:masked_lm_positions: 7 8 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0918 12:35:40.726341 140477288433536 create_pretraining_data.py:161] masked_lm_positions: 7 8 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:masked_lm_ids: 38 5 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0918 12:35:40.726445 140477288433536 create_pretraining_data.py:161] masked_lm_ids: 38 5 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:masked_lm_weights: 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
            "I0918 12:35:40.726563 140477288433536 create_pretraining_data.py:161] masked_lm_weights: 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
            "INFO:tensorflow:next_sentence_labels: 1\n",
            "I0918 12:35:40.726697 140477288433536 create_pretraining_data.py:161] next_sentence_labels: 1\n",
            "INFO:tensorflow:*** Example ***\n",
            "I0918 12:35:40.727324 140477288433536 create_pretraining_data.py:149] *** Example ***\n",
            "INFO:tensorflow:tokens: [CLS] i [MASK] t know [SEP] i guess sometimes these ##claimed sort [MASK] come [MASK] in their own kook ##y sort of way [SEP]\n",
            "I0918 12:35:40.727489 140477288433536 create_pretraining_data.py:151] tokens: [CLS] i [MASK] t know [SEP] i guess sometimes these ##claimed sort [MASK] come [MASK] in their own kook ##y sort of way [SEP]\n",
            "INFO:tensorflow:input_ids: 2 6 4 12 36 3 6 297 566 151 21001 669 4 58 4 19 193 248 10837 221 669 15 118 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0918 12:35:40.727688 140477288433536 create_pretraining_data.py:161] input_ids: 2 6 4 12 36 3 6 297 566 151 21001 669 4 58 4 19 193 248 10837 221 669 15 118 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0918 12:35:40.727868 140477288433536 create_pretraining_data.py:161] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0918 12:35:40.728027 140477288433536 create_pretraining_data.py:161] segment_ids: 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:masked_lm_positions: 2 10 12 14 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0918 12:35:40.728141 140477288433536 create_pretraining_data.py:161] masked_lm_positions: 2 10 12 14 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:masked_lm_ids: 30 185 15 269 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0918 12:35:40.728252 140477288433536 create_pretraining_data.py:161] masked_lm_ids: 30 185 15 269 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:masked_lm_weights: 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
            "I0918 12:35:40.728363 140477288433536 create_pretraining_data.py:161] masked_lm_weights: 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
            "INFO:tensorflow:next_sentence_labels: 1\n",
            "I0918 12:35:40.728464 140477288433536 create_pretraining_data.py:161] next_sentence_labels: 1\n",
            "INFO:tensorflow:*** Example ***\n",
            "I0918 12:35:40.729094 140477288433536 create_pretraining_data.py:149] *** Example ***\n",
            "INFO:tensorflow:tokens: [CLS] [MASK] distance running well you just run [MASK] [MASK] [MASK] back home then [MASK] you don t understand can t you just show me how mongolian get out of a head lock [SEP] i knew it damn [SEP]\n",
            "I0918 12:35:40.729264 140477288433536 create_pretraining_data.py:151] tokens: [CLS] [MASK] distance running well you just run [MASK] [MASK] [MASK] back home then [MASK] you don t understand can t you just show me how mongolian get out of a head lock [SEP] i knew it damn [SEP]\n",
            "INFO:tensorflow:input_ids: 2 4 3732 662 69 5 46 384 4 4 4 85 174 110 4 5 30 12 234 34 12 5 46 257 18 67 14817 44 55 15 10 267 1258 3 6 313 11 290 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0918 12:35:40.729439 140477288433536 create_pretraining_data.py:161] input_ids: 2 4 3732 662 69 5 46 384 4 4 4 85 174 110 4 5 30 12 234 34 12 5 46 257 18 67 14817 44 55 15 10 267 1258 3 6 313 11 290 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0918 12:35:40.729597 140477288433536 create_pretraining_data.py:161] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0918 12:35:40.729801 140477288433536 create_pretraining_data.py:161] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:masked_lm_positions: 1 8 9 10 14 26 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0918 12:35:40.729924 140477288433536 create_pretraining_data.py:161] masked_lm_positions: 1 8 9 10 14 26 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:masked_lm_ids: 177 40 7 118 23 9 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0918 12:35:40.730034 140477288433536 create_pretraining_data.py:161] masked_lm_ids: 177 40 7 118 23 9 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
            "I0918 12:35:40.730145 140477288433536 create_pretraining_data.py:161] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
            "INFO:tensorflow:next_sentence_labels: 1\n",
            "I0918 12:35:40.730249 140477288433536 create_pretraining_data.py:161] next_sentence_labels: 1\n",
            "INFO:tensorflow:*** Example ***\n",
            "I0918 12:35:40.730883 140477288433536 create_pretraining_data.py:149] *** Example ***\n",
            "INFO:tensorflow:tokens: [CLS] did [MASK] know that in some cultures if your children shame you you re allowed [MASK] have them executed [MASK] i feel shamed oh harold i m [MASK] swinging an ax [SEP] i just [MASK] [MASK] to play pit with me i mean is that so horrible honey [MASK] s like that old saying if you love something set it [MASK] maybe [MASK] we try algeria to force it [MASK] ll tightrope to us well all right there you go [MASK] [MASK] free let em free let em go laughs [MASK] get back here all right bill you pick wait why does [MASK] get to pick because i don t trust [MASK] just pick fast don t try to feel around for your paper i m [SEP]\n",
            "I0918 12:35:40.731101 140477288433536 create_pretraining_data.py:151] tokens: [CLS] did [MASK] know that in some cultures if your children shame you you re allowed [MASK] have them executed [MASK] i feel shamed oh harold i m [MASK] swinging an ax [SEP] i just [MASK] [MASK] to play pit with me i mean is that so horrible honey [MASK] s like that old saying if you love something set it [MASK] maybe [MASK] we try algeria to force it [MASK] ll tightrope to us well all right there you go [MASK] [MASK] free let em free let em go laughs [MASK] get back here all right bill you pick wait why does [MASK] get to pick because i don t trust [MASK] just pick fast don t try to feel around for your paper i m [SEP]\n",
            "INFO:tensorflow:input_ids: 2 76 4 36 14 19 102 6501 59 27 645 1431 5 5 33 1702 4 29 105 4998 4 6 199 15997 56 4675 6 26 4 7844 98 8796 3 6 46 4 4 9 391 2916 41 18 6 132 17 14 43 1983 380 4 8 48 14 186 341 59 5 113 116 556 11 4 155 4 20 247 18178 9 868 11 4 47 18405 9 99 69 40 54 50 5 52 4 4 606 70 428 606 70 428 52 1432 4 44 85 45 40 54 629 5 505 150 78 210 4 44 9 505 134 6 30 12 493 4 46 505 580 30 12 247 9 199 190 28 27 822 6 26 3\n",
            "I0918 12:35:40.731303 140477288433536 create_pretraining_data.py:161] input_ids: 2 76 4 36 14 19 102 6501 59 27 645 1431 5 5 33 1702 4 29 105 4998 4 6 199 15997 56 4675 6 26 4 7844 98 8796 3 6 46 4 4 9 391 2916 41 18 6 132 17 14 43 1983 380 4 8 48 14 186 341 59 5 113 116 556 11 4 155 4 20 247 18178 9 868 11 4 47 18405 9 99 69 40 54 50 5 52 4 4 606 70 428 606 70 428 52 1432 4 44 85 45 40 54 629 5 505 150 78 210 4 44 9 505 134 6 30 12 493 4 46 505 580 30 12 247 9 199 190 28 27 822 6 26 3\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0918 12:35:40.736915 140477288433536 create_pretraining_data.py:161] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0918 12:35:40.737151 140477288433536 create_pretraining_data.py:161] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:masked_lm_positions: 2 16 20 28 35 36 49 57 61 63 66 70 72 76 81 82 91 103 112 0\n",
            "I0918 12:35:40.737285 140477288433536 create_pretraining_data.py:161] masked_lm_positions: 2 16 20 28 35 36 49 57 61 63 66 70 72 76 81 82 91 103 112 0\n",
            "INFO:tensorflow:masked_lm_ids: 5 9 69 39 72 105 11 113 606 59 39 49 58 40 49 33 77 21 5 0\n",
            "I0918 12:35:40.737391 140477288433536 create_pretraining_data.py:161] masked_lm_ids: 5 9 69 39 72 105 11 113 606 59 39 49 58 40 49 33 77 21 5 0\n",
            "INFO:tensorflow:masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0\n",
            "I0918 12:35:40.737525 140477288433536 create_pretraining_data.py:161] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0\n",
            "INFO:tensorflow:next_sentence_labels: 0\n",
            "I0918 12:35:40.737669 140477288433536 create_pretraining_data.py:161] next_sentence_labels: 0\n",
            "INFO:tensorflow:*** Example ***\n",
            "I0918 12:35:40.738461 140477288433536 create_pretraining_data.py:149] *** Example ***\n",
            "INFO:tensorflow:tokens: [CLS] i mean once people caught on that that was possible you had madison avenue [MASK] into the job at ##t hire ##s wai to [MASK] people that now its you know its become a very mainstream message [MASK] had a hunch that it was [MASK] to change things in a way that [MASK] advent of [MASK] [MASK] ##bi ##quit ##aka of the automobile changed things it changed how [MASK] dressed how we eat it affect ##s these [MASK] affect everything i mean this was a [MASK] [MASK] technologies it was just a matter of spraying [MASK] the hairs ##pr ##ay and slapping on some lip gloss and this thing was gonna walk you [MASK] they were gonna [MASK] cute [SEP] your what [SEP]\n",
            "I0918 12:35:40.738757 140477288433536 create_pretraining_data.py:151] tokens: [CLS] i mean once people caught on that that was possible you had madison avenue [MASK] into the job at ##t hire ##s wai to [MASK] people that now its you know its become a very mainstream message [MASK] had a hunch that it was [MASK] to change things in a way that [MASK] advent of [MASK] [MASK] ##bi ##quit ##aka of the automobile changed things it changed how [MASK] dressed how we eat it affect ##s these [MASK] affect everything i mean this was a [MASK] [MASK] technologies it was just a matter of spraying [MASK] the hairs ##pr ##ay and slapping on some lip gloss and this thing was gonna walk you [MASK] they were gonna [MASK] cute [SEP] your what [SEP]\n",
            "INFO:tensorflow:input_ids: 2 6 132 348 138 915 24 14 14 35 901 5 97 6342 4328 4 173 7 309 64 180 2727 57 11564 9 4 138 14 65 773 5 36 773 619 10 124 23564 1164 4 97 10 4379 14 11 35 4 9 406 185 19 10 118 14 4 26278 15 4 4 11992 14518 20654 15 7 8455 725 185 11 725 67 4 1520 67 20 358 11 3474 57 151 4 3474 189 6 132 22 35 10 4 4 3777 11 35 46 10 325 15 24515 4 7 15084 25762 4109 13 13835 24 102 4897 8327 13 22 143 35 80 491 5 4 49 101 80 4 1147 3 27 16 3 0 0 0 0\n",
            "I0918 12:35:40.738991 140477288433536 create_pretraining_data.py:161] input_ids: 2 6 132 348 138 915 24 14 14 35 901 5 97 6342 4328 4 173 7 309 64 180 2727 57 11564 9 4 138 14 65 773 5 36 773 619 10 124 23564 1164 4 97 10 4379 14 11 35 4 9 406 185 19 10 118 14 4 26278 15 4 4 11992 14518 20654 15 7 8455 725 185 11 725 67 4 1520 67 20 358 11 3474 57 151 4 3474 189 6 132 22 35 10 4 4 3777 11 35 46 10 325 15 24515 4 7 15084 25762 4109 13 13835 24 102 4897 8327 13 22 143 35 80 491 5 4 49 101 80 4 1147 3 27 16 3 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0\n",
            "I0918 12:35:40.739190 140477288433536 create_pretraining_data.py:161] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0\n",
            "I0918 12:35:40.739379 140477288433536 create_pretraining_data.py:161] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0\n",
            "INFO:tensorflow:masked_lm_positions: 1 15 23 25 38 45 53 55 56 57 60 69 78 86 87 96 114 116 118 0\n",
            "I0918 12:35:40.739527 140477288433536 create_pretraining_data.py:161] masked_lm_positions: 1 15 23 25 38 45 53 55 56 57 60 69 78 86 87 96 114 116 118 0\n",
            "INFO:tensorflow:masked_lm_ids: 6 295 138 104 6 106 7 15 7 957 221 20 185 11753 1676 24 36 101 37 0\n",
            "I0918 12:35:40.739690 140477288433536 create_pretraining_data.py:161] masked_lm_ids: 6 295 138 104 6 106 7 15 7 957 221 20 185 11753 1676 24 36 101 37 0\n",
            "INFO:tensorflow:masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0\n",
            "I0918 12:35:40.739838 140477288433536 create_pretraining_data.py:161] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0\n",
            "INFO:tensorflow:next_sentence_labels: 1\n",
            "I0918 12:35:40.739964 140477288433536 create_pretraining_data.py:161] next_sentence_labels: 1\n",
            "INFO:tensorflow:*** Example ***\n",
            "I0918 12:35:40.740664 140477288433536 create_pretraining_data.py:149] *** Example ***\n",
            "INFO:tensorflow:tokens: [CLS] here goes nothing the maru has activated the fms her sensors [MASK] emitt ##ing at full [MASK] harper did a great job [MASK] i topless t know [MASK] i would swear she [MASK] me apparently [MASK] re not the only one [MASK] m [MASK] a sensor contact at extreme range [MASK] closing fast on the maru [SEP] tag you re it keep it together beka [MASK] t let him spook you multipl ##e [MASK] four missiles headed for the maru all [MASK] he s taken the bait all ahead full ready missile barr ##age on my mark collision [MASK] collision alert tell [MASK] [MASK] i don t know [MASK] s not going to make it covering fire now come on come on [MASK] just one more [SEP]\n",
            "I0918 12:35:40.740907 140477288433536 create_pretraining_data.py:151] tokens: [CLS] here goes nothing the maru has activated the fms her sensors [MASK] emitt ##ing at full [MASK] harper did a great job [MASK] i topless t know [MASK] i would swear she [MASK] me apparently [MASK] re not the only one [MASK] m [MASK] a sensor contact at extreme range [MASK] closing fast on the maru [SEP] tag you re it keep it together beka [MASK] t let him spook you multipl ##e [MASK] four missiles headed for the maru all [MASK] he s taken the bait all ahead full ready missile barr ##age on my mark collision [MASK] collision alert tell [MASK] [MASK] i don t know [MASK] s not going to make it covering fire now come on come on [MASK] just one more [SEP]\n",
            "INFO:tensorflow:input_ids: 2 45 460 166 7 4892 126 5467 7 22021 68 4689 4 25133 123 64 481 4 5249 76 10 167 309 4 6 11462 12 36 4 6 107 1264 53 4 18 1568 4 33 39 7 130 61 4 26 4 10 7762 1286 64 8605 3245 4 3491 580 24 7 4892 3 3010 5 33 11 179 11 269 9216 4 12 70 60 12714 5 7863 178 4 393 7108 1403 28 7 4892 40 4 21 8 741 7 2274 40 513 481 345 5094 15921 3259 24 25 1256 15426 4 15426 2248 104 4 4 6 30 12 36 4 8 39 106 9 122 11 5585 558 65 58 24 58 24 4 46 61 129 3\n",
            "I0918 12:35:40.741111 140477288433536 create_pretraining_data.py:161] input_ids: 2 45 460 166 7 4892 126 5467 7 22021 68 4689 4 25133 123 64 481 4 5249 76 10 167 309 4 6 11462 12 36 4 6 107 1264 53 4 18 1568 4 33 39 7 130 61 4 26 4 10 7762 1286 64 8605 3245 4 3491 580 24 7 4892 3 3010 5 33 11 179 11 269 9216 4 12 70 60 12714 5 7863 178 4 393 7108 1403 28 7 4892 40 4 21 8 741 7 2274 40 513 481 345 5094 15921 3259 24 25 1256 15426 4 15426 2248 104 4 4 6 30 12 36 4 8 39 106 9 122 11 5585 558 65 58 24 58 24 4 46 61 129 3\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0918 12:35:40.741307 140477288433536 create_pretraining_data.py:161] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0918 12:35:40.741477 140477288433536 create_pretraining_data.py:161] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:masked_lm_positions: 12 17 23 25 28 33 36 42 44 51 53 66 74 82 99 103 104 109 123 0\n",
            "I0918 12:35:40.741603 140477288433536 create_pretraining_data.py:161] masked_lm_positions: 12 17 23 25 28 33 36 42 44 51 53 66 74 82 99 103 104 109 123 0\n",
            "INFO:tensorflow:masked_lm_ids: 38 547 59 112 182 101 5 6 292 13 580 30 11222 54 2248 18 116 53 3275 0\n",
            "I0918 12:35:40.741745 140477288433536 create_pretraining_data.py:161] masked_lm_ids: 38 547 59 112 182 101 5 6 292 13 580 30 11222 54 2248 18 116 53 3275 0\n",
            "INFO:tensorflow:masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0\n",
            "I0918 12:35:40.741863 140477288433536 create_pretraining_data.py:161] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0\n",
            "INFO:tensorflow:next_sentence_labels: 0\n",
            "I0918 12:35:40.741963 140477288433536 create_pretraining_data.py:161] next_sentence_labels: 0\n",
            "INFO:tensorflow:*** Example ***\n",
            "I0918 12:35:40.742590 140477288433536 create_pretraining_data.py:149] *** Example ***\n",
            "INFO:tensorflow:tokens: [CLS] must [MASK] [MASK] [MASK] with your head i never killed anyone before what [MASK] re a schizo who s wanted [MASK] murder and you re laying in bed next to me [MASK] ##g like [MASK] [UNK] year old girl on the phone you freaked [MASK] out man but [MASK] [MASK] your family [SEP] then you could have a hell of a problem mr byrnes [SEP]\n",
            "I0918 12:35:40.742825 140477288433536 create_pretraining_data.py:151] tokens: [CLS] must [MASK] [MASK] [MASK] with your head i never killed anyone before what [MASK] re a schizo who s wanted [MASK] murder and you re laying in bed next to me [MASK] ##g like [MASK] [UNK] year old girl on the phone you freaked [MASK] out man but [MASK] [MASK] your family [SEP] then you could have a hell of a problem mr byrnes [SEP]\n",
            "INFO:tensorflow:input_ids: 2 191 4 4 4 41 27 267 6 117 356 403 195 16 4 33 10 3907 75 8 246 4 768 13 5 33 4225 19 635 288 9 18 4 1271 48 4 1 422 186 231 24 7 443 5 4329 4 55 89 42 4 4 27 258 3 110 5 93 29 10 220 15 10 291 209 3175 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0918 12:35:40.743010 140477288433536 create_pretraining_data.py:161] input_ids: 2 191 4 4 4 41 27 267 6 117 356 403 195 16 4 33 10 3907 75 8 246 4 768 13 5 33 4225 19 635 288 9 18 4 1271 48 4 1 422 186 231 24 7 443 5 4329 4 55 89 42 4 4 27 258 3 110 5 93 29 10 220 15 10 291 209 3175 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0918 12:35:40.743170 140477288433536 create_pretraining_data.py:161] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0918 12:35:40.743335 140477288433536 create_pretraining_data.py:161] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:masked_lm_positions: 2 3 4 14 21 32 35 45 49 50 0 0 0 0 0 0 0 0 0 0\n",
            "I0918 12:35:40.743448 140477288433536 create_pretraining_data.py:161] masked_lm_positions: 2 3 4 14 21 32 35 45 49 50 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:masked_lm_ids: 37 14484 1271 5 28 12075 10 18 16 62 0 0 0 0 0 0 0 0 0 0\n",
            "I0918 12:35:40.743554 140477288433536 create_pretraining_data.py:161] masked_lm_ids: 37 14484 1271 5 28 12075 10 18 16 62 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
            "I0918 12:35:40.743696 140477288433536 create_pretraining_data.py:161] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
            "INFO:tensorflow:next_sentence_labels: 1\n",
            "I0918 12:35:40.743805 140477288433536 create_pretraining_data.py:161] next_sentence_labels: 1\n",
            "INFO:tensorflow:*** Example ***\n",
            "I0918 12:35:40.744408 140477288433536 create_pretraining_data.py:149] *** Example ***\n",
            "INFO:tensorflow:tokens: [CLS] so [MASK] is that so terrible but when we talked about making it we [MASK] gonna hit [MASK] big move to [MASK] swim eat [MASK] crabs we can [MASK] a place in palm beach palm beach is ritzy [SEP] [MASK] at the dog track every day i just wanna [MASK] as far [MASK] from frenchy fox the topless wonder as i can be hey you were beautiful as [MASK] fox [MASK] d come out [MASK] you ##vee give it mine little of this those days are over and our accountants want us to be twice as big next [MASK] what good is that if i can t [MASK] a cheeseburger ray [MASK] [MASK] charming tonight i ve seen you when you wanna turn on the charm [SEP]\n",
            "I0918 12:35:40.744630 140477288433536 create_pretraining_data.py:151] tokens: [CLS] so [MASK] is that so terrible but when we talked about making it we [MASK] gonna hit [MASK] big move to [MASK] swim eat [MASK] crabs we can [MASK] a place in palm beach palm beach is ritzy [SEP] [MASK] at the dog track every day i just wanna [MASK] as far [MASK] from frenchy fox the topless wonder as i can be hey you were beautiful as [MASK] fox [MASK] d come out [MASK] you ##vee give it mine little of this those days are over and our accountants want us to be twice as big next [MASK] what good is that if i can t [MASK] a cheeseburger ray [MASK] [MASK] charming tonight i ve seen you when you wanna turn on the charm [SEP]\n",
            "INFO:tensorflow:input_ids: 2 43 4 17 14 43 803 42 90 20 1079 62 520 11 20 4 80 446 4 148 295 9 4 1345 358 4 8512 20 34 4 10 224 19 3120 1195 3120 1195 17 13106 3 4 64 7 304 1434 261 160 6 46 243 4 83 470 4 81 755 2087 7 11462 757 83 6 34 37 95 5 101 365 83 4 2087 4 86 58 55 4 5 16081 131 11 367 111 15 22 181 360 38 120 13 114 4470 72 99 9 37 1066 83 148 288 4 16 71 17 14 59 6 34 12 4 10 9744 658 4 4 3114 420 6 73 314 5 90 5 243 289 24 7 3042 3\n",
            "I0918 12:35:40.744833 140477288433536 create_pretraining_data.py:161] input_ids: 2 43 4 17 14 43 803 42 90 20 1079 62 520 11 20 4 80 446 4 148 295 9 4 1345 358 4 8512 20 34 4 10 224 19 3120 1195 3120 1195 17 13106 3 4 64 7 304 1434 261 160 6 46 243 4 83 470 4 81 755 2087 7 11462 757 83 6 34 37 95 5 101 365 83 4 2087 4 86 58 55 4 5 16081 131 11 367 111 15 22 181 360 38 120 13 114 4470 72 99 9 37 1066 83 148 288 4 16 71 17 14 59 6 34 12 4 10 9744 658 4 4 3114 420 6 73 314 5 90 5 243 289 24 7 3042 3\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0918 12:35:40.745004 140477288433536 create_pretraining_data.py:161] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0918 12:35:40.745155 140477288433536 create_pretraining_data.py:161] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:masked_lm_positions: 2 15 18 22 25 29 40 50 53 69 71 75 77 80 95 99 108 112 113 0\n",
            "I0918 12:35:40.745276 140477288433536 create_pretraining_data.py:161] masked_lm_positions: 2 15 18 22 25 29 40 50 53 69 71 75 77 80 95 99 108 112 113 0\n",
            "INFO:tensorflow:masked_lm_ids: 16 101 11 2104 2038 44 37 37 163 755 5 239 86 10 1066 422 44 141 37 0\n",
            "I0918 12:35:40.745386 140477288433536 create_pretraining_data.py:161] masked_lm_ids: 16 101 11 2104 2038 44 37 37 163 755 5 239 86 10 1066 422 44 141 37 0\n",
            "INFO:tensorflow:masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0\n",
            "I0918 12:35:40.745499 140477288433536 create_pretraining_data.py:161] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0\n",
            "INFO:tensorflow:next_sentence_labels: 0\n",
            "I0918 12:35:40.745597 140477288433536 create_pretraining_data.py:161] next_sentence_labels: 0\n",
            "INFO:tensorflow:*** Example ***\n",
            "I0918 12:35:40.746213 140477288433536 create_pretraining_data.py:149] *** Example ***\n",
            "INFO:tensorflow:tokens: [CLS] [MASK] [MASK] thing get that [MASK] [SEP] the math motherfucker damn jeez fellas i think i found it what false alarm oh damn ##als [MASK] got a star on my car and one on my chest a gun [MASK] my hip and the right to arrest i [MASK] a guy who s the boss on this highway so [MASK] out what you re doin when you re drivin my way if you break the law [MASK] ll [MASK] from [MASK] i know i m [MASK] for the state i m the highway patrol well [MASK] ll know me when you see me cos my door ##ugie painted white my siren a screamin and my [MASK] ##ing red light i work all day and i [MASK] all [SEP]\n",
            "I0918 12:35:40.746425 140477288433536 create_pretraining_data.py:151] tokens: [CLS] [MASK] [MASK] thing get that [MASK] [SEP] the math motherfucker damn jeez fellas i think i found it what false alarm oh damn ##als [MASK] got a star on my car and one on my chest a gun [MASK] my hip and the right to arrest i [MASK] a guy who s the boss on this highway so [MASK] out what you re doin when you re drivin my way if you break the law [MASK] ll [MASK] from [MASK] i know i m [MASK] for the state i m the highway patrol well [MASK] ll know me when you see me cos my door ##ugie painted white my siren a screamin and my [MASK] ##ing red light i work all day and i [MASK] all [SEP]\n",
            "INFO:tensorflow:input_ids: 2 4 4 143 44 14 4 3 7 4150 935 290 2901 1533 6 74 6 312 11 16 2436 1730 56 290 20565 4 63 10 945 24 25 201 13 61 24 25 1775 10 461 4 25 3875 13 7 54 9 1420 6 4 10 203 75 8 7 782 24 22 2267 43 4 55 16 5 33 530 90 5 33 4716 25 118 59 5 448 7 569 4 47 4 81 4 6 36 6 26 4 28 7 588 6 26 7 2267 1830 69 4 47 36 18 90 5 77 18 1138 25 396 18540 1652 642 25 3646 10 8345 13 25 4 123 751 474 6 154 40 160 13 6 4 40 3\n",
            "I0918 12:35:40.746602 140477288433536 create_pretraining_data.py:161] input_ids: 2 4 4 143 44 14 4 3 7 4150 935 290 2901 1533 6 74 6 312 11 16 2436 1730 56 290 20565 4 63 10 945 24 25 201 13 61 24 25 1775 10 461 4 25 3875 13 7 54 9 1420 6 4 10 203 75 8 7 782 24 22 2267 43 4 55 16 5 33 530 90 5 33 4716 25 118 59 5 448 7 569 4 47 4 81 4 6 36 6 26 4 28 7 588 6 26 7 2267 1830 69 4 47 36 18 90 5 77 18 1138 25 396 18540 1652 642 25 3646 10 8345 13 25 4 123 751 474 6 154 40 160 13 6 4 40 3\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0918 12:35:40.746812 140477288433536 create_pretraining_data.py:161] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0918 12:35:40.746980 140477288433536 create_pretraining_data.py:161] segment_ids: 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:masked_lm_positions: 1 2 6 24 25 33 39 42 48 59 76 77 78 80 85 95 106 115 125 0\n",
            "I0918 12:35:40.747095 140477288433536 create_pretraining_data.py:161] masked_lm_positions: 1 2 6 24 25 33 39 42 48 59 76 77 78 80 85 95 106 115 125 0\n",
            "INFO:tensorflow:masked_lm_ids: 44 14 143 2217 6 61 24 13 26 324 5 47 240 18 2474 5 8 3183 154 0\n",
            "I0918 12:35:40.747203 140477288433536 create_pretraining_data.py:161] masked_lm_ids: 44 14 143 2217 6 61 24 13 26 324 5 47 240 18 2474 5 8 3183 154 0\n",
            "INFO:tensorflow:masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0\n",
            "I0918 12:35:40.747319 140477288433536 create_pretraining_data.py:161] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0\n",
            "INFO:tensorflow:next_sentence_labels: 1\n",
            "I0918 12:35:40.747419 140477288433536 create_pretraining_data.py:161] next_sentence_labels: 1\n",
            "INFO:tensorflow:*** Example ***\n",
            "I0918 12:35:40.841887 140477288433536 create_pretraining_data.py:149] *** Example ***\n",
            "INFO:tensorflow:tokens: [CLS] the child in you will never [MASK] the power [MASK] believe is yours alone no one can ever take that child away see the world for a while [MASK] the eyes ofa child you will see so much wonder in your days all that [MASK] believed when you were small [MASK] still the dreams that guide us all the mirror shows you ve [MASK] but reflect ##s the child in you lfthe ##re s one thing i could say toyou [SEP] [MASK] make [MASK] dream come true you can do almost anything if youjust believe if youjust believe if only only only [MASK] believe bonja [MASK] is an [MASK] [MASK] everyone [MASK] dream very often [MASK] do [MASK] a lot but mine has already been withered [SEP]\n",
            "I0918 12:35:40.842361 140477288433536 create_pretraining_data.py:151] tokens: [CLS] the child in you will never [MASK] the power [MASK] believe is yours alone no one can ever take that child away see the world for a while [MASK] the eyes ofa child you will see so much wonder in your days all that [MASK] believed when you were small [MASK] still the dreams that guide us all the mirror shows you ve [MASK] but reflect ##s the child in you lfthe ##re s one thing i could say toyou [SEP] [MASK] make [MASK] dream come true you can do almost anything if youjust believe if youjust believe if only only only [MASK] believe bonja [MASK] is an [MASK] [MASK] everyone [MASK] dream very often [MASK] do [MASK] a lot but mine has already been withered [SEP]\n",
            "INFO:tensorflow:input_ids: 2 7 498 19 5 79 117 4 7 547 4 223 17 506 368 23 61 34 225 94 14 498 163 77 7 242 28 10 327 4 7 413 19273 498 5 79 77 43 140 757 19 27 360 40 14 4 2360 90 5 101 744 4 159 7 1249 14 2572 99 40 7 1845 1937 5 73 4 42 6882 57 7 498 19 5 31580 667 8 61 143 6 93 96 23169 3 4 122 4 628 58 381 5 34 31 583 162 59 12471 223 59 12471 223 59 130 130 130 4 223 23584 4 17 98 4 4 405 4 628 124 1425 4 31 4 10 232 42 367 126 323 109 17628 3\n",
            "I0918 12:35:40.842669 140477288433536 create_pretraining_data.py:161] input_ids: 2 7 498 19 5 79 117 4 7 547 4 223 17 506 368 23 61 34 225 94 14 498 163 77 7 242 28 10 327 4 7 413 19273 498 5 79 77 43 140 757 19 27 360 40 14 4 2360 90 5 101 744 4 159 7 1249 14 2572 99 40 7 1845 1937 5 73 4 42 6882 57 7 498 19 5 31580 667 8 61 143 6 93 96 23169 3 4 122 4 628 58 381 5 34 31 583 162 59 12471 223 59 12471 223 59 130 130 130 4 223 23584 4 17 98 4 4 405 4 628 124 1425 4 31 4 10 232 42 367 126 323 109 17628 3\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0918 12:35:40.842893 140477288433536 create_pretraining_data.py:161] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0918 12:35:40.843104 140477288433536 create_pretraining_data.py:161] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:masked_lm_positions: 7 10 11 15 29 35 45 51 64 82 84 91 103 106 109 110 112 116 118 0\n",
            "I0918 12:35:40.843258 140477288433536 create_pretraining_data.py:161] masked_lm_positions: 7 10 11 15 29 35 45 51 64 82 84 91 103 106 109 110 112 116 118 0\n",
            "INFO:tensorflow:masked_lm_ids: 3614 9 223 23 262 79 5 38 1447 9 1802 583 5 628 4101 143 79 6 628 0\n",
            "I0918 12:35:40.843394 140477288433536 create_pretraining_data.py:161] masked_lm_ids: 3614 9 223 23 262 79 5 38 1447 9 1802 583 5 628 4101 143 79 6 628 0\n",
            "INFO:tensorflow:masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0\n",
            "I0918 12:35:40.843540 140477288433536 create_pretraining_data.py:161] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0\n",
            "INFO:tensorflow:next_sentence_labels: 0\n",
            "I0918 12:35:40.843685 140477288433536 create_pretraining_data.py:161] next_sentence_labels: 0\n",
            "INFO:tensorflow:*** Example ***\n",
            "I0918 12:35:40.844456 140477288433536 create_pretraining_data.py:149] *** Example ***\n",
            "INFO:tensorflow:tokens: [CLS] all right all right lt [MASK] me he s he s here ln the red snappy ##y nova uh that s [MASK] sir [MASK] over all right as soon as he leaves you call me with the owners addresses spirits [MASK] i ll [MASK] those forms [MASK] over sir damn boss always on my [MASK] i [MASK] three here mm hmm thankyou huh randall raines donny astricky otto halli ##well should i set up some tails uh uh they re too smart for that they ll just dump the cars no we [MASK] get them [MASK] the mercedes [SEP] i won t give up now sorry i [MASK] clear some things up they gotta [MASK] cleared [MASK] what the fuck so [MASK] stiff straight in line [SEP]\n",
            "I0918 12:35:40.844719 140477288433536 create_pretraining_data.py:151] tokens: [CLS] all right all right lt [MASK] me he s he s here ln the red snappy ##y nova uh that s [MASK] sir [MASK] over all right as soon as he leaves you call me with the owners addresses spirits [MASK] i ll [MASK] those forms [MASK] over sir damn boss always on my [MASK] i [MASK] three here mm hmm thankyou huh randall raines donny astricky otto halli ##well should i set up some tails uh uh they re too smart for that they ll just dump the cars no we [MASK] get them [MASK] the mercedes [SEP] i won t give up now sorry i [MASK] clear some things up they gotta [MASK] cleared [MASK] what the fuck so [MASK] stiff straight in line [SEP]\n",
            "INFO:tensorflow:input_ids: 2 40 54 40 54 543 4 18 21 8 21 8 45 3617 7 751 15638 221 7901 144 14 8 4 205 4 120 40 54 83 433 83 21 1739 5 165 18 41 7 4303 2698 4075 4 6 47 4 181 2829 4 120 205 290 782 184 24 25 4 6 4 222 45 476 503 3338 227 892 1023 1234 6565 1042 10222 4120 133 6 556 51 102 4194 144 144 49 33 121 719 28 14 49 47 46 2058 7 641 23 20 4 44 105 4 7 1860 3 6 158 12 131 51 65 136 6 4 587 102 185 51 49 198 4 2856 4 16 7 275 43 4 3678 674 19 517 3\n",
            "I0918 12:35:40.844920 140477288433536 create_pretraining_data.py:161] input_ids: 2 40 54 40 54 543 4 18 21 8 21 8 45 3617 7 751 15638 221 7901 144 14 8 4 205 4 120 40 54 83 433 83 21 1739 5 165 18 41 7 4303 2698 4075 4 6 47 4 181 2829 4 120 205 290 782 184 24 25 4 6 4 222 45 476 503 3338 227 892 1023 1234 6565 1042 10222 4120 133 6 556 51 102 4194 144 144 49 33 121 719 28 14 49 47 46 2058 7 641 23 20 4 44 105 4 7 1860 3 6 158 12 131 51 65 136 6 4 587 102 185 51 49 198 4 2856 4 16 7 275 43 4 3678 674 19 517 3\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0918 12:35:40.845105 140477288433536 create_pretraining_data.py:161] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0918 12:35:40.845266 140477288433536 create_pretraining_data.py:161] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:masked_lm_positions: 6 16 22 24 40 41 42 44 47 55 57 75 93 96 102 108 115 117 122 0\n",
            "I0918 12:35:40.845375 140477288433536 create_pretraining_data.py:161] masked_lm_positions: 6 16 22 24 40 41 42 44 47 55 57 75 93 96 102 108 115 117 122 0\n",
            "INFO:tensorflow:masked_lm_ids: 8 17073 5314 626 40 54 6 44 54 459 63 102 47 41 12 198 44 51 283 0\n",
            "I0918 12:35:40.845477 140477288433536 create_pretraining_data.py:161] masked_lm_ids: 8 17073 5314 626 40 54 6 44 54 459 63 102 47 41 12 198 44 51 283 0\n",
            "INFO:tensorflow:masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0\n",
            "I0918 12:35:40.845593 140477288433536 create_pretraining_data.py:161] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0\n",
            "INFO:tensorflow:next_sentence_labels: 1\n",
            "I0918 12:35:40.845717 140477288433536 create_pretraining_data.py:161] next_sentence_labels: 1\n",
            "INFO:tensorflow:*** Example ***\n",
            "I0918 12:35:40.846388 140477288433536 create_pretraining_data.py:149] *** Example ***\n",
            "INFO:tensorflow:tokens: [CLS] [MASK] i think about it and i often do it s like film images clearly etched and [MASK] lines i suffer from something called retrospect ##ive jealousy during [MASK] intensely erotic interl ##ude in paris i questioned marianne joking ##ly [MASK] her previous lovers she was trusting and walked right [MASK] the trap she was touched [MASK] my interest [MASK] told [MASK] in detail about her relationship with [MASK] how [MASK] some circumstances she achieve ##d an intensity off [MASK] that she d never experienced either before or since that cut deeply [MASK] [MASK] a small but infected wound and that disastrous night the wound broke [MASK] and there was nothing i could do i see [MASK] her face [SEP] i m not [MASK] with you [SEP]\n",
            "I0918 12:35:40.846600 140477288433536 create_pretraining_data.py:151] tokens: [CLS] [MASK] i think about it and i often do it s like film images clearly etched and [MASK] lines i suffer from something called retrospect ##ive jealousy during [MASK] intensely erotic interl ##ude in paris i questioned marianne joking ##ly [MASK] her previous lovers she was trusting and walked right [MASK] the trap she was touched [MASK] my interest [MASK] told [MASK] in detail about her relationship with [MASK] how [MASK] some circumstances she achieve ##d an intensity off [MASK] that she d never experienced either before or since that cut deeply [MASK] [MASK] a small but infected wound and that disastrous night the wound broke [MASK] and there was nothing i could do i see [MASK] her face [SEP] i m not [MASK] with you [SEP]\n",
            "INFO:tensorflow:input_ids: 2 4 6 74 62 11 13 6 1425 31 11 8 48 1122 6510 2287 8508 13 4 2102 6 1834 81 116 343 14956 5146 6844 1211 4 14211 6108 28987 25388 19 1542 6 5040 2123 2249 353 4 68 3537 2858 53 35 12874 13 1308 54 4 7 3442 53 35 2433 4 25 2129 4 196 4 19 4660 62 68 1068 41 4 67 4 102 3148 53 4067 206 98 10068 125 4 14 53 86 117 4542 625 195 100 374 14 372 3355 4 4 10 744 42 5969 1773 13 14 10966 169 7 1773 956 4 13 50 35 166 6 93 31 6 77 4 68 332 3 6 26 39 4 41 5 3\n",
            "I0918 12:35:40.846812 140477288433536 create_pretraining_data.py:161] input_ids: 2 4 6 74 62 11 13 6 1425 31 11 8 48 1122 6510 2287 8508 13 4 2102 6 1834 81 116 343 14956 5146 6844 1211 4 14211 6108 28987 25388 19 1542 6 5040 2123 2249 353 4 68 3537 2858 53 35 12874 13 1308 54 4 7 3442 53 35 2433 4 25 2129 4 196 4 19 4660 62 68 1068 41 4 67 4 102 3148 53 4067 206 98 10068 125 4 14 53 86 117 4542 625 195 100 374 14 372 3355 4 4 10 744 42 5969 1773 13 14 10966 169 7 1773 956 4 13 50 35 166 6 93 31 6 77 4 68 332 3 6 26 39 4 41 5 3\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0918 12:35:40.846976 140477288433536 create_pretraining_data.py:161] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1\n",
            "I0918 12:35:40.847158 140477288433536 create_pretraining_data.py:161] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:masked_lm_positions: 1 18 27 29 41 42 51 57 60 62 69 71 76 80 93 94 107 117 124 0\n",
            "I0918 12:35:40.847275 140477288433536 create_pretraining_data.py:161] masked_lm_positions: 1 18 27 29 41 42 51 57 60 62 69 71 76 80 93 94 107 117 124 0\n",
            "INFO:tensorflow:masked_lm_ids: 90 7 6844 114 62 68 173 119 13 18 1215 423 206 25853 13 1207 326 2123 262 0\n",
            "I0918 12:35:40.847384 140477288433536 create_pretraining_data.py:161] masked_lm_ids: 90 7 6844 114 62 68 173 119 13 18 1215 423 206 25853 13 1207 326 2123 262 0\n",
            "INFO:tensorflow:masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0\n",
            "I0918 12:35:40.847494 140477288433536 create_pretraining_data.py:161] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0\n",
            "INFO:tensorflow:next_sentence_labels: 1\n",
            "I0918 12:35:40.847597 140477288433536 create_pretraining_data.py:161] next_sentence_labels: 1\n",
            "INFO:tensorflow:*** Example ***\n",
            "I0918 12:35:40.848234 140477288433536 create_pretraining_data.py:149] *** Example ***\n",
            "INFO:tensorflow:tokens: [CLS] guess who s back in [MASK] circle of trust pull the string and i [MASK] wink [MASK] [MASK] i m your puppet look at jack whoa oh poor kevin looks lonely maybe i should [MASK] him to dance what [MASK] you think [MASK] [SEP] cancelled [SEP]\n",
            "I0918 12:35:40.848396 140477288433536 create_pretraining_data.py:151] tokens: [CLS] guess who s back in [MASK] circle of trust pull the string and i [MASK] wink [MASK] [MASK] i m your puppet look at jack whoa oh poor kevin looks lonely maybe i should [MASK] him to dance what [MASK] you think [MASK] [SEP] cancelled [SEP]\n",
            "INFO:tensorflow:input_ids: 2 297 75 8 85 19 4 1799 15 493 626 7 5328 13 6 4 5079 4 4 6 26 27 8236 82 64 418 379 56 538 1105 308 1678 155 6 133 4 60 9 659 16 4 5 74 4 3 7802 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0918 12:35:40.848570 140477288433536 create_pretraining_data.py:161] input_ids: 2 297 75 8 85 19 4 1799 15 493 626 7 5328 13 6 4 5079 4 4 6 26 27 8236 82 64 418 379 56 538 1105 308 1678 155 6 133 4 60 9 659 16 4 5 74 4 3 7802 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0918 12:35:40.848758 140477288433536 create_pretraining_data.py:161] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0918 12:35:40.848909 140477288433536 create_pretraining_data.py:161] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:masked_lm_positions: 6 15 17 18 35 40 43 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0918 12:35:40.849033 140477288433536 create_pretraining_data.py:161] masked_lm_positions: 6 15 17 18 35 40 43 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:masked_lm_ids: 7 47 64 5 279 31 149 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0918 12:35:40.849144 140477288433536 create_pretraining_data.py:161] masked_lm_ids: 7 47 64 5 279 31 149 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
            "I0918 12:35:40.849256 140477288433536 create_pretraining_data.py:161] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
            "INFO:tensorflow:next_sentence_labels: 1\n",
            "I0918 12:35:40.849354 140477288433536 create_pretraining_data.py:161] next_sentence_labels: 1\n",
            "INFO:tensorflow:*** Example ***\n",
            "I0918 12:35:40.849960 140477288433536 create_pretraining_data.py:149] *** Example ***\n",
            "INFO:tensorflow:tokens: [CLS] sighing [MASK] to me okay it [MASK] over dickie it [MASK] over [SEP] why don t i drive [SEP]\n",
            "I0918 12:35:40.850125 140477288433536 create_pretraining_data.py:151] tokens: [CLS] sighing [MASK] to me okay it [MASK] over dickie it [MASK] over [SEP] why don t i drive [SEP]\n",
            "INFO:tensorflow:input_ids: 2 5257 4 9 18 91 11 4 120 1348 11 4 120 3 78 30 12 6 617 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0918 12:35:40.850291 140477288433536 create_pretraining_data.py:161] input_ids: 2 5257 4 9 18 91 11 4 120 1348 11 4 120 3 78 30 12 6 617 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0918 12:35:40.850445 140477288433536 create_pretraining_data.py:161] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0918 12:35:40.850606 140477288433536 create_pretraining_data.py:161] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:masked_lm_positions: 2 7 11 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0918 12:35:40.850744 140477288433536 create_pretraining_data.py:161] masked_lm_positions: 2 7 11 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:masked_lm_ids: 229 8 8 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0918 12:35:40.850853 140477288433536 create_pretraining_data.py:161] masked_lm_ids: 229 8 8 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:masked_lm_weights: 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
            "I0918 12:35:40.850961 140477288433536 create_pretraining_data.py:161] masked_lm_weights: 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
            "INFO:tensorflow:next_sentence_labels: 1\n",
            "I0918 12:35:40.851075 140477288433536 create_pretraining_data.py:161] next_sentence_labels: 1\n",
            "INFO:tensorflow:*** Example ***\n",
            "I0918 12:35:40.851687 140477288433536 create_pretraining_data.py:149] *** Example ***\n",
            "INFO:tensorflow:tokens: [CLS] to me terribly sorry very sorry overhearing get posts [MASK] customer account listing and you [MASK] me an evaluation report [SEP] cover the other [MASK] i want charlie arrested on [MASK] hey irene you just keep walking now [SEP]\n",
            "I0918 12:35:40.851854 140477288433536 create_pretraining_data.py:151] tokens: [CLS] to me terribly sorry very sorry overhearing get posts [MASK] customer account listing and you [MASK] me an evaluation report [SEP] cover the other [MASK] i want charlie arrested on [MASK] hey irene you just keep walking now [SEP]\n",
            "INFO:tensorflow:input_ids: 2 9 18 4040 136 124 136 17471 44 21015 4 2892 2529 24125 13 5 4 18 98 11379 805 3 947 7 183 4 6 72 276 2241 24 4 95 639 5 46 179 1133 65 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0918 12:35:40.852034 140477288433536 create_pretraining_data.py:161] input_ids: 2 9 18 4040 136 124 136 17471 44 21015 4 2892 2529 24125 13 5 4 18 98 11379 805 3 947 7 183 4 6 72 276 2241 24 4 95 639 5 46 179 1133 65 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0918 12:35:40.955818 140477288433536 create_pretraining_data.py:161] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0918 12:35:40.957223 140477288433536 create_pretraining_data.py:161] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:masked_lm_positions: 7 9 10 16 25 31 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0918 12:35:40.958422 140477288433536 create_pretraining_data.py:161] masked_lm_positions: 7 9 10 16 25 31 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:masked_lm_ids: 205 18 7 44 362 1865 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0918 12:35:40.959416 140477288433536 create_pretraining_data.py:161] masked_lm_ids: 205 18 7 44 362 1865 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
            "I0918 12:35:40.959834 140477288433536 create_pretraining_data.py:161] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
            "INFO:tensorflow:next_sentence_labels: 1\n",
            "I0918 12:35:40.960851 140477288433536 create_pretraining_data.py:161] next_sentence_labels: 1\n",
            "INFO:tensorflow:*** Example ***\n",
            "I0918 12:35:40.961698 140477288433536 create_pretraining_data.py:149] *** Example ***\n",
            "INFO:tensorflow:tokens: [CLS] then [MASK] and i the action occurs let s say in a circus ah no i m not dating i member i m in love with another character the magician who is much older than i ##zie [MASK] [MASK] the [MASK] did i tell you he plays the violin all i want is to see her to hold her to forgive her what happened with rafael nothing too great my best friend [MASK] the winner is why can [MASK] everything [MASK] back to what [MASK] used to be i [MASK] [MASK] everything tomorrow i ll file for [MASK] let s go home let go [MASK] leave [MASK] [MASK] easy [SEP] leave me alone drop that i m going to nag myself lucia i [MASK] another man [SEP]\n",
            "I0918 12:35:40.968116 140477288433536 create_pretraining_data.py:151] tokens: [CLS] then [MASK] and i the action occurs let s say in a circus ah no i m not dating i member i m in love with another character the magician who is much older than i ##zie [MASK] [MASK] the [MASK] did i tell you he plays the violin all i want is to see her to hold her to forgive her what happened with rafael nothing too great my best friend [MASK] the winner is why can [MASK] everything [MASK] back to what [MASK] used to be i [MASK] [MASK] everything tomorrow i ll file for [MASK] let s go home let go [MASK] leave [MASK] [MASK] easy [SEP] leave me alone drop that i m going to nag myself lucia i [MASK] another man [SEP]\n",
            "INFO:tensorflow:input_ids: 2 110 4 13 6 7 1242 12759 70 8 96 19 10 4063 477 23 6 26 39 2220 6 2875 6 26 19 113 41 255 2408 7 5781 75 17 140 1902 197 6 11173 4 4 7 4 76 6 104 5 21 1835 7 4393 40 6 72 17 9 77 68 9 252 68 9 746 68 16 260 41 10984 166 121 167 25 253 264 4 7 1886 17 78 34 4 189 4 85 9 16 4 352 9 37 6 4 4 189 407 6 47 1611 28 4 70 8 52 174 70 52 4 218 4 4 320 3 218 18 368 724 14 6 26 106 9 4755 377 14671 6 4 255 89 3\n",
            "I0918 12:35:40.968994 140477288433536 create_pretraining_data.py:161] input_ids: 2 110 4 13 6 7 1242 12759 70 8 96 19 10 4063 477 23 6 26 39 2220 6 2875 6 26 19 113 41 255 2408 7 5781 75 17 140 1902 197 6 11173 4 4 7 4 76 6 104 5 21 1835 7 4393 40 6 72 17 9 77 68 9 252 68 9 746 68 16 260 41 10984 166 121 167 25 253 264 4 7 1886 17 78 34 4 189 4 85 9 16 4 352 9 37 6 4 4 189 407 6 47 1611 28 4 70 8 52 174 70 52 4 218 4 4 320 3 218 18 368 724 14 6 26 106 9 4755 377 14671 6 4 255 89 3\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0918 12:35:40.969261 140477288433536 create_pretraining_data.py:161] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0918 12:35:40.969459 140477288433536 create_pretraining_data.py:161] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:masked_lm_positions: 2 21 37 38 39 41 60 73 79 81 85 90 91 98 105 107 108 120 124 0\n",
            "I0918 12:35:40.969584 140477288433536 create_pretraining_data.py:161] masked_lm_positions: 2 21 37 38 39 41 60 73 79 81 85 90 91 98 105 107 108 120 124 0\n",
            "INFO:tensorflow:masked_lm_ids: 5 74 139 13 1835 4393 9 13 12 52 11 196 60 2492 752 18 368 228 570 0\n",
            "I0918 12:35:40.969737 140477288433536 create_pretraining_data.py:161] masked_lm_ids: 5 74 139 13 1835 4393 9 13 12 52 11 196 60 2492 752 18 368 228 570 0\n",
            "INFO:tensorflow:masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0\n",
            "I0918 12:35:40.969872 140477288433536 create_pretraining_data.py:161] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0\n",
            "INFO:tensorflow:next_sentence_labels: 0\n",
            "I0918 12:35:40.969982 140477288433536 create_pretraining_data.py:161] next_sentence_labels: 0\n",
            "INFO:tensorflow:*** Example ***\n",
            "I0918 12:35:40.977507 140477288433536 create_pretraining_data.py:149] *** Example ***\n",
            "INFO:tensorflow:tokens: [CLS] cracker ##jack what are you lookin at i happen to be noticing [MASK] i was lookin at you a [MASK] of times [MASK] [MASK] for the first time i had the thought that in [MASK] very very strange way you [MASK] a sweet face it s off beat in a kind of bizarre you know i don t know how to explain misbehaving [SEP] you mean it s a mainzer may i m trying [MASK] say a nice thing cos [MASK] being a relative of [MASK] i never [MASK] classified [MASK] as [MASK] human type female so i i i was married a long time [MASK] right it was a really tragic story [MASK] my husband [MASK] was dyslexic [MASK] the only thing he could [MASK] [SEP]\n",
            "I0918 12:35:40.980443 140477288433536 create_pretraining_data.py:151] tokens: [CLS] cracker ##jack what are you lookin at i happen to be noticing [MASK] i was lookin at you a [MASK] of times [MASK] [MASK] for the first time i had the thought that in [MASK] very very strange way you [MASK] a sweet face it s off beat in a kind of bizarre you know i don t know how to explain misbehaving [SEP] you mean it s a mainzer may i m trying [MASK] say a nice thing cos [MASK] being a relative of [MASK] i never [MASK] classified [MASK] as [MASK] human type female so i i i was married a long time [MASK] right it was a really tragic story [MASK] my husband [MASK] was dyslexic [MASK] the only thing he could [MASK] [SEP]\n",
            "INFO:tensorflow:input_ids: 2 5362 7293 16 38 5 1039 64 6 436 9 37 8675 4 6 35 1039 64 5 10 4 15 514 4 4 28 7 175 92 6 97 7 171 14 19 4 124 124 683 118 5 4 10 644 332 11 8 125 743 19 10 251 15 3906 5 36 6 30 12 36 67 9 774 21539 3 5 132 11 8 10 21421 245 6 26 329 4 96 10 194 143 1138 4 293 10 4314 15 4 6 117 4 9557 4 83 4 605 1646 2356 43 6 6 6 35 462 10 177 92 4 54 11 35 10 108 3606 542 4 25 632 4 35 13012 4 7 130 143 21 93 4 3\n",
            "I0918 12:35:40.980780 140477288433536 create_pretraining_data.py:161] input_ids: 2 5362 7293 16 38 5 1039 64 6 436 9 37 8675 4 6 35 1039 64 5 10 4 15 514 4 4 28 7 175 92 6 97 7 171 14 19 4 124 124 683 118 5 4 10 644 332 11 8 125 743 19 10 251 15 3906 5 36 6 30 12 36 67 9 774 21539 3 5 132 11 8 10 21421 245 6 26 329 4 96 10 194 143 1138 4 293 10 4314 15 4 6 117 4 9557 4 83 4 605 1646 2356 43 6 6 6 35 462 10 177 92 4 54 11 35 10 108 3606 542 4 25 632 4 35 13012 4 7 130 143 21 93 4 3\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0918 12:35:40.980973 140477288433536 create_pretraining_data.py:161] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0918 12:35:40.981154 140477288433536 create_pretraining_data.py:161] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:masked_lm_positions: 13 20 23 24 35 41 63 70 75 81 86 89 91 93 106 114 117 120 126 0\n",
            "I0918 12:35:40.981413 140477288433536 create_pretraining_data.py:161] masked_lm_positions: 13 20 23 24 35 41 63 70 75 81 86 89 91 93 106 114 117 120 126 0\n",
            "INFO:tensorflow:masked_lm_ids: 5 604 420 1138 10 63 11 6409 9 5 755 195 5 10 349 134 1042 13 2511 0\n",
            "I0918 12:35:40.981540 140477288433536 create_pretraining_data.py:161] masked_lm_ids: 5 604 420 1138 10 63 11 6409 9 5 755 195 5 10 349 134 1042 13 2511 0\n",
            "INFO:tensorflow:masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0\n",
            "I0918 12:35:40.981693 140477288433536 create_pretraining_data.py:161] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0\n",
            "INFO:tensorflow:next_sentence_labels: 0\n",
            "I0918 12:35:40.981806 140477288433536 create_pretraining_data.py:161] next_sentence_labels: 0\n",
            "INFO:tensorflow:*** Example ***\n",
            "I0918 12:35:40.982519 140477288433536 create_pretraining_data.py:149] *** Example ***\n",
            "INFO:tensorflow:tokens: [CLS] woman s voice [MASK] four lev axle [MASK] you ni ##v dee can [UNK] groaning [UNK] darvo se ##d four red do 10 screeching fastened ray i m hungry frenchy learn something there s nothing to learn this is [MASK] honor james lived [MASK] the ##pyjamas leader stupid married to betty grab ##le yes [SEP] to the to the to the [MASK] teat [SEP]\n",
            "I0918 12:35:40.982735 140477288433536 create_pretraining_data.py:151] tokens: [CLS] woman s voice [MASK] four lev axle [MASK] you ni ##v dee can [UNK] groaning [UNK] darvo se ##d four red do 10 screeching fastened ray i m hungry frenchy learn something there s nothing to learn this is [MASK] honor james lived [MASK] the ##pyjamas leader stupid married to betty grab ##le yes [SEP] to the to the to the [MASK] teat [SEP]\n",
            "INFO:tensorflow:input_ids: 2 270 8 701 4 393 11922 14835 4 5 5280 3576 2507 34 1 1903 1 14109 2833 206 393 751 31 554 3094 18545 658 6 26 948 755 673 116 50 8 166 9 673 22 17 4 912 2320 950 4 7 29665 1055 419 462 9 2523 890 2233 84 3 9 7 9 7 9 7 4 9951 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0918 12:35:40.982918 140477288433536 create_pretraining_data.py:161] input_ids: 2 270 8 701 4 393 11922 14835 4 5 5280 3576 2507 34 1 1903 1 14109 2833 206 393 751 31 554 3094 18545 658 6 26 948 755 673 116 50 8 166 9 673 22 17 4 912 2320 950 4 7 29665 1055 419 462 9 2523 890 2233 84 3 9 7 9 7 9 7 4 9951 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0918 12:35:40.983444 140477288433536 create_pretraining_data.py:161] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I0918 12:35:40.983700 140477288433536 create_pretraining_data.py:161] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:masked_lm_positions: 4 8 25 38 40 41 44 46 60 62 0 0 0 0 0 0 0 0 0 0\n",
            "I0918 12:35:40.983839 140477288433536 create_pretraining_data.py:161] masked_lm_positions: 4 8 25 38 40 41 44 46 60 62 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:masked_lm_ids: 1 11605 4326 22 103 1567 75 1578 9 9951 0 0 0 0 0 0 0 0 0 0\n",
            "I0918 12:35:40.983956 140477288433536 create_pretraining_data.py:161] masked_lm_ids: 1 11605 4326 22 103 1567 75 1578 9 9951 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
            "I0918 12:35:40.984074 140477288433536 create_pretraining_data.py:161] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
            "INFO:tensorflow:next_sentence_labels: 1\n",
            "I0918 12:35:40.984177 140477288433536 create_pretraining_data.py:161] next_sentence_labels: 1\n",
            "INFO:tensorflow:*** Example ***\n",
            "I0918 12:35:40.984893 140477288433536 create_pretraining_data.py:149] *** Example ***\n",
            "INFO:tensorflow:tokens: [CLS] am just a dog [SEP] well don [MASK] forget to [MASK] i guess we could always appear atyour trial [MASK] animat ##ed character witnesses no rocky bullwinkle it s your [MASK] to get [MASK] new york by [UNK] 00 pm tomorrow rocky karen we can t leave ##you ##now hey i m [MASK] [MASK] agent remember i ll straighten this out and catch up with you [MASK] but we ve never been [MASK] the real world before oh you ll do great i know it hey what about our faces oh sorry wait you can t just [MASK] them on the side ofthe [MASK] [MASK] that they don t even know [MASK] they are don t [MASK] sup am they re animals they ll for ##age [SEP]\n",
            "I0918 12:35:40.985105 140477288433536 create_pretraining_data.py:151] tokens: [CLS] am just a dog [SEP] well don [MASK] forget to [MASK] i guess we could always appear atyour trial [MASK] animat ##ed character witnesses no rocky bullwinkle it s your [MASK] to get [MASK] new york by [UNK] 00 pm tomorrow rocky karen we can t leave ##you ##now hey i m [MASK] [MASK] agent remember i ll straighten this out and catch up with you [MASK] but we ve never been [MASK] the real world before oh you ll do great i know it hey what about our faces oh sorry wait you can t just [MASK] them on the side ofthe [MASK] [MASK] that they don t even know [MASK] they are don t [MASK] sup am they re animals they ll for ##age [SEP]\n",
            "INFO:tensorflow:input_ids: 2 139 46 10 304 3 69 30 4 410 9 4 6 297 20 93 184 3062 15107 1887 4 25603 161 2408 5006 23 1267 1093 11 8 27 4 9 44 4 170 789 119 1 614 6059 407 1267 1102 20 34 12 218 527 4143 95 6 26 4 4 634 239 6 47 3638 22 55 13 548 51 41 5 4 42 20 73 117 109 4 7 256 242 195 56 5 47 31 167 6 36 11 95 16 62 114 3357 56 136 150 5 34 12 46 4 105 24 7 555 2847 4 4 14 49 30 12 142 36 4 49 38 30 12 4 20317 139 49 33 2112 49 47 28 3259 3\n",
            "I0918 12:35:40.985387 140477288433536 create_pretraining_data.py:161] input_ids: 2 139 46 10 304 3 69 30 4 410 9 4 6 297 20 93 184 3062 15107 1887 4 25603 161 2408 5006 23 1267 1093 11 8 27 4 9 44 4 170 789 119 1 614 6059 407 1267 1102 20 34 12 218 527 4143 95 6 26 4 4 634 239 6 47 3638 22 55 13 548 51 41 5 4 42 20 73 117 109 4 7 256 242 195 56 5 47 31 167 6 36 11 95 16 62 114 3357 56 136 150 5 34 12 46 4 105 24 7 555 2847 4 4 14 49 30 12 142 36 4 49 38 30 12 4 20317 139 49 33 2112 49 47 28 3259 3\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0918 12:35:40.985561 140477288433536 create_pretraining_data.py:161] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0918 12:35:40.985769 140477288433536 create_pretraining_data.py:161] segment_ids: 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:masked_lm_positions: 8 11 12 20 31 34 53 54 62 64 67 73 98 104 105 108 112 117 118 0\n",
            "I0918 12:35:40.985891 140477288433536 create_pretraining_data.py:161] masked_lm_positions: 8 11 12 20 31 34 53 54 62 64 67 73 98 104 105 108 112 117 118 0\n",
            "INFO:tensorflow:masked_lm_ids: 12 918 6 83 1857 9 98 1181 13 51 386 19 218 1071 48 30 103 351 526 0\n",
            "I0918 12:35:40.985997 140477288433536 create_pretraining_data.py:161] masked_lm_ids: 12 918 6 83 1857 9 98 1181 13 51 386 19 218 1071 48 30 103 351 526 0\n",
            "INFO:tensorflow:masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0\n",
            "I0918 12:35:40.986110 140477288433536 create_pretraining_data.py:161] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0\n",
            "INFO:tensorflow:next_sentence_labels: 1\n",
            "I0918 12:35:40.986213 140477288433536 create_pretraining_data.py:161] next_sentence_labels: 1\n",
            "INFO:tensorflow:Wrote 94522 total instances\n",
            "I0918 12:36:21.594717 139910923954048 create_pretraining_data.py:166] Wrote 94522 total instances\n",
            "INFO:tensorflow:Wrote 88775 total instances\n",
            "I0918 12:36:23.604229 140477288433536 create_pretraining_data.py:166] Wrote 88775 total instances\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZKnW_hVxPoP6",
        "colab_type": "text"
      },
      "source": [
        "## Step 6: setting up persistent storage\n",
        "\n",
        "To preserve our hard-earned assets, we will persist them to Google Cloud Storage. Provided that you have created the GCS bucket, this should be simple.\n",
        "\n",
        "We will create two directories in GCS, one for the data and one for the model.\n",
        "In the model directory, we will put the model vocabulary and configuration file.\n",
        "\n",
        "**Configure your BUCKET_NAME variable here before proceeding, otherwise the model and data will not be saved.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gDtrt68QQIHs",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "BUCKET_NAME = \"bert_resourses\" #@param {type:\"string\"}\n",
        "MODEL_DIR = \"bert_model\" #@param {type:\"string\"}\n",
        "tf.gfile.MkDir(MODEL_DIR)\n",
        "\n",
        "if not BUCKET_NAME:\n",
        "  log.warning(\"WARNING: BUCKET_NAME is not set. \"\n",
        "              \"You will not be able to train the model.\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YigCcV-hSHVH",
        "colab_type": "text"
      },
      "source": [
        "Below is the sample hyperparameter configuration for BERT-base. Change at your own risk."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SEpSGpUKReKW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# use this for BERT-base\n",
        "\n",
        "bert_base_config = {\n",
        "  \"attention_probs_dropout_prob\": 0.1, \n",
        "  \"directionality\": \"bidi\", \n",
        "  \"hidden_act\": \"gelu\", \n",
        "  \"hidden_dropout_prob\": 0.1, \n",
        "  \"hidden_size\": 768, \n",
        "  \"initializer_range\": 0.02, \n",
        "  \"intermediate_size\": 3072, \n",
        "  \"max_position_embeddings\": 512, \n",
        "  \"num_attention_heads\": 12, \n",
        "  \"num_hidden_layers\": 12, \n",
        "  \"pooler_fc_size\": 768, \n",
        "  \"pooler_num_attention_heads\": 12, \n",
        "  \"pooler_num_fc_layers\": 3, \n",
        "  \"pooler_size_per_head\": 128, \n",
        "  \"pooler_type\": \"first_token_transform\", \n",
        "  \"type_vocab_size\": 2, \n",
        "  \"vocab_size\": VOC_SIZE\n",
        "}\n",
        "\n",
        "with open(\"{}/bert_config.json\".format(MODEL_DIR), \"w\") as fo:\n",
        "  json.dump(bert_base_config, fo, indent=2)\n",
        "  \n",
        "with open(\"{}/{}\".format(MODEL_DIR, VOC_FNAME), \"w\") as fo:\n",
        "  for token in bert_vocab:\n",
        "    fo.write(token+\"\\n\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "txgrEDugRG48",
        "colab_type": "code",
        "outputId": "5227e9f0-6ccb-48cf-9469-b7e6e10e25ed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "if BUCKET_NAME:\n",
        "  !gsutil -m cp -r $MODEL_DIR $PRETRAINING_DIR gs://$BUCKET_NAME"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Copying file://pretraining_data/shard_0003.tfrecord [Content-Type=application/octet-stream]...\n",
            "Copying file://bert_model/bert_config.json [Content-Type=application/json]...\n",
            "Copying file://pretraining_data/shard_0002.tfrecord [Content-Type=application/octet-stream]...\n",
            "Copying file://pretraining_data/shard_0001.tfrecord [Content-Type=application/octet-stream]...\n",
            "Copying file://pretraining_data/shard_0000.tfrecord [Content-Type=application/octet-stream]...\n",
            "Copying file://bert_model/vocab.txt [Content-Type=text/plain]...\n",
            "-\n",
            "Operation completed over 6 objects/269.4 MiB.                                    \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3DL6xuCAYPrp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3gdQEOzhYmSh",
        "colab_type": "text"
      },
      "source": [
        "## Step 7: training the model\n",
        "\n",
        "We are almost ready to begin training our model. If you wish  to continue an interrupted training run, you may skip steps 2-6 and proceed from here.\n",
        "\n",
        "**Make sure that you have set the BUCKET_NAME here as well.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yXAuzsJfYrio",
        "colab_type": "code",
        "cellView": "both",
        "outputId": "ae5e2ddc-bdf8-4ed7-bcff-82f784169db4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "BUCKET_NAME = \"bert_resourses\" #@param {type:\"string\"}\n",
        "MODEL_DIR = \"bert_model\" #@param {type:\"string\"}\n",
        "PRETRAINING_DIR = \"pretraining_data\" #@param {type:\"string\"}\n",
        "VOC_FNAME = \"vocab.txt\" #@param {type:\"string\"}\n",
        "\n",
        "# Input data pipeline config\n",
        "TRAIN_BATCH_SIZE = 128 #@param {type:\"integer\"}\n",
        "MAX_PREDICTIONS = 20 #@param {type:\"integer\"}\n",
        "MAX_SEQ_LENGTH = 128 #@param {type:\"integer\"}\n",
        "MASKED_LM_PROB = 0.15 #@param\n",
        "\n",
        "# Training procedure config\n",
        "EVAL_BATCH_SIZE = 64\n",
        "LEARNING_RATE = 2e-5\n",
        "TRAIN_STEPS = 1000000 #@param {type:\"integer\"}\n",
        "SAVE_CHECKPOINTS_STEPS = 2500 #@param {type:\"integer\"}\n",
        "NUM_TPU_CORES = 8\n",
        "\n",
        "if BUCKET_NAME:\n",
        "  BUCKET_PATH = \"gs://{}\".format(BUCKET_NAME)\n",
        "else:\n",
        "  BUCKET_PATH = \".\"\n",
        "\n",
        "BERT_GCS_DIR = \"{}/{}\".format(BUCKET_PATH, MODEL_DIR)\n",
        "DATA_GCS_DIR = \"{}/{}\".format(BUCKET_PATH, PRETRAINING_DIR)\n",
        "\n",
        "VOCAB_FILE = os.path.join(BERT_GCS_DIR, VOC_FNAME)\n",
        "CONFIG_FILE = os.path.join(BERT_GCS_DIR, \"bert_config.json\")\n",
        "\n",
        "INIT_CHECKPOINT = tf.train.latest_checkpoint(BERT_GCS_DIR)\n",
        "\n",
        "bert_config = modeling.BertConfig.from_json_file(CONFIG_FILE)\n",
        "input_files = tf.gfile.Glob(os.path.join(DATA_GCS_DIR,'*tfrecord'))\n",
        "\n",
        "log.info(\"Using checkpoint: {}\".format(INIT_CHECKPOINT))\n",
        "log.info(\"Using {} data shards\".format(len(input_files)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2019-09-18 12:40:05,216 :  Couldn't match files for checkpoint gs://bert_resourses/bert_model/model.ckpt-102500\n",
            "2019-09-18 12:40:05,651 :  Using checkpoint: None\n",
            "2019-09-18 12:40:05,656 :  Using 4 data shards\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zwwF-WqcZHUG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MQTFjITdd53F",
        "colab_type": "text"
      },
      "source": [
        "Prepare the training run configuration, build the estimator and input function, power up the bass cannon."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CMahsqUnZ55z",
        "colab_type": "code",
        "outputId": "1db95e73-228c-4134-d67d-5324cc68169e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 275
        }
      },
      "source": [
        "model_fn = model_fn_builder(\n",
        "      bert_config=bert_config,\n",
        "      init_checkpoint=INIT_CHECKPOINT,\n",
        "      learning_rate=LEARNING_RATE,\n",
        "      num_train_steps=TRAIN_STEPS,\n",
        "      num_warmup_steps=10,\n",
        "      use_tpu=USE_TPU,\n",
        "      use_one_hot_embeddings=True)\n",
        "\n",
        "tpu_cluster_resolver = tf.contrib.cluster_resolver.TPUClusterResolver(TPU_ADDRESS)\n",
        "\n",
        "run_config = tf.contrib.tpu.RunConfig(\n",
        "    cluster=tpu_cluster_resolver,\n",
        "    model_dir=BERT_GCS_DIR,\n",
        "    save_checkpoints_steps=SAVE_CHECKPOINTS_STEPS,\n",
        "    tpu_config=tf.contrib.tpu.TPUConfig(\n",
        "        iterations_per_loop=SAVE_CHECKPOINTS_STEPS,\n",
        "        num_shards=NUM_TPU_CORES,\n",
        "        per_host_input_for_training=tf.contrib.tpu.InputPipelineConfig.PER_HOST_V2))\n",
        "\n",
        "estimator = tf.contrib.tpu.TPUEstimator(\n",
        "    use_tpu=USE_TPU,\n",
        "    model_fn=model_fn,\n",
        "    config=run_config,\n",
        "    train_batch_size=TRAIN_BATCH_SIZE,\n",
        "    eval_batch_size=EVAL_BATCH_SIZE)\n",
        "  \n",
        "train_input_fn = input_fn_builder(\n",
        "        input_files=input_files,\n",
        "        max_seq_length=MAX_SEQ_LENGTH,\n",
        "        max_predictions_per_seq=MAX_PREDICTIONS,\n",
        "        is_training=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2019-09-18 12:42:14,316 :  Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7f242273e7b8>) includes params argument, but params are not passed to Estimator.\n",
            "2019-09-18 12:42:14,325 :  Using config: {'_model_dir': 'gs://bert_resourses/bert_model', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 2500, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
            "cluster_def {\n",
            "  job {\n",
            "    name: \"worker\"\n",
            "    tasks {\n",
            "      key: 0\n",
            "      value: \"10.91.210.154:8470\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "isolate_session_state: true\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': None, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f24285ab208>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': 'grpc://10.91.210.154:8470', '_evaluation_master': 'grpc://10.91.210.154:8470', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1, '_tpu_config': TPUConfig(iterations_per_loop=2500, num_shards=8, num_cores_per_replica=None, per_host_input_for_training=3, tpu_job_name=None, initial_infeed_sleep_secs=None, input_partition_dims=None, eval_training_input_configuration=2), '_cluster': <tensorflow.python.distribute.cluster_resolver.tpu_cluster_resolver.TPUClusterResolver object at 0x7f24285abc50>}\n",
            "2019-09-18 12:42:14,330 :  _TPUContext: eval_on_tpu True\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kNt5ykopeIYB",
        "colab_type": "text"
      },
      "source": [
        "Fire!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JrCuEbr6dv8U",
        "colab_type": "code",
        "outputId": "4e3c3b40-2dfe-44a6-8fb6-fb3ce3f28cdf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "estimator.train(input_fn=train_input_fn, max_steps=TRAIN_STEPS)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2019-09-18 12:42:19,833 :  Couldn't match files for checkpoint gs://bert_resourses/bert_model/model.ckpt-102500\n",
            "2019-09-18 12:42:19,835 :  Querying Tensorflow master (grpc://10.91.210.154:8470) for TPU system metadata.\n",
            "2019-09-18 12:42:19,857 :  Found TPU system:\n",
            "2019-09-18 12:42:19,859 :  *** Num TPU Cores: 8\n",
            "2019-09-18 12:42:19,860 :  *** Num TPU Workers: 1\n",
            "2019-09-18 12:42:19,861 :  *** Num TPU Cores Per Worker: 8\n",
            "2019-09-18 12:42:19,863 :  *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, -1, 10112529597588573712)\n",
            "2019-09-18 12:42:19,866 :  *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 17179869184, 7136981085282186828)\n",
            "2019-09-18 12:42:19,867 :  *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 17179869184, 4902132816901732828)\n",
            "2019-09-18 12:42:19,868 :  *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 17179869184, 2089294067726479014)\n",
            "2019-09-18 12:42:19,869 :  *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 17179869184, 18174741405453929323)\n",
            "2019-09-18 12:42:19,871 :  *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 17179869184, 15460803542009079250)\n",
            "2019-09-18 12:42:19,872 :  *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 17179869184, 10830896127408992583)\n",
            "2019-09-18 12:42:19,873 :  *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 17179869184, 11487562379932309715)\n",
            "2019-09-18 12:42:19,874 :  *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 17179869184, 10911185247063431966)\n",
            "2019-09-18 12:42:19,875 :  *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 8589934592, 8988734776553969133)\n",
            "2019-09-18 12:42:19,876 :  *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184, 7268548307044494427)\n",
            "2019-09-18 12:42:19,920 :  From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
            "2019-09-18 12:42:19,952 :  Calling model_fn.\n",
            "2019-09-18 12:42:19,954 :  From /content/bert/run_pretraining.py:337: The name tf.FixedLenFeature is deprecated. Please use tf.io.FixedLenFeature instead.\n",
            "\n",
            "2019-09-18 12:42:19,968 :  From /content/bert/run_pretraining.py:368: parallel_interleave (from tensorflow.contrib.data.python.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.experimental.parallel_interleave(...)`.\n",
            "2019-09-18 12:42:19,969 :  From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/data/python/ops/interleave_ops.py:77: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.\n",
            "2019-09-18 12:42:20,023 :  From /content/bert/run_pretraining.py:385: map_and_batch (from tensorflow.contrib.data.python.ops.batching) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.experimental.map_and_batch(...)`.\n",
            "2019-09-18 12:42:20,025 :  From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/data/python/ops/batching.py:273: map_and_batch (from tensorflow.python.data.experimental.ops.batching) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.map(map_func, num_parallel_calls)` followed by `tf.data.Dataset.batch(batch_size, drop_remainder)`. Static tf.data optimizations will take care of using the fused implementation.\n",
            "2019-09-18 12:42:20,028 :  From /content/bert/run_pretraining.py:393: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.\n",
            "\n",
            "2019-09-18 12:42:20,052 :  From /content/bert/run_pretraining.py:400: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "2019-09-18 12:42:20,154 :  From /content/bert/run_pretraining.py:117: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n",
            "\n",
            "2019-09-18 12:42:20,155 :  *** Features ***\n",
            "2019-09-18 12:42:20,156 :    name = input_ids, shape = (16, 128)\n",
            "2019-09-18 12:42:20,157 :    name = input_mask, shape = (16, 128)\n",
            "2019-09-18 12:42:20,158 :    name = masked_lm_ids, shape = (16, 20)\n",
            "2019-09-18 12:42:20,159 :    name = masked_lm_positions, shape = (16, 20)\n",
            "2019-09-18 12:42:20,160 :    name = masked_lm_weights, shape = (16, 20)\n",
            "2019-09-18 12:42:20,161 :    name = next_sentence_labels, shape = (16, 1)\n",
            "2019-09-18 12:42:20,162 :    name = segment_ids, shape = (16, 128)\n",
            "2019-09-18 12:42:20,163 :  From bert/modeling.py:171: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
            "\n",
            "2019-09-18 12:42:20,176 :  From bert/modeling.py:409: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
            "\n",
            "2019-09-18 12:42:20,225 :  From bert/modeling.py:490: The name tf.assert_less_equal is deprecated. Please use tf.compat.v1.assert_less_equal instead.\n",
            "\n",
            "2019-09-18 12:42:20,285 :  From bert/modeling.py:358: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "2019-09-18 12:42:20,313 :  From bert/modeling.py:671: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.dense instead.\n",
            "2019-09-18 12:42:24,555 :  **** Trainable Variables ****\n",
            "2019-09-18 12:42:24,556 :    name = bert/embeddings/word_embeddings:0, shape = (32000, 768)\n",
            "2019-09-18 12:42:24,557 :    name = bert/embeddings/token_type_embeddings:0, shape = (2, 768)\n",
            "2019-09-18 12:42:24,558 :    name = bert/embeddings/position_embeddings:0, shape = (512, 768)\n",
            "2019-09-18 12:42:24,559 :    name = bert/embeddings/LayerNorm/beta:0, shape = (768,)\n",
            "2019-09-18 12:42:24,560 :    name = bert/embeddings/LayerNorm/gamma:0, shape = (768,)\n",
            "2019-09-18 12:42:24,561 :    name = bert/encoder/layer_0/attention/self/query/kernel:0, shape = (768, 768)\n",
            "2019-09-18 12:42:24,562 :    name = bert/encoder/layer_0/attention/self/query/bias:0, shape = (768,)\n",
            "2019-09-18 12:42:24,563 :    name = bert/encoder/layer_0/attention/self/key/kernel:0, shape = (768, 768)\n",
            "2019-09-18 12:42:24,564 :    name = bert/encoder/layer_0/attention/self/key/bias:0, shape = (768,)\n",
            "2019-09-18 12:42:24,565 :    name = bert/encoder/layer_0/attention/self/value/kernel:0, shape = (768, 768)\n",
            "2019-09-18 12:42:24,566 :    name = bert/encoder/layer_0/attention/self/value/bias:0, shape = (768,)\n",
            "2019-09-18 12:42:24,567 :    name = bert/encoder/layer_0/attention/output/dense/kernel:0, shape = (768, 768)\n",
            "2019-09-18 12:42:24,568 :    name = bert/encoder/layer_0/attention/output/dense/bias:0, shape = (768,)\n",
            "2019-09-18 12:42:24,568 :    name = bert/encoder/layer_0/attention/output/LayerNorm/beta:0, shape = (768,)\n",
            "2019-09-18 12:42:24,569 :    name = bert/encoder/layer_0/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
            "2019-09-18 12:42:24,570 :    name = bert/encoder/layer_0/intermediate/dense/kernel:0, shape = (768, 3072)\n",
            "2019-09-18 12:42:24,571 :    name = bert/encoder/layer_0/intermediate/dense/bias:0, shape = (3072,)\n",
            "2019-09-18 12:42:24,572 :    name = bert/encoder/layer_0/output/dense/kernel:0, shape = (3072, 768)\n",
            "2019-09-18 12:42:24,572 :    name = bert/encoder/layer_0/output/dense/bias:0, shape = (768,)\n",
            "2019-09-18 12:42:24,573 :    name = bert/encoder/layer_0/output/LayerNorm/beta:0, shape = (768,)\n",
            "2019-09-18 12:42:24,574 :    name = bert/encoder/layer_0/output/LayerNorm/gamma:0, shape = (768,)\n",
            "2019-09-18 12:42:24,575 :    name = bert/encoder/layer_1/attention/self/query/kernel:0, shape = (768, 768)\n",
            "2019-09-18 12:42:24,576 :    name = bert/encoder/layer_1/attention/self/query/bias:0, shape = (768,)\n",
            "2019-09-18 12:42:24,577 :    name = bert/encoder/layer_1/attention/self/key/kernel:0, shape = (768, 768)\n",
            "2019-09-18 12:42:24,577 :    name = bert/encoder/layer_1/attention/self/key/bias:0, shape = (768,)\n",
            "2019-09-18 12:42:24,578 :    name = bert/encoder/layer_1/attention/self/value/kernel:0, shape = (768, 768)\n",
            "2019-09-18 12:42:24,579 :    name = bert/encoder/layer_1/attention/self/value/bias:0, shape = (768,)\n",
            "2019-09-18 12:42:24,580 :    name = bert/encoder/layer_1/attention/output/dense/kernel:0, shape = (768, 768)\n",
            "2019-09-18 12:42:24,581 :    name = bert/encoder/layer_1/attention/output/dense/bias:0, shape = (768,)\n",
            "2019-09-18 12:42:24,581 :    name = bert/encoder/layer_1/attention/output/LayerNorm/beta:0, shape = (768,)\n",
            "2019-09-18 12:42:24,582 :    name = bert/encoder/layer_1/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
            "2019-09-18 12:42:24,583 :    name = bert/encoder/layer_1/intermediate/dense/kernel:0, shape = (768, 3072)\n",
            "2019-09-18 12:42:24,584 :    name = bert/encoder/layer_1/intermediate/dense/bias:0, shape = (3072,)\n",
            "2019-09-18 12:42:24,585 :    name = bert/encoder/layer_1/output/dense/kernel:0, shape = (3072, 768)\n",
            "2019-09-18 12:42:24,586 :    name = bert/encoder/layer_1/output/dense/bias:0, shape = (768,)\n",
            "2019-09-18 12:42:24,586 :    name = bert/encoder/layer_1/output/LayerNorm/beta:0, shape = (768,)\n",
            "2019-09-18 12:42:24,587 :    name = bert/encoder/layer_1/output/LayerNorm/gamma:0, shape = (768,)\n",
            "2019-09-18 12:42:24,588 :    name = bert/encoder/layer_2/attention/self/query/kernel:0, shape = (768, 768)\n",
            "2019-09-18 12:42:24,589 :    name = bert/encoder/layer_2/attention/self/query/bias:0, shape = (768,)\n",
            "2019-09-18 12:42:24,590 :    name = bert/encoder/layer_2/attention/self/key/kernel:0, shape = (768, 768)\n",
            "2019-09-18 12:42:24,591 :    name = bert/encoder/layer_2/attention/self/key/bias:0, shape = (768,)\n",
            "2019-09-18 12:42:24,592 :    name = bert/encoder/layer_2/attention/self/value/kernel:0, shape = (768, 768)\n",
            "2019-09-18 12:42:24,592 :    name = bert/encoder/layer_2/attention/self/value/bias:0, shape = (768,)\n",
            "2019-09-18 12:42:24,593 :    name = bert/encoder/layer_2/attention/output/dense/kernel:0, shape = (768, 768)\n",
            "2019-09-18 12:42:24,594 :    name = bert/encoder/layer_2/attention/output/dense/bias:0, shape = (768,)\n",
            "2019-09-18 12:42:24,595 :    name = bert/encoder/layer_2/attention/output/LayerNorm/beta:0, shape = (768,)\n",
            "2019-09-18 12:42:24,596 :    name = bert/encoder/layer_2/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
            "2019-09-18 12:42:24,597 :    name = bert/encoder/layer_2/intermediate/dense/kernel:0, shape = (768, 3072)\n",
            "2019-09-18 12:42:24,597 :    name = bert/encoder/layer_2/intermediate/dense/bias:0, shape = (3072,)\n",
            "2019-09-18 12:42:24,598 :    name = bert/encoder/layer_2/output/dense/kernel:0, shape = (3072, 768)\n",
            "2019-09-18 12:42:24,599 :    name = bert/encoder/layer_2/output/dense/bias:0, shape = (768,)\n",
            "2019-09-18 12:42:24,600 :    name = bert/encoder/layer_2/output/LayerNorm/beta:0, shape = (768,)\n",
            "2019-09-18 12:42:24,601 :    name = bert/encoder/layer_2/output/LayerNorm/gamma:0, shape = (768,)\n",
            "2019-09-18 12:42:24,602 :    name = bert/encoder/layer_3/attention/self/query/kernel:0, shape = (768, 768)\n",
            "2019-09-18 12:42:24,603 :    name = bert/encoder/layer_3/attention/self/query/bias:0, shape = (768,)\n",
            "2019-09-18 12:42:24,603 :    name = bert/encoder/layer_3/attention/self/key/kernel:0, shape = (768, 768)\n",
            "2019-09-18 12:42:24,604 :    name = bert/encoder/layer_3/attention/self/key/bias:0, shape = (768,)\n",
            "2019-09-18 12:42:24,605 :    name = bert/encoder/layer_3/attention/self/value/kernel:0, shape = (768, 768)\n",
            "2019-09-18 12:42:24,606 :    name = bert/encoder/layer_3/attention/self/value/bias:0, shape = (768,)\n",
            "2019-09-18 12:42:24,607 :    name = bert/encoder/layer_3/attention/output/dense/kernel:0, shape = (768, 768)\n",
            "2019-09-18 12:42:24,608 :    name = bert/encoder/layer_3/attention/output/dense/bias:0, shape = (768,)\n",
            "2019-09-18 12:42:24,609 :    name = bert/encoder/layer_3/attention/output/LayerNorm/beta:0, shape = (768,)\n",
            "2019-09-18 12:42:24,609 :    name = bert/encoder/layer_3/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
            "2019-09-18 12:42:24,610 :    name = bert/encoder/layer_3/intermediate/dense/kernel:0, shape = (768, 3072)\n",
            "2019-09-18 12:42:24,611 :    name = bert/encoder/layer_3/intermediate/dense/bias:0, shape = (3072,)\n",
            "2019-09-18 12:42:24,612 :    name = bert/encoder/layer_3/output/dense/kernel:0, shape = (3072, 768)\n",
            "2019-09-18 12:42:24,613 :    name = bert/encoder/layer_3/output/dense/bias:0, shape = (768,)\n",
            "2019-09-18 12:42:24,614 :    name = bert/encoder/layer_3/output/LayerNorm/beta:0, shape = (768,)\n",
            "2019-09-18 12:42:24,615 :    name = bert/encoder/layer_3/output/LayerNorm/gamma:0, shape = (768,)\n",
            "2019-09-18 12:42:24,615 :    name = bert/encoder/layer_4/attention/self/query/kernel:0, shape = (768, 768)\n",
            "2019-09-18 12:42:24,616 :    name = bert/encoder/layer_4/attention/self/query/bias:0, shape = (768,)\n",
            "2019-09-18 12:42:24,617 :    name = bert/encoder/layer_4/attention/self/key/kernel:0, shape = (768, 768)\n",
            "2019-09-18 12:42:24,618 :    name = bert/encoder/layer_4/attention/self/key/bias:0, shape = (768,)\n",
            "2019-09-18 12:42:24,619 :    name = bert/encoder/layer_4/attention/self/value/kernel:0, shape = (768, 768)\n",
            "2019-09-18 12:42:24,620 :    name = bert/encoder/layer_4/attention/self/value/bias:0, shape = (768,)\n",
            "2019-09-18 12:42:24,621 :    name = bert/encoder/layer_4/attention/output/dense/kernel:0, shape = (768, 768)\n",
            "2019-09-18 12:42:24,622 :    name = bert/encoder/layer_4/attention/output/dense/bias:0, shape = (768,)\n",
            "2019-09-18 12:42:24,622 :    name = bert/encoder/layer_4/attention/output/LayerNorm/beta:0, shape = (768,)\n",
            "2019-09-18 12:42:24,623 :    name = bert/encoder/layer_4/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
            "2019-09-18 12:42:24,624 :    name = bert/encoder/layer_4/intermediate/dense/kernel:0, shape = (768, 3072)\n",
            "2019-09-18 12:42:24,625 :    name = bert/encoder/layer_4/intermediate/dense/bias:0, shape = (3072,)\n",
            "2019-09-18 12:42:24,626 :    name = bert/encoder/layer_4/output/dense/kernel:0, shape = (3072, 768)\n",
            "2019-09-18 12:42:24,627 :    name = bert/encoder/layer_4/output/dense/bias:0, shape = (768,)\n",
            "2019-09-18 12:42:24,628 :    name = bert/encoder/layer_4/output/LayerNorm/beta:0, shape = (768,)\n",
            "2019-09-18 12:42:24,629 :    name = bert/encoder/layer_4/output/LayerNorm/gamma:0, shape = (768,)\n",
            "2019-09-18 12:42:24,629 :    name = bert/encoder/layer_5/attention/self/query/kernel:0, shape = (768, 768)\n",
            "2019-09-18 12:42:24,630 :    name = bert/encoder/layer_5/attention/self/query/bias:0, shape = (768,)\n",
            "2019-09-18 12:42:24,631 :    name = bert/encoder/layer_5/attention/self/key/kernel:0, shape = (768, 768)\n",
            "2019-09-18 12:42:24,632 :    name = bert/encoder/layer_5/attention/self/key/bias:0, shape = (768,)\n",
            "2019-09-18 12:42:24,633 :    name = bert/encoder/layer_5/attention/self/value/kernel:0, shape = (768, 768)\n",
            "2019-09-18 12:42:24,634 :    name = bert/encoder/layer_5/attention/self/value/bias:0, shape = (768,)\n",
            "2019-09-18 12:42:24,634 :    name = bert/encoder/layer_5/attention/output/dense/kernel:0, shape = (768, 768)\n",
            "2019-09-18 12:42:24,635 :    name = bert/encoder/layer_5/attention/output/dense/bias:0, shape = (768,)\n",
            "2019-09-18 12:42:24,636 :    name = bert/encoder/layer_5/attention/output/LayerNorm/beta:0, shape = (768,)\n",
            "2019-09-18 12:42:24,637 :    name = bert/encoder/layer_5/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
            "2019-09-18 12:42:24,638 :    name = bert/encoder/layer_5/intermediate/dense/kernel:0, shape = (768, 3072)\n",
            "2019-09-18 12:42:24,639 :    name = bert/encoder/layer_5/intermediate/dense/bias:0, shape = (3072,)\n",
            "2019-09-18 12:42:24,639 :    name = bert/encoder/layer_5/output/dense/kernel:0, shape = (3072, 768)\n",
            "2019-09-18 12:42:24,640 :    name = bert/encoder/layer_5/output/dense/bias:0, shape = (768,)\n",
            "2019-09-18 12:42:24,641 :    name = bert/encoder/layer_5/output/LayerNorm/beta:0, shape = (768,)\n",
            "2019-09-18 12:42:24,642 :    name = bert/encoder/layer_5/output/LayerNorm/gamma:0, shape = (768,)\n",
            "2019-09-18 12:42:24,643 :    name = bert/encoder/layer_6/attention/self/query/kernel:0, shape = (768, 768)\n",
            "2019-09-18 12:42:24,644 :    name = bert/encoder/layer_6/attention/self/query/bias:0, shape = (768,)\n",
            "2019-09-18 12:42:24,645 :    name = bert/encoder/layer_6/attention/self/key/kernel:0, shape = (768, 768)\n",
            "2019-09-18 12:42:24,645 :    name = bert/encoder/layer_6/attention/self/key/bias:0, shape = (768,)\n",
            "2019-09-18 12:42:24,646 :    name = bert/encoder/layer_6/attention/self/value/kernel:0, shape = (768, 768)\n",
            "2019-09-18 12:42:24,647 :    name = bert/encoder/layer_6/attention/self/value/bias:0, shape = (768,)\n",
            "2019-09-18 12:42:24,648 :    name = bert/encoder/layer_6/attention/output/dense/kernel:0, shape = (768, 768)\n",
            "2019-09-18 12:42:24,649 :    name = bert/encoder/layer_6/attention/output/dense/bias:0, shape = (768,)\n",
            "2019-09-18 12:42:24,650 :    name = bert/encoder/layer_6/attention/output/LayerNorm/beta:0, shape = (768,)\n",
            "2019-09-18 12:42:24,650 :    name = bert/encoder/layer_6/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
            "2019-09-18 12:42:24,651 :    name = bert/encoder/layer_6/intermediate/dense/kernel:0, shape = (768, 3072)\n",
            "2019-09-18 12:42:24,652 :    name = bert/encoder/layer_6/intermediate/dense/bias:0, shape = (3072,)\n",
            "2019-09-18 12:42:24,653 :    name = bert/encoder/layer_6/output/dense/kernel:0, shape = (3072, 768)\n",
            "2019-09-18 12:42:24,654 :    name = bert/encoder/layer_6/output/dense/bias:0, shape = (768,)\n",
            "2019-09-18 12:42:24,655 :    name = bert/encoder/layer_6/output/LayerNorm/beta:0, shape = (768,)\n",
            "2019-09-18 12:42:24,656 :    name = bert/encoder/layer_6/output/LayerNorm/gamma:0, shape = (768,)\n",
            "2019-09-18 12:42:24,656 :    name = bert/encoder/layer_7/attention/self/query/kernel:0, shape = (768, 768)\n",
            "2019-09-18 12:42:24,657 :    name = bert/encoder/layer_7/attention/self/query/bias:0, shape = (768,)\n",
            "2019-09-18 12:42:24,658 :    name = bert/encoder/layer_7/attention/self/key/kernel:0, shape = (768, 768)\n",
            "2019-09-18 12:42:24,659 :    name = bert/encoder/layer_7/attention/self/key/bias:0, shape = (768,)\n",
            "2019-09-18 12:42:24,660 :    name = bert/encoder/layer_7/attention/self/value/kernel:0, shape = (768, 768)\n",
            "2019-09-18 12:42:24,661 :    name = bert/encoder/layer_7/attention/self/value/bias:0, shape = (768,)\n",
            "2019-09-18 12:42:24,662 :    name = bert/encoder/layer_7/attention/output/dense/kernel:0, shape = (768, 768)\n",
            "2019-09-18 12:42:24,663 :    name = bert/encoder/layer_7/attention/output/dense/bias:0, shape = (768,)\n",
            "2019-09-18 12:42:24,663 :    name = bert/encoder/layer_7/attention/output/LayerNorm/beta:0, shape = (768,)\n",
            "2019-09-18 12:42:24,664 :    name = bert/encoder/layer_7/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
            "2019-09-18 12:42:24,665 :    name = bert/encoder/layer_7/intermediate/dense/kernel:0, shape = (768, 3072)\n",
            "2019-09-18 12:42:24,666 :    name = bert/encoder/layer_7/intermediate/dense/bias:0, shape = (3072,)\n",
            "2019-09-18 12:42:24,667 :    name = bert/encoder/layer_7/output/dense/kernel:0, shape = (3072, 768)\n",
            "2019-09-18 12:42:24,668 :    name = bert/encoder/layer_7/output/dense/bias:0, shape = (768,)\n",
            "2019-09-18 12:42:24,668 :    name = bert/encoder/layer_7/output/LayerNorm/beta:0, shape = (768,)\n",
            "2019-09-18 12:42:24,669 :    name = bert/encoder/layer_7/output/LayerNorm/gamma:0, shape = (768,)\n",
            "2019-09-18 12:42:24,670 :    name = bert/encoder/layer_8/attention/self/query/kernel:0, shape = (768, 768)\n",
            "2019-09-18 12:42:24,671 :    name = bert/encoder/layer_8/attention/self/query/bias:0, shape = (768,)\n",
            "2019-09-18 12:42:24,672 :    name = bert/encoder/layer_8/attention/self/key/kernel:0, shape = (768, 768)\n",
            "2019-09-18 12:42:24,673 :    name = bert/encoder/layer_8/attention/self/key/bias:0, shape = (768,)\n",
            "2019-09-18 12:42:24,674 :    name = bert/encoder/layer_8/attention/self/value/kernel:0, shape = (768, 768)\n",
            "2019-09-18 12:42:24,675 :    name = bert/encoder/layer_8/attention/self/value/bias:0, shape = (768,)\n",
            "2019-09-18 12:42:24,676 :    name = bert/encoder/layer_8/attention/output/dense/kernel:0, shape = (768, 768)\n",
            "2019-09-18 12:42:24,676 :    name = bert/encoder/layer_8/attention/output/dense/bias:0, shape = (768,)\n",
            "2019-09-18 12:42:24,677 :    name = bert/encoder/layer_8/attention/output/LayerNorm/beta:0, shape = (768,)\n",
            "2019-09-18 12:42:24,678 :    name = bert/encoder/layer_8/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
            "2019-09-18 12:42:24,679 :    name = bert/encoder/layer_8/intermediate/dense/kernel:0, shape = (768, 3072)\n",
            "2019-09-18 12:42:24,680 :    name = bert/encoder/layer_8/intermediate/dense/bias:0, shape = (3072,)\n",
            "2019-09-18 12:42:24,681 :    name = bert/encoder/layer_8/output/dense/kernel:0, shape = (3072, 768)\n",
            "2019-09-18 12:42:24,682 :    name = bert/encoder/layer_8/output/dense/bias:0, shape = (768,)\n",
            "2019-09-18 12:42:24,683 :    name = bert/encoder/layer_8/output/LayerNorm/beta:0, shape = (768,)\n",
            "2019-09-18 12:42:24,684 :    name = bert/encoder/layer_8/output/LayerNorm/gamma:0, shape = (768,)\n",
            "2019-09-18 12:42:24,684 :    name = bert/encoder/layer_9/attention/self/query/kernel:0, shape = (768, 768)\n",
            "2019-09-18 12:42:24,685 :    name = bert/encoder/layer_9/attention/self/query/bias:0, shape = (768,)\n",
            "2019-09-18 12:42:24,686 :    name = bert/encoder/layer_9/attention/self/key/kernel:0, shape = (768, 768)\n",
            "2019-09-18 12:42:24,687 :    name = bert/encoder/layer_9/attention/self/key/bias:0, shape = (768,)\n",
            "2019-09-18 12:42:24,688 :    name = bert/encoder/layer_9/attention/self/value/kernel:0, shape = (768, 768)\n",
            "2019-09-18 12:42:24,689 :    name = bert/encoder/layer_9/attention/self/value/bias:0, shape = (768,)\n",
            "2019-09-18 12:42:24,689 :    name = bert/encoder/layer_9/attention/output/dense/kernel:0, shape = (768, 768)\n",
            "2019-09-18 12:42:24,690 :    name = bert/encoder/layer_9/attention/output/dense/bias:0, shape = (768,)\n",
            "2019-09-18 12:42:24,691 :    name = bert/encoder/layer_9/attention/output/LayerNorm/beta:0, shape = (768,)\n",
            "2019-09-18 12:42:24,692 :    name = bert/encoder/layer_9/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
            "2019-09-18 12:42:24,693 :    name = bert/encoder/layer_9/intermediate/dense/kernel:0, shape = (768, 3072)\n",
            "2019-09-18 12:42:24,694 :    name = bert/encoder/layer_9/intermediate/dense/bias:0, shape = (3072,)\n",
            "2019-09-18 12:42:24,695 :    name = bert/encoder/layer_9/output/dense/kernel:0, shape = (3072, 768)\n",
            "2019-09-18 12:42:24,696 :    name = bert/encoder/layer_9/output/dense/bias:0, shape = (768,)\n",
            "2019-09-18 12:42:24,697 :    name = bert/encoder/layer_9/output/LayerNorm/beta:0, shape = (768,)\n",
            "2019-09-18 12:42:24,697 :    name = bert/encoder/layer_9/output/LayerNorm/gamma:0, shape = (768,)\n",
            "2019-09-18 12:42:24,698 :    name = bert/encoder/layer_10/attention/self/query/kernel:0, shape = (768, 768)\n",
            "2019-09-18 12:42:24,699 :    name = bert/encoder/layer_10/attention/self/query/bias:0, shape = (768,)\n",
            "2019-09-18 12:42:24,700 :    name = bert/encoder/layer_10/attention/self/key/kernel:0, shape = (768, 768)\n",
            "2019-09-18 12:42:24,701 :    name = bert/encoder/layer_10/attention/self/key/bias:0, shape = (768,)\n",
            "2019-09-18 12:42:24,702 :    name = bert/encoder/layer_10/attention/self/value/kernel:0, shape = (768, 768)\n",
            "2019-09-18 12:42:24,702 :    name = bert/encoder/layer_10/attention/self/value/bias:0, shape = (768,)\n",
            "2019-09-18 12:42:24,703 :    name = bert/encoder/layer_10/attention/output/dense/kernel:0, shape = (768, 768)\n",
            "2019-09-18 12:42:24,704 :    name = bert/encoder/layer_10/attention/output/dense/bias:0, shape = (768,)\n",
            "2019-09-18 12:42:24,706 :    name = bert/encoder/layer_10/attention/output/LayerNorm/beta:0, shape = (768,)\n",
            "2019-09-18 12:42:24,707 :    name = bert/encoder/layer_10/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
            "2019-09-18 12:42:24,708 :    name = bert/encoder/layer_10/intermediate/dense/kernel:0, shape = (768, 3072)\n",
            "2019-09-18 12:42:24,712 :    name = bert/encoder/layer_10/intermediate/dense/bias:0, shape = (3072,)\n",
            "2019-09-18 12:42:24,713 :    name = bert/encoder/layer_10/output/dense/kernel:0, shape = (3072, 768)\n",
            "2019-09-18 12:42:24,714 :    name = bert/encoder/layer_10/output/dense/bias:0, shape = (768,)\n",
            "2019-09-18 12:42:24,715 :    name = bert/encoder/layer_10/output/LayerNorm/beta:0, shape = (768,)\n",
            "2019-09-18 12:42:24,716 :    name = bert/encoder/layer_10/output/LayerNorm/gamma:0, shape = (768,)\n",
            "2019-09-18 12:42:24,717 :    name = bert/encoder/layer_11/attention/self/query/kernel:0, shape = (768, 768)\n",
            "2019-09-18 12:42:24,718 :    name = bert/encoder/layer_11/attention/self/query/bias:0, shape = (768,)\n",
            "2019-09-18 12:42:24,720 :    name = bert/encoder/layer_11/attention/self/key/kernel:0, shape = (768, 768)\n",
            "2019-09-18 12:42:24,721 :    name = bert/encoder/layer_11/attention/self/key/bias:0, shape = (768,)\n",
            "2019-09-18 12:42:24,722 :    name = bert/encoder/layer_11/attention/self/value/kernel:0, shape = (768, 768)\n",
            "2019-09-18 12:42:24,723 :    name = bert/encoder/layer_11/attention/self/value/bias:0, shape = (768,)\n",
            "2019-09-18 12:42:24,723 :    name = bert/encoder/layer_11/attention/output/dense/kernel:0, shape = (768, 768)\n",
            "2019-09-18 12:42:24,725 :    name = bert/encoder/layer_11/attention/output/dense/bias:0, shape = (768,)\n",
            "2019-09-18 12:42:24,726 :    name = bert/encoder/layer_11/attention/output/LayerNorm/beta:0, shape = (768,)\n",
            "2019-09-18 12:42:24,727 :    name = bert/encoder/layer_11/attention/output/LayerNorm/gamma:0, shape = (768,)\n",
            "2019-09-18 12:42:24,728 :    name = bert/encoder/layer_11/intermediate/dense/kernel:0, shape = (768, 3072)\n",
            "2019-09-18 12:42:24,729 :    name = bert/encoder/layer_11/intermediate/dense/bias:0, shape = (3072,)\n",
            "2019-09-18 12:42:24,730 :    name = bert/encoder/layer_11/output/dense/kernel:0, shape = (3072, 768)\n",
            "2019-09-18 12:42:24,731 :    name = bert/encoder/layer_11/output/dense/bias:0, shape = (768,)\n",
            "2019-09-18 12:42:24,732 :    name = bert/encoder/layer_11/output/LayerNorm/beta:0, shape = (768,)\n",
            "2019-09-18 12:42:24,733 :    name = bert/encoder/layer_11/output/LayerNorm/gamma:0, shape = (768,)\n",
            "2019-09-18 12:42:24,735 :    name = bert/pooler/dense/kernel:0, shape = (768, 768)\n",
            "2019-09-18 12:42:24,735 :    name = bert/pooler/dense/bias:0, shape = (768,)\n",
            "2019-09-18 12:42:24,737 :    name = cls/predictions/transform/dense/kernel:0, shape = (768, 768)\n",
            "2019-09-18 12:42:24,738 :    name = cls/predictions/transform/dense/bias:0, shape = (768,)\n",
            "2019-09-18 12:42:24,739 :    name = cls/predictions/transform/LayerNorm/beta:0, shape = (768,)\n",
            "2019-09-18 12:42:24,740 :    name = cls/predictions/transform/LayerNorm/gamma:0, shape = (768,)\n",
            "2019-09-18 12:42:24,741 :    name = cls/predictions/output_bias:0, shape = (32000,)\n",
            "2019-09-18 12:42:24,742 :    name = cls/seq_relationship/output_weights:0, shape = (2, 768)\n",
            "2019-09-18 12:42:24,744 :    name = cls/seq_relationship/output_bias:0, shape = (2,)\n",
            "2019-09-18 12:42:24,745 :  From bert/optimization.py:27: The name tf.train.get_or_create_global_step is deprecated. Please use tf.compat.v1.train.get_or_create_global_step instead.\n",
            "\n",
            "2019-09-18 12:42:24,748 :  From bert/optimization.py:32: The name tf.train.polynomial_decay is deprecated. Please use tf.compat.v1.train.polynomial_decay instead.\n",
            "\n",
            "2019-09-18 12:42:24,764 :  From /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/optimizer_v2/learning_rate_schedule.py:409: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Deprecated in favor of operator or tf.math.divide.\n",
            "2019-09-18 12:42:25,402 :  From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1205: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "2019-09-18 12:42:39,563 :  Create CheckpointSaverHook.\n",
            "2019-09-18 12:42:39,944 :  Done calling model_fn.\n",
            "2019-09-18 12:42:45,324 :  TPU job name worker\n",
            "2019-09-18 12:42:47,087 :  Graph was finalized.\n",
            "2019-09-18 12:42:47,209 :  From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n",
            "2019-09-18 12:42:47,346 :  Error recorded from training_loop: The passed save_path is not a valid checkpoint: gs://bert_resourses/bert_model/model.ckpt-102500\n",
            "2019-09-18 12:42:47,347 :  training_loop marked as finished\n",
            "2019-09-18 12:42:47,352 :  Reraising captured error\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-31-fc1a0ca3c649>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_input_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTRAIN_STEPS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, input_fn, hooks, steps, max_steps, saving_listeners)\u001b[0m\n\u001b[1;32m   2874\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2875\u001b[0m       \u001b[0mrendezvous\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord_done\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'training_loop'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2876\u001b[0;31m       \u001b[0mrendezvous\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_errors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2877\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2878\u001b[0m   def evaluate(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/tpu/error_handling.py\u001b[0m in \u001b[0;36mraise_errors\u001b[0;34m(self, timeout_sec)\u001b[0m\n\u001b[1;32m    129\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Reraising captured error'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtyp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraceback\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtyp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraceback\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkept_errors\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/six.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(tp, value, tb)\u001b[0m\n\u001b[1;32m    691\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    692\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 693\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    694\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    695\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, input_fn, hooks, steps, max_steps, saving_listeners)\u001b[0m\n\u001b[1;32m   2869\u001b[0m           \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2870\u001b[0m           \u001b[0mmax_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2871\u001b[0;31m           saving_listeners=saving_listeners)\n\u001b[0m\u001b[1;32m   2872\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2873\u001b[0m       \u001b[0mrendezvous\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'training_loop'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, input_fn, hooks, steps, max_steps, saving_listeners)\u001b[0m\n\u001b[1;32m    365\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    366\u001b[0m       \u001b[0msaving_listeners\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_listeners_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 367\u001b[0;31m       \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    368\u001b[0m       \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Loss for final step: %s.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_train_model\u001b[0;34m(self, input_fn, hooks, saving_listeners)\u001b[0m\n\u001b[1;32m   1156\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_model_distributed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1157\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1158\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_model_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1160\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_train_model_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_train_model_default\u001b[0;34m(self, input_fn, hooks, saving_listeners)\u001b[0m\n\u001b[1;32m   1190\u001b[0m       return self._train_with_estimator_spec(estimator_spec, worker_hooks,\n\u001b[1;32m   1191\u001b[0m                                              \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglobal_step_tensor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1192\u001b[0;31m                                              saving_listeners)\n\u001b[0m\u001b[1;32m   1193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1194\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_train_model_distributed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_train_with_estimator_spec\u001b[0;34m(self, estimator_spec, worker_hooks, hooks, global_step_tensor, saving_listeners)\u001b[0m\n\u001b[1;32m   1478\u001b[0m         \u001b[0msave_summaries_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msave_summary_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1479\u001b[0m         \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session_config\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1480\u001b[0;31m         log_step_count_steps=log_step_count_steps) as mon_sess:\n\u001b[0m\u001b[1;32m   1481\u001b[0m       \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1482\u001b[0m       \u001b[0many_step_done\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mMonitoredTrainingSession\u001b[0;34m(master, is_chief, checkpoint_dir, scaffold, hooks, chief_only_hooks, save_checkpoint_secs, save_summaries_steps, save_summaries_secs, config, stop_grace_period_secs, log_step_count_steps, max_wait_secs, save_checkpoint_steps, summary_dir)\u001b[0m\n\u001b[1;32m    582\u001b[0m       \u001b[0msession_creator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msession_creator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    583\u001b[0m       \u001b[0mhooks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mall_hooks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 584\u001b[0;31m       stop_grace_period_secs=stop_grace_period_secs)\n\u001b[0m\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    586\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, session_creator, hooks, stop_grace_period_secs)\u001b[0m\n\u001b[1;32m   1005\u001b[0m         \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1006\u001b[0m         \u001b[0mshould_recover\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1007\u001b[0;31m         stop_grace_period_secs=stop_grace_period_secs)\n\u001b[0m\u001b[1;32m   1008\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1009\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, session_creator, hooks, should_recover, stop_grace_period_secs)\u001b[0m\n\u001b[1;32m    723\u001b[0m         stop_grace_period_secs=stop_grace_period_secs)\n\u001b[1;32m    724\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mshould_recover\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 725\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_RecoverableSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_coordinated_creator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    726\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    727\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_coordinated_creator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, sess_creator)\u001b[0m\n\u001b[1;32m   1198\u001b[0m     \"\"\"\n\u001b[1;32m   1199\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sess_creator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess_creator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1200\u001b[0;31m     \u001b[0m_WrappedSession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1202\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_create_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36m_create_session\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1203\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1204\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1205\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sess_creator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1206\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0m_PREEMPTION_ERRORS\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1207\u001b[0m         logging.info(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mcreate_session\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    869\u001b[0m       \u001b[0;34m\"\"\"Creates a coordinated session.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m       \u001b[0;31m# Keep the tf_sess for unit testing.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 871\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtf_sess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session_creator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    872\u001b[0m       \u001b[0;31m# We don't want coordinator to suppress any exception.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    873\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoord\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcoordinator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCoordinator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclean_stop_exception_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mcreate_session\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    645\u001b[0m         \u001b[0minit_op\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_scaffold\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_op\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    646\u001b[0m         \u001b[0minit_feed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_scaffold\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_feed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 647\u001b[0;31m         init_fn=self._scaffold.init_fn)\n\u001b[0m\u001b[1;32m    648\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    649\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/session_manager.py\u001b[0m in \u001b[0;36mprepare_session\u001b[0;34m(self, master, init_op, saver, checkpoint_dir, checkpoint_filename_with_path, wait_for_checkpoint, max_wait_secs, config, init_feed_dict, init_fn)\u001b[0m\n\u001b[1;32m    288\u001b[0m         \u001b[0mwait_for_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwait_for_checkpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    289\u001b[0m         \u001b[0mmax_wait_secs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_wait_secs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 290\u001b[0;31m         config=config)\n\u001b[0m\u001b[1;32m    291\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_loaded_from_checkpoint\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0minit_op\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0minit_fn\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_local_init_op\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/session_manager.py\u001b[0m in \u001b[0;36m_restore_checkpoint\u001b[0;34m(self, master, saver, checkpoint_dir, checkpoint_filename_with_path, wait_for_checkpoint, max_wait_secs, config)\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m     \u001b[0;31m# Loads the checkpoint.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 220\u001b[0;31m     \u001b[0msaver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mckpt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_checkpoint_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    221\u001b[0m     \u001b[0msaver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecover_last_checkpoints\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mckpt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall_model_checkpoint_paths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py\u001b[0m in \u001b[0;36mrestore\u001b[0;34m(self, sess, save_path)\u001b[0m\n\u001b[1;32m   1276\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcheckpoint_management\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheckpoint_exists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1277\u001b[0m       raise ValueError(\"The passed save_path is not a valid checkpoint: \" +\n\u001b[0;32m-> 1278\u001b[0;31m                        compat.as_text(save_path))\n\u001b[0m\u001b[1;32m   1279\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1280\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Restoring parameters from %s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: The passed save_path is not a valid checkpoint: gs://bert_resourses/bert_model/model.ckpt-102500"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N_OeXod-fHMT",
        "colab_type": "text"
      },
      "source": [
        "Training the model with the default parameters for 1 million steps will take ~53 hours. \n",
        "\n",
        "In case the kernel is restarted, you may always continue training from the latest checkpoint. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "77ZIAAATfzdF",
        "colab_type": "text"
      },
      "source": [
        "This concludes the guide to pre-training BERT from scratch on a cloud TPU. However, the really fun stuff is still  to come, so stay tuned.\n",
        "\n",
        "Keep learning!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RiFH_9Lbze5f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!gsutil cp gs://hermes_assets/russian_uncased_L-12_H-768_A-12.zip gs://bert_resourses/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PP7_2pKWzfiZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}